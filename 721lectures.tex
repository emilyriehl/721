% !TEX program = lualatex
% The following code introduces a new \if macro which we use to switch
% compilation between the published and internet versions of the book
%
\newif\ifmine
%
% The default is false, which means we compile the internet version.
% Un-comment the next line to compile the published version:
%
%\minetrue
%
\documentclass{amsart}
\usepackage[hidelinks]{hyperref}  
\usepackage{tensor}    
\usepackage{comment} 
\usepackage{enumitem}      
\usepackage{moreenum}
\usepackage{graphicx}   
\usepackage{ifthen}  
\usepackage{stmaryrd}
\usepackage[svgnames]{xcolor}  
 \usepackage{fullpage}
 \hypersetup{  
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
} 
\usepackage{mathpartir}%I think for \inferrule
 
% Font packages  
\usepackage[no-math]{fontspec} 
\usepackage{realscripts}

% Unicode mathematics fonts
\usepackage{unicode-math}
\setmathfont{Asana Math}[Alternate = 2]

% Font imports, for some reason this has to be after 
% the unicode-math stuff. 

\setmainfont{CormorantGaramond}[
Numbers = Lining,  
Ligatures = NoCommon,
Kerning = On,
UprightFont = *-Medium,
ItalicFont = *-MediumItalic,
BoldFont = *-Bold,
BoldItalicFont = *-BoldItalic
]

\setsansfont{texgyreheros}[
Scale=0.9129,
Ligatures = NoCommon,
UprightFont = *-Regular, 
ItalicFont = *-Italic,
BoldFont = *-Bold,
BoldItalicFont = *-BoldItalic
]

\setmonofont{SourceCodePro}[
Scale=0.8333,
UprightFont = *-Regular,
ItalicFont = *-MediumItalic,
BoldFont = *-Bold,
BoldItalicFont = *-BoldItalic
]

% AMS Packages
\usepackage{amsmath}
\usepackage{amsxtra}
\usepackage{amsthm}

% We use TikZ for diagrams
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{makebox}%to try and fix the spacing in some diagrams with wildly divergent node sizes

\renewcommand{\theenumi}{\roman{enumi}} %roman numerals in enumerate

% Adjust list environments.

\setlist{}
\setenumerate{leftmargin=*,labelindent=0\parindent}
\setitemize{leftmargin=\parindent}%,labelindent=0.5\parindent}
%\setdescription{leftmargin=1em}

\newcommand{\todo}[1]
{ {\bfseries \color{blue} #1 }}


\newcommand{\lecture}[1]{\vspace{.1cm}\centerline{\fbox{\textbf{#1}}}\vspace{.1cm}}

\theoremstyle{theorem}
\newtheorem*{thm}{Theorem}
\newtheorem*{lem}{Lemma}
\newtheorem*{fact}{Fact}
\newtheorem*{cor}{Corollary}
\newtheorem*{prop}{Proposition}

\theoremstyle{definition}
\newtheorem*{defn}{defn}
\newtheorem*{ntn}{Notation}
\newtheorem*{post}{Postulate}
\newtheorem*{ax}{Axiom}
\newtheorem*{ex}{ex}
\newtheorem*{nex}{non-ex}
\newtheorem*{exc}{Exercise}
\newtheorem*{exnex}{Example/Non-Example}
\newtheorem*{tf}{T/F}
\newtheorem*{q}{Q}
\newtheorem*{rQ}{rhetorialQ}
\newtheorem*{rev}{Review}


\theoremstyle{remark}
\newtheorem*{rmk}{Remark}
\newtheorem*{war}{Warning}
\newtheorem*{dig}{Digression}

%\makeatletter
%\let\c@equation\c@thm
%\makeatother
%\numberwithin{equation}{section}

\newcommand{\cat}[1]{\textup{\textsf{#1}}}% for categories
\newcommand{\fun}[1]{\textup{#1}}%for functors


%math operators
\DeclareMathOperator{\dom}{\mathrm{dom}}
\DeclareMathOperator{\cod}{\mathrm{cod}}
\DeclareMathOperator{\ob}{\mathrm{ob}}
\DeclareMathOperator{\mor}{\mathrm{mor}}
\DeclareMathOperator*{\colim}{\mathrm{colim}}
\newcommand{\hocolim}{\mathrm{hocolim}}
\newcommand{\wcolim}{\mathrm{wcolim}}
\newcommand{\holim}{\mathrm{holim}}


\newcommand{\op}{\mathrm{op}}
\newcommand{\co}{\mathrm{co}}
\newcommand{\Nat}{\mathrm{Nat}}
\newcommand{\End}{\mathrm{End}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Sym}{\mathrm{Sym}}

\newcommand{\coim}{\mathrm{coim}}
\newcommand{\To}{\Rightarrow}
\newcommand{\coker}{\mathrm{coker}}

\newcommand{\Map}{\mathord{\text{\normalfont{\textsf{Map}}}}}
\newcommand{\Fun}{\mathord{\text{\normalfont{\textsf{Fun}}}}}
\newcommand{\Hom}{\mathord{\text{\normalfont{\textsf{Hom}}}}}
\newcommand{\Ho}{\mathord{\text{\normalfont{\textsf{Ho}}}}}
\newcommand{\h}{\cat{h}}
\DeclareMathOperator{\Lan}{\fun{Lan}}
\DeclareMathOperator{\Ran}{\fun{Ran}}
\newcommand{\comma}{\!\downarrow\!}

%special blackboard bold characters
\newcommand{\bbefamily}{\fontencoding{U}\fontfamily{bbold}\selectfont}
\newcommand{\textbbe}[1]{{\bbefamily #1}}
\DeclareMathAlphabet{\mathbbe}{U}{bbold}{m}{n}


\def\DDelta{{\mbfDelta}}

%categories?
\newcommand{\cA}{\mathsf{A}}
\newcommand{\cB}{\mathsf{B}}
\newcommand{\cC}{\mathsf{C}}
\newcommand{\cD}{\mathsf{D}}
\newcommand{\cE}{\mathsf{E}}
\newcommand{\cF}{\mathsf{F}}
\newcommand{\cG}{\mathsf{G}}
\newcommand{\cI}{\mathsf{I}}
\newcommand{\cJ}{\mathsf{J}}
\newcommand{\cK}{\mathsf{K}}
\newcommand{\cL}{\mathsf{L}}
\newcommand{\cM}{\mathsf{M}}
\newcommand{\cN}{\mathsf{N}}
\newcommand{\cP}{\mathsf{P}}
\newcommand{\cS}{\mathsf{S}}
\newcommand{\cT}{\mathsf{T}}
\newcommand{\cV}{\mathsf{V}}

\newcommand{\0}{\mathbbe{0}}
\newcommand{\1}{\mathbbe{1}}
\newcommand{\2}{\mathbbe{2}}
\newcommand{\3}{\mathbbe{3}}
\newcommand{\4}{\mathbbe{4}}
\newcommand{\iso}{\mathbbe{I}}

%blackboard bold
\renewcommand{\AA}{\mathbb{A}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\LL}{\mathbb{L}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\kk}{\mathbbe{k}}

\newcommand{\sA}{\mathcal{A}}
\newcommand{\sB}{\mathcal{B}}
\newcommand{\sC}{\mathcal{C}}
\newcommand{\sJ}{\mathcal{J}}
\newcommand{\sL}{\mathcal{L}}
\newcommand{\sR}{\mathcal{R}}



%type theory stuff
\newcommand{\univ}{{~\texttt{type}~}}
\newcommand{\judgment}{\mathcal{J}}
\newcommand{\term}[1]{{\textup{\texttt{#1}}}}
\newcommand{\type}[1]{{\textup{#1}}}

\newcommand{\comp}{\term{comp}}
\newcommand{\id}{\term{id}}

\newcommand{\bN}{{\mathbb{N}}}
\newcommand{\bT}{{\mathbb{T}}}
\newcommand{\suc}{\term{succ}_{\bN}}

\newcommand{\ind}{\term{ind}}
\newcommand{\inl}{\term{inl}}
\newcommand{\inr}{\term{inr}}
\newcommand{\pair}{\term{pair}}
\newcommand{\pr}{\term{pr}}

\newcommand{\bZ}{{\mathbb{Z}}}

\newcommand{\refl}{\term{refl}}
\newcommand{\pathind}{\term{path}\text{-}\term{ind}}
\newcommand{\concat}{\term{concat}}
\newcommand{\inv}{\term{inv}}
\newcommand{\assoc}{\term{assoc}}
\newcommand{\ap}{\term{ap}}
\newcommand{\apcoh}[1]{\term{ap}\text{-}\term{#1}}
\newcommand{\tr}{\term{tr}}
\newcommand{\apd}{\term{apd}}

\newcommand{\const}{\term{const}}
\newcommand{\glue}{\term{glue}}

\newcommand{\UU}{{\mathcal{U}}}
\newcommand{\sT}{\mathcal{T}}
\newcommand{\Id}{\textup{\text{Id}}}
\newcommand{\Eq}{\textup{\text{Eq}}}


\newcommand{\bool}{\type{bool}}
\newcommand{\true}{\term{true}}
\newcommand{\false}{\term{false}}

\newcommand{\is}[1]{\type{is-{#1}}}
\newcommand{\iscontr}{\type{is-contr}}
\newcommand{\isprop}{\type{is-prop}}
\newcommand{\isequiv}{\type{is-equiv}}

\newcommand{\fib}{\type{fib}}

\newcommand{\Prop}{\type{Prop}_{\UU}}
\newcommand{\Set}{\type{Set}_{\UU}}
\renewcommand{\iff}{\leftrightarrow}

\newcommand{\mere}[1]{\|{#1}\|}
\newcommand{\set}[1]{\|{#1}\|_0}
\newcommand{\im}[1]{\type{im}(#1)}
\newcommand{\ev}{\term{ev}}

\newcommand{\Fin}{\type{Fin}}

\newcommand{\Sone}{\mathbf{S}^1}
\newcommand{\Sn}[1]{\mathbf{S}^{#1}}
\newcommand{\base}{\term{base}}
\newcommand{\lloop}{\term{loop}}

\newcommand{\mul}{\term{mul}}

\begin{document}

\title{Math 721: Homotopy Type Theory}
\author{Emily Riehl}
\date{Fall 2021}

%\begin{abstract}
%\end{abstract}

\address{Dept.~of Mathematics\\Johns Hopkins University\\3400 N Charles St\\Baltimore, MD 21218}
\email{eriehl@math.jhu.edu}

\maketitle

\setcounter{tocdepth}{1}
\tableofcontents


\ifmine
\subsection*{Index cards:} name, what I should call you, pronouns, year, relevant previous coursework, why you are here, something fun


\subsection*{Personal history:}
Prehistory of homotopy type theory dates to a 1998 paper of Martin Hofmann and Thomas Streicher called ``The groupoid interpretation of type theory,'' that I'll tell you about later. Key early developments were in the mid aughts with the major players coming together for the first time in 2010 at Carnegie Mellon. This expanded to a larger group at Oberwolfach in 2011 followed by a special year at IAS in 2012-2013, during which the HoTT book (not our book) was written.

I got my PhD in 2011. I started hearing a little about this in my final years of grad school but learned most of what I'll tell you about this semester during my postdoc and while here at Johns Hopkins. Point of this to say is that learning doesn't stop when you earn your PhD. Learning also doesn't necessarily precede teaching. My goal for this semester is to know a lot more \texttt{agda} by the end than I do right now. My promise to you is that I'll do all the homework before I assign it. I don't promise that I'll be able to answer very many of your questions about what is going on under the hood, but that's okay too: it's probably useful for all of us to be reminded that figures of authority don't always know what they're talking about.

\subsection*{Syllabus:}
The goal for this course is to change the way you think about doing mathematics. I certainly have. Along the way, I hope you all learn a lot, though as is typical in a graduate course, that's somewhat in proportion to the amount of work you put in. This also has a lot to do with your background. If you're coming from CS, you'll probably leave the course knowing way more \texttt{agda} than I do, but perhaps a bit less about synthetic homotopy theory. For others, it will be vice versa. Still others might engage most with the philosophical implications of these developments. I'm equally happy with all of these directions. 

There are two ``active learning'' activities. The first is writing your own formal proofs in the computer proof assistant \texttt{agda}. This is hard in the sense that if you make one typo the whole thing breaks but a lot of help is available. I'll say more about it when the time comes. In particular, I'm hoping many folks will attend group office hours on Thursday evenings from 5-6pm. In the first meeting there won't be a problem set due: instead the goal will be to get \texttt{agda} installed. Come see me if you're worried about technical issues.

The second active learning activity is a final project. I'm very flexible about the parameters. Essentially you should pick something that sounds fun to you.

Questions?
\fi

\part{Martin-L\"of's Dependent Type Theory}


\section*{August 30: Dependent Type Theory}

Martin-L\"{o}f's dependent type theory is a formal language for writing mathematics: both constructions of mathematical objects and proofs of mathematical propositions. As we shall discover, these two things are treated in parallel (in contrast to classical Set theory plus first-order logic, where the latter supplies the proof calculus and the former gives the language which you use to state things to prove).

\subsection*{Judgments and contexts}

I find it helpful to imagine I'm teaching a computer to do mathematics. It's also helpful to forget that you know other ways of doing mathematics.\footnote{Indeed, there are very deep theorems that describe how to interpret dependent type theory into classical set-based mathematics. You're welcome to investigate these for your final project but they are beyond the scope of this course.}

\begin{defn} There are four kinds of \textbf{judgments} in dependent type theory, which you can think of as the ``grammatically correct'' expressions:
\begin{enumerate}
\item $\Gamma \vdash A \univ$, meaning that $A$ is a well-formed type in \textbf{context} $\Gamma$ (more about this soon).
\item $\Gamma \vdash a : A$, meaning that $a$ is a well-formed term of type $A$ in context $\Gamma$.
\item $\Gamma \vdash A \doteq B \univ$, meaning that $A$ and $B$ are \textbf{judgmentally} or \textbf{definitionally} equal types in context $\Gamma$.
\item $\Gamma \vdash a \doteq b : A$, meaning that $a$ and $b$ are judgmentally equal terms of type $A$ in context $\Gamma$.
\end{enumerate}
These might be collectively abbreviated by $\Gamma \vdash \judgment$.
\end{defn}

The statement of a mathematical theorem, often begins with an expression like ``Let $n$ and $m$ be positive integers, with $n < m$, and let $\vec{v}_1,\ldots, \vec{v}_m$ be vectors in $\RR^n$. Then \ldots'' This statement of the hypotheses defines a \textbf{context}, a finite list of types and hypothetical terms (called \textbf{variables}\footnote{We're not going to say anything about proper syntax for variables and instead rely on instinct to recognize proper and improper usage.}) satisfying an inductive condition that that each type can be derived in the context of the previous types and terms using the inference rules of type theory.

\begin{defn} A \textbf{context} is a finite list of variable declarations:
\[ x : A_1, x_2 : A_2(x_1), \ldots, x_n : A_n(x_1,\ldots, x_{n-1})\]
satisfying the condition that for each $1\leq k \leq n$ we can derive the judgment
\[ x_1 : A_1, \ldots, x_{k-1} : A_{k-1}(x_1,\ldots, x_{k-2}) \vdash A_k(x_1,\ldots, x_{k-1}) \univ\]
using the inference rules of type theory.
\end{defn}

We'll introduce the inference rules shortly but the idea is that it needs to be possible to form the type $A_k(x_1,\ldots, x_{k-1})$ given terms $x_1, \ldots, x_{k-1}$ of the previously-formed types. 

\begin{ex} For example, there is a unique context of length zero: the empty context.
\end{ex}

\begin{ex} $n : \NN, m : \NN, p : n < m, \vec{v} : (\RR^n)^m$ is a context. Here $n : \NN, m : \NN \vdash n < m$ is a dependent type that corresponds to the relation $\{ n < m \mid n, m \in \NN\} \subset \NN \times \NN$ and the variable $p$ is a witness that $n < m$ is true (more about this later). 
\end{ex}

\subsection*{Type families}

Absolutely everything in dependent type theory is context dependent so we always assume we're working in a background context $\Gamma$. Let's focus on the primary two judgment forms.

\begin{defn} Given a type $A$ in context $\Gamma$ a \textbf{family} of types over $A$ in context $\Gamma$ is a type $B(x)$ in context $\Gamma, x : A$, as represented by the judgment:
\[ \Gamma, x : A \vdash B(x) \univ\]
We also say that $B(x)$ is a type \textbf{indexed} by $x : A$, in context $\Gamma$.
\end{defn}

\begin{ex}  $\RR^n$ is a type indexed by $n \in \NN$.
\end{ex}

\begin{defn} Consider a type family $B$ over $A$ in context $\Gamma$. A \textbf{section} of the family $B$ over $A$ in context $\Gamma$ is a term of type $B(x)$ in context $\Gamma, x : A$, as represented by the judgment:
\[ \Gamma, x : A \vdash b(x) : B(x) \]
We say that $b$ is a \textbf{section} of the family $B$ over $A$ in context $\Gamma$ or that $b(x)$ is a term of type $B(x)$ indexed by $x : A$ in context $\Gamma$.
\end{defn}

\begin{ex} $\vec{0}_n : \RR^n$ is a term dependent on $n \in \NN$.
\end{ex}

\begin{exc} If you've heard the word ``section'' before you should think about what it is being used here.
\end{exc}

\subsection*{Inference rules}

There are five types of inference rules that collectively describe the structural rules of dependent type theory. They are
\begin{enumerate}
\item Rules postulating that judgmental equality is an equivalence relation:
\[
\inferrule{\Gamma \vdash A \univ}{\Gamma \vdash A \doteq A \univ}\quad
\inferrule{\Gamma \vdash A \doteq B \univ}{\Gamma \vdash B \doteq A \univ}\quad
\inferrule{\Gamma \vdash A \doteq B \univ \\ \Gamma \vdash B \doteq C \univ}{\Gamma \vdash A \doteq C \univ}
\]
and similarly for judgmental equality between terms.
\item Variable conversion rules for judgmental equality between types:
\[
\inferrule{\Gamma \vdash A \doteq A' \univ \\ \Gamma, x : A, \Delta \vdash  \judgment}{\Gamma, x : A', \Delta \vdash \judgment}
\]

\item Substitution rules:
\[
\inferrule{\Gamma \vdash a : A \\ \Gamma, x : A, \Delta \vdash \judgment}{\Gamma, \Delta[a/x] \vdash \judgment[a/x]}
\]
If $\Delta$ is the context $y_1 : B_1(x),\ldots, y_n : B_n(x,y_1,\ldots, y_{n-1})$ then $\Delta[a/x]$ is the context $y_1 : B(a), \ldots, y_n : B_n(a,y_1,\ldots, y_{n-1})$. A similar substitution is performed in the judgment $\judgment[a/x]$. Further rules indicate that substitution by judgmentally equal terms gives judgmentally equal results.
\item Weakening rules:
\[
\inferrule{ \Gamma \vdash A \univ \\ \Gamma,\Delta \vdash \judgment}{\Gamma, x : A, \Delta \vdash \judgment}
\]
Eg if $A$ and $B$ are types in context $\Gamma$, then $B$ is also a type in context $\Gamma, x : A$.
\item The generic term:
\[ 
\inferrule{\Gamma \vdash A \univ }{\Gamma, x : A \vdash x :A}
\]
This will be used to define the identity function of any type.
\end{enumerate}

\subsection*{Derivations}

A derivation in type theory is a finite rooted tree where each node is a valid rule of inference. The root is the conclusion.

\begin{ex} The interchange rule is derived as follows
\[
\inferrule{ 
\inferrule{ 
\inferrule{ \Gamma \vdash B \univ}{\Gamma, y :B \vdash y : B}}
{\Gamma, y : B, x : A\vdash y : B} \qquad
\inferrule{
\inferrule{}{\Gamma \vdash B \univ} \\ \inferrule{\Gamma, x : A, y : B, \Delta \vdash \judgment}{\Gamma, x : A, z : B, \Delta[z/y] \vdash \judgment[z/y]}}
{\Gamma, y : B, x : A, z : B, \Delta[z/y] \vdash \judgment[z/y]}
}{\Gamma, y : B, x : A, \Delta \vdash \judgment}
\]
\end{ex}

\section*{September 1: Dependent function types \& the natural numbers}

\subsection*{The rules for dependent function types}

Consider a section $b$ of a family $B$ over $A$ in context $\Gamma$, as encoded by a judgment:
\[ \Gamma, x : A \vdash b(x) : B(x).\]
We think of the section $b$ as a function that takes as input $x : A$ and produces a term $b(x) : B(x)$. Since the type of the output is allowed to depend on the term being input, this isn't quite an ordinary function but a \textbf{dependent function}. The type of all dependent functions is the \textbf{dependent function type}
\[ \Pi_{x : A} B(x)\]

What is a thing in mathematics? Structuralism says the ontology of a thing is determined by its behavior. In dependent type theory, we define dependent function types by stating their rules, which have the following forms:
\begin{enumerate}
\item \textbf{formation rules} tell us how a type may be formed
\item \textbf{introduction rules}  tell us how to introduce new terms of the type
\item \textbf{elimination rules}  tell us how the terms of a type may be used
\item  \textbf{computation rules} tell us how the introduction and elimination rules interact
\end{enumerate}
There are also \textbf{congruence rules} that tell us that all constructions respect judgmental equality. See \cite{Rijke} for more details.

\begin{defn}[dependent function types]
The $\Pi$-\textbf{formation rule} has the form:
\[
\inferrule{ \Gamma, x : A \vdash B(x) \univ}{\Gamma \vdash \Pi_{x :A} B(x) \univ}
\]

The $\Pi$-\textbf{introduction rule} has the form:
\[
\inferrule{ \Gamma, x : A \vdash b(x) : B(x)}{ \Gamma \vdash \lambda x. b(x) : \Pi_{x :A} B(x)}
\]
The $\lambda$-\textbf{abstraction} $\lambda x. b(x)$ can be thought of as notation for $x \mapsto b(x)$. 

The $\Pi$-\textbf{elimination rule} has the form of the evaluation function:
\[
\inferrule{ \Gamma \vdash f : \Pi_{x :A} B(x)}{\Gamma, x :A \vdash f(x) : B(x)}
\]

Finally, there are two computation rules: the $\beta$-\textbf{rule}
\[
\inferrule{\Gamma , x :A \vdash b(x) : B(x) }{ \Gamma, x : A \vdash (\lambda y. b(y))(x) \doteq b(x) : B(x)}
\]
and the $\eta$-\textbf{rule}, which says that all elements of a $\Pi$-type are dependent functions:
\[
\inferrule{ \Gamma \vdash f : \Pi_{x : A}B(x)}{\Gamma \vdash \lambda x. f(x) \doteq f : \Pi_{x :A} B(x)}\]
\end{defn}





\subsection*{Ordinary function types}

\begin{defn}[function types]
The formation rule is derived from the formation rule for $\Pi$-types together with weakening:
\[
\inferrule{
\inferrule{ \Gamma \vdash A \univ \\ \Gamma \vdash B \univ}{\Gamma, x : A \vdash B \univ}}
{\Gamma \vdash \Pi_{x : A}B \univ}
\]
We adopt the notation
\[ A \to B \coloneq \Pi_{x : A} B\]
for the dependent function type in the case where the type family $B$ is constant over $x : A$.

The introduction, evaluation, and computation rules are instances of term conversion: eg
\[
\inferrule{ \Gamma \vdash B \univ \\ \Gamma, x : A \vdash b(x) : B}
{ \Gamma \vdash \lambda x. b(x) : A \to B}
\qquad
\inferrule{ \Gamma \vdash f : A \to B}{\Gamma, x : A \vdash f(x) : B}
\]
plus the two computation rules:
\[
\inferrule{ \Gamma \vdash B \univ \\ \Gamma, x : A \vdash b(x) : B}{ \Gamma, x : A \vdash (\lambda y. b(y))(x) \doteq b(x) : B}
\qquad
\inferrule{ \Gamma \vdash f : A  \to B}{\Gamma \vdash \lambda x. f(x) \doteq f : A \to B}
\]
\end{defn}

\begin{defn} Identity functions are defined as follows:
\[
\inferrule{
\inferrule{ \Gamma \vdash A \univ}{\Gamma, x : A \vdash x : A}}
{ \Gamma \vdash \lambda x. x : A \to A}\]
which is traditionally denoted by $\id_A \coloneq \lambda x. x$.
\end{defn}

The idea of composition is that given a function $f \colon A \to B$ and $g \colon B \to C$ you should get a function $g \circ f \colon A \to C$. Using infix notation you might denote this function by $\_\circ\_$.

\begin{q} $\_\circ\_$ is itself a function, so it's a term of some type. What type?\footnote{Really the type should involve three universe variables but let's save this for next week.}
\end{q}

\begin{defn} Composition has the form:
\[
\inferrule{ \Gamma \vdash A \univ \\ \Gamma \vdash B \univ \\ \Gamma \vdash C \univ}{\Gamma \vdash \_\circ\_ : (B \to C) \to ((A \to B) \to (A \to C))}
\]
It is defined by
\[ \_\circ\_ \coloneq \lambda g. \lambda f . \lambda x. g(f(x))\]
which can be understood as the term constructed by three applications of the $\Pi$-introduction rule followed by two applications of the $\Pi$-elimination rule.
\end{defn}

Composition is associative essentially because both $(h\circ g)\circ f$ and $h \circ (g \circ f)$ are defined by $\lambda x. h(g(f(x)))$. We'll think about this more formally when we come back to identity types.

Similarly, you can compute that for all $f : A \to B$, $\id_B \circ f \doteq f : A \to B$ and $f \circ \id_A \doteq f : A \to B$.

\subsection*{The type of natural numbers}

The type $\bN$ of natural numbers is the archetypical example of an \textbf{inductive type} about more which soon. It is given by rules which say that it has a term $0_\bN : \bN$, it has a successor function $\suc : \bN \to\bN$ and it satisfies the induction principle.

The $\bN$-formation rule is
\[
\inferrule{~}{\vdash \bN \univ}
\]
In other words, $\bN$ is a type in the empty context.

There are two $\bN$-introduction rules:
\[
\inferrule{~}{\vdash 0_\bN : \bN} \qquad
\inferrule{~}{\vdash \suc : \bN \to \bN}
\]

\begin{dig}[traditional induction]
In traditional first-order logic, the principle of $\bN$-induction is stated in terms of a \textbf{predicate} $P$ over $\bN$. One way to think about $P$ is as a function $P \colon \bN \to \{ \top, \bot\}$. That is, for each $n \in \bN$, $P(n)$ is either true or false. We could also think of $P$ as an indexed family of sets $(P(n))_{n \in \bN}$ where for each $n$ either $P(n) = \emptyset$ (corresponding to $P(n)$ being false) or $P(n) = *$ (corresponding to $P(n)$ being true).

The induction principle then says \[ \forall P : \{0,1\}^\bN, (P(0) \wedge (\forall n, P(n) \to P(n+1)) \to \forall n, P(n)).\]
\end{dig}

In dependent type theory it is most natural to let $P$ be an arbitrary type family over $\bN$. This is a stronger assumption, as we'll see. 

\begin{q}
What then corresponds to a proof that $\forall n, P(n)$?
\end{q}

The induction principle is encoded by the following rule:
\[
\inferrule{ \Gamma, n : \bN \vdash P(n) \univ \\ \Gamma \vdash p_0 : P(0_\bN) \\ \Gamma \vdash p_S : \Pi_{n : \bN} (P(n) \to P(\suc(n))) }
{ \Gamma \vdash \term{ind}_\bN(p_0,p_S) : \Pi_{n : \bN} P(n)}
\]

\begin{rmk} There are other forms this rule might take that are interderivable with this one.
\end{rmk}

The computation rules say that the function $\term{ind}_\bN(p_0,p_S) : \Pi_{n : \bN} P(n)$ behaves like it should on $0_\bN$ and successors:
\[
\inferrule{ \Gamma , n : \bN \vdash P(n) \univ \\ \Gamma \vdash p_0 : P(0_\bN) \\ \Gamma \vdash p_S : \Pi_{n : \bN} (P(n) \to P(\suc(n))) }
{ \Gamma \vdash \term{ind}_\bN(p_0,p_S)(0_\bN) \doteq p_0 : P(0_\bN)}
\]
and under the same premises
\[ \Gamma, n : \bN \vdash \texttt{ind}_\bN(p_0, p_S)(\suc(n)) \doteq p_S(n, \texttt{ind}_\bN(p_0,p_S,n)) : P(\suc(n)).\]
These computation rules don't matter so much if the type family $n : \bN \vdash P(n)$ is really a predicate --- $P(n)$ is either true or false and that's the end of the story --- but they do matter if $P(n)$ is more like an indexed family of sets. In the latter case, $\term{ind}_\bN(p_0,p_S)$ is the recursive function defined from $p_0$ and $p_S$ and these are the computation rules for that recursion.

\begin{rmk} Recall Peano's axioms for the natural numbers: 
\begin{enumerate}
\item $0_\bN \in \bN$
\item $\suc : \bN \to \bN$
\item $\forall n, \suc(n) \neq 0_\bN$
\item $\forall n,m, \suc(n)= \suc(m) \to n=m$
\item induction
\end{enumerate}
We'll be able to \emph{prove} the missing two axioms from the induction principle we've assumed once we have identity types and universes. We'll come back to this in a few weeks.
\end{rmk}

\subsection*{Addition on the natural numbers}

\begin{rmk} When addition is defined by recursion on the second variable, from the computation rules associated to function types and the natural numbers type you can derive judgmental equalities \[
m + 0 \doteq m \quad \text{and} \quad m + \suc(n) \doteq \suc(m + n).
\]
But you can't derive the symmetric judgmental equalities.
\end{rmk}

We \emph{will} be able to prove such equalities using the identity types, to be introduced shortly.

\subsection*{Pattern matching}

To define a dependent function $f : \Pi_{n : \bN} P(n)$ by induction on $n$ it suffices, by the elimination rule for the natural numbers type, to provide two terms:
\[ p_0 : P(0_\bN) \qquad p_S : \Pi_{n : \bN} P(n) \to P(\suc(n)).\]
Thus the definition of $f$ may be presented by writing
\[ f(0_\bN) \coloneq p_0 \qquad f(\suc(n)) \coloneq p_S(n,f(n)).\]
This defines the function $f$ by \textbf{pattern matching} on the variable $n$. When a function is defined in this form, the judgmental equalities accompanying the definition are immediately displayed.

\section*{September 8: The formal proof assistant \texttt{agda}}

See \url{https://github.com/emilyriehl/721/blob/master/introduction.agda}


\section*{September 13: Inductive types}

The rules for the natural numbers type $\bN$ tell us:
\begin{enumerate}
\item how to form terms in $\bN$, and
\item how to define dependent functions in $\Pi_{n : \bN} P(n)$ for any type family $n : \bN \vdash P(n) \univ$,
\end{enumerate}
while providing two computation rules for those dependent functions.

Many types can be specified by stating how to form their terms and how to define dependent functions out of them. Such types are called \textbf{inductive types}. 

\subsection*{The idea of inductive types}

Recall a type is specified by its formation rules, its introduction rules, its elimination rules, and its computation rules. For inductive types, the introduction rules specify the \textbf{constructors} of the inductive type, while the elimination rule provides the \textbf{induction principle}. The computation rules provide definitional equalities for the induction principle.

In more detail:
\begin{enumerate}
\item The constructors tell us what structure the identity type is given with.
\item The induction principle defines sections of any type family over the inductive type by specifying the behavior at the constructors.
\item The computation rules assert that the inductively defined section agrees on the constructors with the data used to define it. So there is one computation rule for each constructor.
\end{enumerate}

\subsection*{The unit type}

The formal definition of the \textbf{unit type} is as follows:
\[
\inferrule{}{\vdash \1 \univ} \qquad
\inferrule{}{\vdash \star : \1} \qquad 
\inferrule{ x : \1 \vdash P(x) \univ \\ p : P(\star)}{ x: \1 \vdash \ind_\1(p,x) : P(x)} \qquad
\inferrule{ x : \1 \vdash P(x) \univ \\ p : P(\star)}{x : \1 \vdash \ind_1(p,\star) \doteq p : P(\star)}
\]
As an inductive type, the definition is packaged as follows:

\begin{defn} The \textbf{unit type} is a type $\1$ equipped with a term $\star : \1$ satisfying the inductive principle that for any family $x : \1 \vdash P(x)$ there is a function
\[ \ind_\1 : P(\star) \to \Pi_{x : 1} P(x)\]
with the computation rule $\ind_1(p,\star) \doteq p$.
\end{defn}

In agda, this definition has the form:
\begin{quote}
\texttt{data unit : UU lzero where\\ \indent
  star : unit}
  \end{quote}


\begin{q} What does the induction rule look like for a constant type family $A$ that does not depend on $\1$?
\end{q}

\subsection*{The empty type}

\begin{defn}
The empty type is a type $\emptyset$ satisfying the induction principle that for any family of types $x : \emptyset \vdash P(x)$ there is a term
\[ \ind_\emptyset : \Pi_{x : \emptyset} P(x).\]
\end{defn}

That is the empty type is the inductive type with no constructors. Thus there are no computation rules. In agda, this definition has the form:
\begin{quote}
\texttt{data empty : UU lzero where}
  \end{quote}

\begin{rmk} As a special case of the elimination rule for the empty type we have
\[
\inferrule{ \vdash A \univ}{ \term{ex-falso} \coloneq \ind_\emptyset : \emptyset \to A}
\]
By the elimination rule for function types it follows that if we had a term $x : \emptyset$ then we could get a term in any type. The name comes from latin \emph{ex falso quodlibet}: ``from falsehood, anything.''
\end{rmk}

We've already seen a few glimpses of logic in type theory, something we'll discuss more formally soon. The basic idea is that we can interpret the formation of a type as akin to the process of formulating a mathematical statement that could be a sentence (if its a type in the empty context) or a predicate (if it's a dependent type). The act of constructing a term in that type is then analogous to proving the proposition so-encoded. 
These ideas motivate the logically-inflected terms in what follows. 

For instance, we can use the empty type to define a negation operation on types:
\begin{defn}
For any type $A$, we define its \textbf{negation} by $\neg A \coloneq A \to \emptyset$ and say the type $A$ \textbf{is empty} if there is a term in this type.
\end{defn}

\begin{rmk} To construct a term of type $\neg A$, use the introduction rule for function types and assume given a term $a : A$. The task then is to derive a term of $\emptyset$. In other words, we prove $\neg A$ by assuming $A$ and deriving a contradiction. This proof technique is called \textbf{proof of negation}.

This should be contrasted with \textbf{proof by contradiction}, which aims to prove a proposition $P$ by assuming $\neg P$ and deriving a contradiction. This uses the logical step ``$\neg \neg P$ implies $P$.'' In type theory, however, $\neg \neg A$ is the type of functions
\[ \neg \neg A \coloneq (A \to \emptyset) \to \emptyset)\] and it is not possible in general to use a term in this type to construct a term of type $A$. 
\end{rmk}

The law of contraposition does work, at least in one direction.

\begin{prop} For any types $P$ and $Q$ there is a function
\[ (P \to Q) \to (\neg Q \to \neg P).\]
\end{prop}
\begin{proof}
By $\lambda$-abstraction assume given $f : P \to Q$ and $\tilde{q} : Q \to \emptyset$. We seek a term in $P \to \emptyset$, which we obtain simply by composing: $\tilde{q} \circ f : P \to \emptyset$. Thus
\[\lambda f. \lambda \tilde{q} .\lambda p. \tilde{q}(f(p)) : (P \to Q) \to (\neg Q \to \neg P). \qedhere\]
\end{proof}

\subsection*{Coproducts}

Inductive types can be defined outside the empty context. For instance, the formation and introduction rules for the coproduct type have the form:
\[
\inferrule{ \Gamma \vdash A \univ \\ \Gamma \vdash B \univ}{\Gamma \vdash A + B \univ} 
\]
\[
\inferrule{ \Gamma \vdash A \univ \\ \Gamma \vdash B \univ \\ \Gamma \vdash a : A}{ \Gamma \vdash \inl a : A + B} \qquad
\inferrule{ \Gamma \vdash A \univ \\ \Gamma \vdash B \univ \\ \Gamma \vdash b : B}{ \Gamma \vdash \inr b : A + B}
\]

\begin{defn} Given types $A$ and $B$ the \textbf{coproduct type} is the type equipped with 
\[ \inl : A \to A + B \qquad \inr : B \to A+ B\]
satisfying the induction principle that says that for any family of types $x : A + B \vdash P(x) \univ$ there is a term
\[ \ind_+ : \left( \Pi_{x : A} P(\inl (x))\right) \to \left( \Pi_{y : B} P(\inr(y))\right) \to \Pi_{z : A + B}P(z)\]
satisfying the computation rules
\[ \ind_+(f,g, \inl(x)) \doteq f(x) \qquad \ind_+(f,g, \inr(y)) \doteq g(y).\]
\end{defn}
Not as a special case we have
\[ \ind_+ : (A \to X) \to (B \to X) \to (A + B \to X)\]
which is similar to the elimination rule for disjunction in first order logic: if you've proven that $A$ implies $X$ and that $B$ implies $X$ then you can conclude that $A$ or $B$ implies $X$.

\subsection*{The type of integers}

There are many ways to define the integers in Martin-L\"{o}f type theory, one of which is as follows:

\begin{defn} Define the \textbf{integers} to be the type $\bZ \coloneq \bN + (\1 + \bN)$ which comes equipped with inclusions:
\[ \term{in-pos} \coloneq \inr\circ\inr : \bN \to \bZ \qquad \term{in-neg} \coloneq \inl : \bN \to \bZ\]
and constants
\[ -1_\bZ \coloneq \term{in-neg}(0_\bN) \qquad 0_\bZ \coloneq \inr (\inl(\star)) \qquad 1_{\bZ} \coloneq \term{in-pos}(0_\bN).\]
\end{defn}

Since $\bZ$ is built from inductive types it is then an inductive type given with its own induction principle.

\subsection*{Dependent pair types}

Of all the inductive types we've introduced, the final one is perhaps the most important.

Recall a \textbf{dependent function} $\lambda x . f(x) : \Pi_{x : A}B(x)$ is like an ordinary function except the output type is allowed to vary with the input term. Similarly, a \textbf{dependent pair} $(a,b) : \Sigma_{x : A}B(x)$ is like an ordinary (ordered) pair except the type of the second term $b : B(a)$ is allowed to vary with the first term $a :A$.

\begin{defn} Consider a type family $x : A \vdash B(x) \univ$. The \textbf{dependent pair type} or $\Sigma$-\textbf{type} $\Sigma_{x :A}B(x)$ is the inductive type equipped with the function
\[ \pair : \Pi_{x : A} \left(B(x) \to \Sigma_{y : A}B(y)\right).\]
The induction principle asserts that for any family of types $p : \Sigma_{x :A} B(x) \vdash P(p) \univ$ there is a function
\[ \ind_\Sigma : \left( \Pi_{x :A} \Pi_{y : B}P(\pair(x,y) \right) \to \left( \Pi_{z : \Sigma_{x :A}B(x)}P(z) \right)
\]
satisfying the computation rule $\ind_\Sigma (g,\pair(x,y)) \doteq g(x,y)$.
\end{defn}

It is common to write ``$(x,y)$'' as shorthand for ``$\pair(x,y)$.''

\begin{defn} Given a type family $x :A \vdash B(x) \univ$ by the induction principle for $\Sigma$-types, we have a function
\[ \pr_1 : \Sigma_{x :A}B(x) \to A\]
defined by $\pr_1(x,y) \coloneq x$ and a dependent function
\[ \pr_2 :  \Pi_{ p : \Sigma_{x :A}B(x)} B(\pr_1(p))\]
defined by $\pr_2(x,y) \coloneq y$.
\end{defn}

When $B$ is a constant type family over $A$, the type $\Sigma_{x : A}B$ is the type of ordinary pairs $(x,y)$ where $x :A $ and $y: B$. Thus \textbf{product types} arise as special cases of $\Sigma$-types.

\begin{defn} Given types $A$ and $B$ their product type is the type $A \times B \coloneq \Sigma_{x :A}B$. It comes with a pairing function
\[ (-,-) : A \to B \to A \times B\] and satisfies an induction principle:
\[ \ind_\times : \Pi_{x : A} \Pi_{y : B} P(x,y) \to \Pi_{z : A \times B} P(z)\]
satisfying the computation rule $\ind_\times (g,(x,y)) \doteq g(x,y)$.
\end{defn}

As a special case, we have
\[ \ind_\times : (A \to B \to C) \to ((A \times B) \to C).\]
This is the inverse of the \textbf{currying function}. Thus $\ind_\times$ and $\ind_\Sigma$ sometimes go by the name \textbf{uncurrying}.

\section*{September 15: Identity types}

We have started to develop an analogy in which types play the role of mathematical propositions and terms in a type play the role of proofs of that proposition. More exactly, we might think of a type as a ``proof-relevant'' proposition, the distinction being that the individual proofs of a given proposition---the terms of the type---are first class mathematical objects, which may be used as ingredients in future proofs, rather than mere witnesses to the truth of the particular proposition.

The various constructions on types that we have discussed are analogous to the logical operations ``and,'' ``or,'' ``implies,'' ``not,'' ``there exists,'' and ``for all.'' We also have the unit type $\1$ to represent the proposition $\top$ and the empty type $\emptyset$ to represent the proposition $\bot$. There is one further ingredient from first-order logic that is missing a counterpart in dependent type theory: the logical operation ``$=$.''

Given a type $A$ and two terms $x,y : A$ it is sensible to ask whether $x = y$. From the point of view of types as proof-relevant propositions, ``$x=y$'' should be the name of a type, in fact a dependent type. The formation rule for \textbf{identity types} says
\[
\inferrule{ \Gamma \vdash A \univ}
{\Gamma, x : A, y : A \vdash x =_A y \univ}
\]
where ``$x=y$'' is commonly used as an abbreviation for ``$x=_Ay$'' when the type of $x$ and $y$ is clear from context. A term $p : x = y$ of an identity type is called an \textbf{identification} of $x$ and $y$ or a \textbf{path} from $x$ to $y$ (more about this second term later). Identifications have a rich structure that follows from a very simple characterization of the identity type due to Per Martin-L\"{o}f: it is the inductive type family freely generated by the reflexivity terms.

\subsection*{The inductive definition of identity types}

We can define identity types as inductive types in either a one-sided or two-sided fashion. The induction rule may be easier to understand from the one-sided point of view, so we present it first.

\begin{defn}[one-sided identity types] Given a type $A$ and a term $a : A$, the \textbf{identity type} of $A$ at $a$ is the inductive family of types $x : A \vdash a =_A x \univ$ with a single constructor $\refl_a : a =_A a$. The induction principle is postulates that for any type family $x : A, p : a =_A x \vdash P(x,p) \univ$ there is a function
\[ \pathind_a : P(a, \refl_a) \to \Pi_{x : A} \Pi_{p : a =_A x} P(x,p)\]
satisfying $\pathind_a(q,a, \refl_a) \doteq q$.
\end{defn}

This is a very strong induction principle: it says that to prove a predicate $P(x,p)$ depending on any term $x :A$ and any identification $p : a =_A x$ it suffices to assume $x$ is $a$ and $p$ is $\refl_a$ and prove $P(a,\refl_a)$. 

More formally, identity types are defined by the following rules:
\[
\inferrule{ \Gamma \vdash a : A}{ \Gamma, x : A \vdash a =_A x \univ} \qquad
\inferrule{\Gamma \vdash a : A}{\Gamma \vdash \refl_a : a =_A a}\]
\[ 
\inferrule{\Gamma \vdash a : A \\ \Gamma, x : A, p: a=_A x \vdash P(x,p) \univ}{\Gamma \vdash \pathind_a : P(a,\refl_a) \to \Pi_{x :A}\Pi_{p : a =_A x}P(x,p)} \qquad
\inferrule{\Gamma \vdash a : A \\ \Gamma, x : A, p: a=_A x \vdash P(x,p) \univ}{\Gamma \vdash \pathind_a(q,a, \refl_a) \doteq q : P(a,\refl_a)}
\]

Equally, the identity type can be considered in a two-sided fashion:
\begin{defn}[two-sided identity types]
 Given a type $A$, the \textbf{identity type} of $A$ is the inductive family of types $x : A, y :A \vdash x =_A y \univ$ with a single constructor $x : A \vdash \refl_x : x =_A x$. The induction principle is postulates that for any type family $x : A, y : A, p : x =_A y \vdash P(x,y,p) \univ$ there is a function
\[ \pathind : \Pi_{a : A} P(a, a, \refl_a) \to \Pi_{x : A} \Pi_{y: A}\Pi_{p : x =_A y} P(x,y,p)\]
satisfying $\pathind(q,a, a,\refl_a) \doteq q$.
\end{defn}

In this form, the identity types are defined by the following rules:
\[
\inferrule{ \Gamma \vdash A}{ \Gamma, x : A, y : A \vdash x =_A y \univ} \qquad
\inferrule{\Gamma \vdash A}{\Gamma, x :A \vdash \refl_x : x =_A x}\]
\[ 
\inferrule{\Gamma \vdash A \\ \Gamma, x : A, y : A, p: x=_A y \vdash P(x,y,p) \univ}{\Gamma \vdash \pathind : \Pi_{a : A} P(a,a,\refl_a) \to \Pi_{x :A}\Pi_{y :A}\Pi_{p : x =_A y}P(x,y, p)} \quad
\inferrule{\Gamma \vdash  A \\ \Gamma, x : A, y : A, p: x=_A y \vdash P(x,y,p) \univ}{\Gamma, a : A \vdash  \pathind (q,a,a,\refl_a) \doteq q : P(a,a,\refl_a)}
\]

These presentations are interderivable.

\subsection*{The groupoid structure on types}

Mathematical equality, as traditionally understood, is an equivalence relation: it's reflexive, symmetric, and transitive. But all we've asserted about identity types is that they are inductively generated by the reflexivity terms! As we'll now start to discover, considerable additional structure follows.

\begin{prop}[symmetry] For any type $A$, three is an  \textbf{inverse operation}
\[ \inv : \Pi_{x, y :A} x = y \to y =x.\]
\end{prop}
\begin{proof}
We define $\inv$ by path induction. By the introduction rule for function types it suffices to define $\inv p : y =x$ for $p : x = y$. Consider the type family $x : A, y : A, p: x = y \vdash P(x,y,p) \coloneq y = x$. By path induction to inhabit $y=x$ it suffices to assume $x = y$ and $p$ is $\refl_x$ in which case we may define $\inv \refl_x \coloneq \refl_x : x=x$. Thus $\inv$ is
\[ \pathind (\lambda x, \refl x) : \Pi_{x :A} \Pi_{y :A} \Pi_{x = y} y =x.\]
\end{proof}

\begin{ntn} Write $p^{-1}$ for $\inv(p)$.
\end{ntn}

\begin{prop}[transitivity]
For any type $A$, there is a  \textbf{concatenation} operation
\[ \concat : \Pi_{x,y,z :A} x= y \to y=z \to x = z.\] 
\end{prop}
\begin{proof}
We define $\concat$ by appealing to the path induction principle for identity types. 
By the introduction rule for dependent function types, to define $\concat$ you may assume given $p : x=y$. The task is then to define $\concat (p) : \Pi_{z} y =z \to x = z$.  For this, consider the type family $x :A , y : A, p : x = y \vdash P(x,y,p)$ where $P(x,y,p) \coloneq \Pi_{z : A} (y = z) \to (x = z)$. By applying the function $\pathind$ to get a term of this type it suffices to assume $y$ is $x$ and $p$ is $\refl_x$. So we need only define $\concat( \refl_x) : \Pi_{z :A} x =z \to x = z$ and we define this to be the identity function $\id_{x = z}$. Thus the function $\concat$ is 
\[  \pathind( \lambda x, \lambda z, \id_{x=z}) : \Pi_{x :A}\Pi_{y :A} \Pi_{p : x = y} \Pi_{z :A} y=z \to x =z,\]
which can be regarded as a function in the type $\Pi_{x,y,z :A} x= y \to y=z \to x = z$ by swapping the order of the arguments $p$ and $z$.
\end{proof}

\begin{ntn} Write $p \cdot q$ for $\concat(p,q)$.
\end{ntn}

While the elimination rule for identity types is quite strong the corresponding computation rule is relatively weak. It's not strong enough to show that $(p \cdot q) \cdot r$ and $p \cdot (q \cdot r)$ are judgmentally equal for any $p : x = y$, $q : y = z$, and $r : z = q$. In fact there are countermodels that show that this is false in general. However, since both $(p \cdot q) \cdot r$ and $p \cdot (q \cdot r)$ are terms of type $x = w$ we can ask whether there is an identification between them and it turns out this is always true.

\begin{prop}[associativity] Given $x,y,z,w  :A$ and identifications $p : x = y$, $q : y =z$, and $r : z = w$, there is an associator
\[ \assoc (p,q,r) : (p \cdot q) \cdot r = p \cdot (q \cdot r)\]
\end{prop}
\begin{proof} We define $\assoc(p,q,r)$ by path induction. 

Consider the type family $x :A, y : A, p: x = y \vdash \Pi_{z :A} \Pi_{q : y =z} \Pi_{w:A} \Pi_{r : z =w} (p \cdot q) \cdot r = p \cdot (q \cdot r)$. To define a term $\assoc (p,q,r)$ in here it suffices to assume $y$ is $x$ and $p$ is $\refl_x$ and define
\[ \lambda z. \lambda q. \lambda w. \lambda r. \assoc(\refl_x, q,r) : \Pi_{z :A} \Pi_{q : x =z} \Pi_{w:A} \Pi_{r : z =w} (\refl_x \cdot q) \cdot r = \refl_x \cdot (q \cdot r).\]
By the definition of concatenation, $\refl_x \cdot q \doteq q$ and $\refl_x \cdot (q \cdot r) \doteq q \cdot r$. So we must define 
\[ \assoc(\refl_x, q,r) :  q \cdot r = q \cdot r\]
and we can take this term to be $\refl_{q \cdot r}$.
\end{proof}

\begin{prop}[units] For any type $A$, there are left and right \textbf{unit laws}
\[ \lambda x. \lambda y. \lambda p. \term{left-unit}(p) :  \lambda {x,y : A} \Pi_{p: x = y} \refl_x \cdot p = p \qquad  \lambda x. \lambda y. \lambda p.\term{right-unit}(p) : \Pi_{x , y : A} \Pi_{p : x = y} p \cdot \refl_y = p.\]
\end{prop}
\begin{proof}
We are asked to define  dependent functions that takes $x, y :A$ and $p : x = y$ and produce terms
\[ \term{left-unit}(p) : \refl_x \cdot p = p \qquad \term{right-unit}(p) : p \cdot \refl_y = p.\]
By path induction, it suffices to assume $y$ is $x$ and $p$ is $\refl_x$, in which case we require terms
\[ \term{left-unit}(\refl_x) : \refl_x \cdot \refl_x = \refl_x \qquad \term{right-unit}(\refl_x) : \refl_x \cdot \refl_x = \refl_x.\] By the definition of concatenation $\refl_x \cdot \refl_x \doteq \refl_x$ so we can take $\refl_{\refl_x}$ as both $\term{left-unit}(\refl_x)$ and $\term{right-unit}(\refl_x)$.
\end{proof}

\begin{prop}[inverses] For any type $A$, there are left and right \textbf{inverse laws}
\[  \lambda x. \lambda y. \lambda p.\term{left-inv}(p) : \Pi_{x,y :A} \Pi_{p : x= y} p^{-1} \cdot p = \refl_y \qquad  \lambda x. \lambda y. \lambda p.\term{right-inv}(p) : \Pi_{x,y :A} \Pi_{p : x=y} p \cdot p^{-1} = \refl_x.\]
\end{prop}
\begin{proof}
We are asked to define  dependent functions that takes $x, y :A$ and $p : x = y$ and produce terms
\[ \term{left-inv}(p) : p^{-1} \cdot p = \refl_y \qquad \term{right-inv}(p) : p \cdot p^{-1} = \refl_x.\]
By path induction, it suffices to assume $y$ is $x$ and $p$ is $\refl_x$, in which case we require terms
\[ \term{left-inv}(\refl_x) : \refl_x^{-1} \cdot \refl_x = \refl_x \qquad \term{right-inv}(\refl_x) : \refl_x \cdot \refl_x^{-1} = \refl_x.\]
By the definitions of concatenation and inverses, again both left-hand and right-hand sides are judgementally equal so we take $\term{left-inv}(\refl_x)$ and $\term{right-inv}(\refl_x)$ to be $\refl_{\refl_x}$.
\end{proof}

\section*{September 20: More identity types}

\subsection*{Types as \texorpdfstring{$\infty$}{infinity}-groupoids}

Martin-L\"{o}f's rules for the identity types date from a 1975 paper ``An Intuitionistic Theory of Types.'' In the following two decades, there was a conjecture that went by the name ``uniqueness of identity proofs" that for any $x,y : A$, $p, q  : x =_A y$, the type $p =_{x=_A y} q$ is inhabited, meaning that it's possible to construct an identification between $p$ and $q$. In 1994, Martin Hofmann and Thomas Streicher constructed a model of Martin-L\"{o}f's dependent type theory in the category of groupoids that refutes uniqueness of identity proofs.\footnote{The technical details of what exactly it means to ``construct a model of type theory'' are quite elaborate and would be interesting to explore as a final project.}

In the Hofmann-Streicher model, types $A$ correspond to \emph{groupoids} and terms $x, y : A$ correspond to \emph{objects} in the groupoid. An identification $p : x = y$ corresponds to a(n iso)morphism $p : x \to y$ in the groupoid, while an identification between identifications exists if and only if $p$ and $q$ define the same morphism. Since there are groupoids with multiple distinct morphisms between a fixed pair of objects, we see that it is not always the case that $p=_{x=_A y} q$. Following Hofmann-Streicher, it made sense to start viewing types as more akin to groupoids than to sets. The proofs of symmetry and transitivity for identity types are more accurately described as inverses and concatenation operations in a groupoid. As we've seen, these satisfy various associativity, unit, and inverse laws---up to identification at least---as required by a groupoid.

But that last caveat is important. We've shown that for any type $A$, its identity types $x,y :A \vdash x=_A y \univ$ give it something like the structure of a groupoid. But for each $x,y :A$, $x=_A y$ is also a type, so \emph{its} identity types $p,q: x=_A y \vdash p =_{x=_A y}q \univ$ give $x=_A y$ its own groupoid structure. And the higher identity types, $\alpha, \beta : p =_{x=_A y}q  \vdash \alpha= \beta \univ$ give $p =_{x=_A y}q$ its own groupoid structure and so on. So a modern point of view is that the types in Martin-L\"{o}f's dependent type theory should be thought of as $\infty$-\emph{groupoids}.

If $A$ is an $\infty$-groupoid, its terms $x :A$ might be called \textbf{points} and its identifications $p : x =_A y$ might be called \textbf{paths}. This explains the modern name ``path induction'' for the induction principle for identity types. These ideas are at the heart of the homotopical interpretation of type theory, about more which later.

\subsection*{The uniqueness of \texorpdfstring{$\refl$}{refl}}

The definition of the identity types says that the family of types $a =x$ indexed by $x : A$ is inductively generated by the term $\refl_a : a = a$. It does \emph{not} say that the type $a =a$ is inductively generated by $a : A$. In particular, we cannot apply path induction to prove that $p = \refl_a$ for any $p : a = a$ because in this case neither endpoint of the identity type is free. 

There is a sense however in which the reflexivity term is unique:

\begin{prop} For any type $A$ and $a : A$, $(a, \refl_a)$ is the unique term of the type $\Sigma_{x : A} a =x$. That is, for any $z : \Sigma_{x :A} a =x$, there is an identification $(a, \refl_a) = z$.
\end{prop}
\begin{proof} We're trying to define a dependent function that takes $z : \Sigma_{x :A} a =x$ and gives a term in the identity type $(a,\refl_a) =_{\Sigma_{x :A} a =x} z$. By $\Sigma$-induction it suffices to assume $z$ is a pair $(x,p)$ where $x :A$ and $p : a =x$ and construct an identification $(a, \refl_a) =_{\Sigma_{x :A} a =x} (x,p)$. So now we're trying to define a dependent function that takes $x :A$ and $p : a =x$ and constructs an identification $(a, \refl_a) =_{\Sigma_{x :A} a =x} (x,p)$. By path induction, it suffices to assume $x$ is $a$ and $p$ is $\refl_a$. But now we can use reflexivity to show that $(a, \refl_a) = (a, \refl_a)$.
\end{proof}

In terminology to be introduced later, this result says that the type $\Sigma_{x : A} a =x$ is \textbf{contractible} with the term  $(a, \refl_a)$ serving as its \textbf{center of contraction}.


\subsection*{The action of paths on functions}

The structural rules of type theory guarantee that any function (and indeed any construction in type theory) preserve definitional equality. We now show that in addition every function preserves identifications.

\begin{prop} Let $f \colon A \to B$. There is an operation that defines the \textbf{action on paths} of $f$
\[ \ap_f : \Pi_{x,y :A} (x=y) \to (f(x) = f(y))\]
that satisfies the coherence conditions
\[ \apcoh{id}_A : \Pi_{x,y:A} \Pi_{p : x= y} p = \ap_{\id_A}(p)\]
\[ \apcoh{comp}(f,g) : \Pi_{x,y:A} \Pi_{p: x=y} \ap_g(\ap_f(p))= \ap_{g\circ f}(p).\]
\end{prop}
\begin{proof}
By path induction to define $\ap_f(p) : f(x)=f(y)$ it suffices to assume $y$ is $x$ and $p$ is $\refl_x$. We may then define $\ap_f(\refl_x) \coloneq \refl_{f(x)} : f(x) = f(x)$.

Next to define $\apcoh{id}_A$ it similarly suffices to suppose $y$ is $x$ and $p$ is $\refl_x$. Since $\ap_{\id_A}(\refl_x)\doteq \refl_x$, we may define $\apcoh{id}_A(\refl_x) \coloneq \refl_{\refl_x} : \refl_x = \refl_x$.

Finally, to define $\apcoh{comp}(f,g)$, by path induction we may again assume $y$ is $x$ and $p$ is $\refl_x$. Since both $\ap_g(\ap_f(\refl_x))$ and $\ap_{g \circ f}(\refl_x)$ are defined to be $\refl_{g(f(x))}$ we may define $\apcoh{comp}(f,g)(\refl_x)$ to be $\refl_{\refl_{g(f(x))}}$.
\end{proof}

If the types $A$ and $B$ are thought of as $\infty$-groupoids, then $f \colon A \to B$ can be thought of as a functor of $\infty$-groupoids in a sense hinted at by the following lemma.

\begin{lem} For $f \colon A \to B$ there are identifications
\begin{align*}
\apcoh{refl}(f,x) &: \ap_f (\refl_x) = \refl_{f(x)} \\
\apcoh{inv}(f,p) &: \ap_f (p^{-1}) = \ap_f(p)^{-1} \\
\apcoh{concat}(f,p,q) &: \ap_f(p \cdot q) = \ap_f(p) \cdot \ap_f(q)
\end{align*}
for every $p : x= y$ and $q: y = z$.
\end{lem}
\begin{proof}
For the first coherence, there is a definitional equality $\ap_f (\refl_x) \doteq \refl_{f(x)}$ so we take $\apcoh{refl}(f,x) \coloneq \refl_{\refl_{f(x)}}$. 

We define $\apcoh{inv}(f,p)$ by path induction on $p$ by defining $\apcoh{inv}(f,\refl_x) \coloneq \refl_{\refl_{f(x)}}$.

Similarly, we define $\apcoh{concat}(f,p,q)$ by path induction on $p$ (since concat was defined by path induction on $p$) by defining $\apcoh{concat}(f,\refl_x,q)$ to be $\refl_{\ap_f(q)}$.
\end{proof}

\subsection*{Transport}

The term $\ap_f$ defines the action of a non-dependent function $f \colon A \to B$ on paths in $A$. It's natural to ask whether a dependent function $f : \Pi_{z:A}B(z)$ also induces an action on paths. There's a challenge here, though. If $x,y : A$ are terms belonging to the base type, then we can form the type $x=_A y$ to ask whether they are identifiable. But the terms $f(x) : B(x)$ and $f(y) : B(y)$  belong to different types and are not identifiable. But nevertheless if there is  path $p : x = y$ identifying $y$ with $x$ intuition suggests there should be some way to compare $f(y)$ to $f(x)$.

To achieve this, we must construct a different sort of action of paths function first. This is called the  \textbf{transport} function for dependent types $x :A \vdash B(x) \univ$ that, given an identification $p : x = y$ in the base type, can be used to transport any term in $B(x)$ to a term in $B(y)$.

\begin{prop} For any type family $x : A \vdash B(x) \univ$, there is a \textbf{transport operation}
\[ \tr_B : \Pi_{x,y :A} (x=y) \to (B(x) \to B(y)).\]
\end{prop}
\begin{proof}
By path induction it suffices to define $\tr_B(\refl_x)) \coloneq \id_{B(x)}$.
\end{proof}

As an application of transport we can now defined the action on paths of a dependent function.

\begin{prop} For any dependent function $f : \Pi_{z: A} B(z)$ and identification $p : x=_A y$ there is a path
\[ \apd_f(p) : \tr_B(p, f(x)) =_{B(y)} f(y).\]
\end{prop}
\begin{proof}
The function
 \[ \lambda x . \lambda y. \lambda p. \apd_f(p) : \Pi_{x,y:A} \Pi_{p : x=y} \tr_B(p, f(x)) =_{B(y)} f(y)\]
 may be defined by path induction on $p$. It suffices to construct a path
 \[ \lambda x . \apd_f(\refl_x) : \Pi_{x :A} \tr_B(\refl_x,f(x)) =_{B(x)} f(x).\]
Since  $\tr_B(\refl_x),f(x)) \doteq f(x)$ we may defined $\apd_f(\refl_x) \coloneq \refl_{f(x)}$.
\end{proof}

\subsection*{The laws of addition on $\bN$}

Recall that we defined the addition of natural numbers in such a way that
\[ m+ 0 \doteq m \qquad m+ \suc(n) \doteq \suc(m+n)\]
by induction on the second variable. With this definition, these are the only definitional equalities. However, it is possible to produce identifications proving the other commutative monoid axioms.

\begin{lem} For any $n : \bN$ there are identifications
\[\term{left-unit-law-add}_\bN(n) : 0 + n = n \qquad \term{right-unit-law-add}_\bN(n) : n+0=n.\]
\end{lem}
\begin{proof}
The second of these can be taken to be $\refl_n$ but the first is more complicated. We define $\term{left-unit-law-add}_\bN(n)$ by induction on $n : \bN$. When $n = 0$, $0+0=0$ holds by reflexivity. 

Our final goal is to show $0+\suc(n) = \suc(n)$, for which it suffices to construct an identification \[ \suc(0+n) = \suc(n)\]
by the definition of addition. We may assume we have an identification $p : 0 + n = n$. Thus, we can use the action on paths of $\suc : \bN \to \bN$  to obtain a term $\ap_{\suc}(p) : \suc(0+n) = \suc(n)$.
\end{proof}

\begin{prop} For any $m,n : \bN$ there are identifications
\begin{align*} \term{left-successor-law-add}_\bN(m,n) &: \suc(m) + n = \suc(m+n) \\
\term{right-sucessor-law-add}_\bN(m,n) &= m+ \suc(n) = \suc(m+n)
\end{align*}
\end{prop}
\begin{proof}
Again the second identification holds judgmentally so we  define \[\term{right-sucessor-law-add}_\bN(m,n) \coloneq \refl_{\suc(m+n)}.\] We construct the former using induction on $n \in \bN$. The base case $\suc(m)+0 = \suc(m+0)$ holds by $\refl_{\suc(m)}$. For the inductive step we assume we have an identification $p : \suc(m)+n = \suc(m+n)$. Our goal is to show that $\suc(m)+\suc(n) = \suc(m+\suc(n))$. By action of paths of $\suc : \bN \to \bN$ we obtain a term
\[ \ap_{\suc}(p) : \suc(\suc(m)+n) = \suc(\suc(m+n))\] but here the left hand side is judgmentally equal to $\suc(m)+\suc(n)$ while the right hand side is judgmentally equal to $\suc(m+ \suc(n))$.
\end{proof}  

\begin{prop}[associativity] For all $k,m,n : \bN$,
\[ \term{associative-add}_\bN(k,m,n) : (m+n)+k = m+(n+k).\]
\end{prop}
\begin{proof}
We construct $\term{associative-add}_\bN(k,m,n)$ by induction on $n$. In the base case we have
\[ (k+m)+0 \doteq k+m \doteq k + (m+0),\] so we define $\term{associative-add}_\bN(k,m,0) \coloneq \refl_{m+n}$.

For the inductive step let $p : (k+m)+n = k+(m+n)$. We then have
\[ \ap_{\suc}(p) : \suc((k+m)+n) = \suc(k+(m+n)).\]
We have $\suc((k+m)+n) \doteq (k+m)+\suc(n)$ and $\suc(k+(m+n)) \doteq k + \suc(m+n) \doteq k + (m + \suc(n))$ so this term is the term we wanted.
\end{proof}


\begin{prop}[commutativity] For all $m,n : \bN$,
\[ \term{commutative-add}_\bN(m,n) : m+n = n+m.\]
\end{prop}
\begin{proof} By induction on $m$ we have to show $0+n = n+0$, which holds by the unit laws for $n$. Then we may assume $p : m+n = n+m$ and must show $\suc(m)+n= n + \suc(m)$. We have
\[ \ap_{\suc}(p) : \suc(m+n) = \suc(n+m).\] We then concatenate this path with the paths $ \term{left-successor-law-add}_\bN(m,n)$ and $\term{right-successor-law-add}_\bN(n,m)$ to obtain the identification we want. 
\end{proof}

\section*{September 22: Universes}

Recall that in Martin-L\"{o}f's dependent type theory, $\bN$ was defined as the inductive type freely generated by a term $0_\bN : \bN$ and a function $\suc :\bN \to \bN$. The corresponding induction principle gives a strengthened version of the Dedekind-Peano principle of mathematical induction, but two of the traditional axioms---namely that $0_\bN$ is not a successor and $\suc$ is injective---are missing. Using our type forming operations, we can define the types that assert those axioms:
\[ \Pi_{n : \bN} (n = 0_\bN) \to \emptyset \qquad \Pi_{n,m : \bN} (\suc(n) = \suc(m)) \to (n = m)\]
but we don't yet have the tools needed to construct terms in those types. Type theoretic \emph{universes} will enable us to construct terms in these types and prove many other things besides.

Informally, a universe $\UU$ can be thought of as a ``type whose terms are types.'' More precisely, a universe is a type $\UU$ together with a type family $X : \UU \vdash \sT(X)$ called the \emph{universal type family}. We think of the term $X$ as an \emph{encoding} of the type $\sT(X)$ though its common to conflate these notions notationally, writing ``$X$'' for both the encoding and the type.

Universes are assumed to be closed under all the type constructors in a sense to be made precise below. To avoid a famous inconsistency, however, we do not assume that the universe is contained in itself. One way to think about this is that $\UU$ is the type of ``small'' types, but $\UU$ itself is not ``small.''

In the presence of a universe $\UU$, a family of small types $x : A \vdash B(x) \univ$ over a type $A$ can be encoded by a function $B \colon A \to \UU$ defined by sending the term $x$ to the encoding of the type $B(x)$.\footnote{This is already how we have been defining type families in \texttt{agda}.} In particular, if $A$ is an inductive type, freely generated by some finite list of constructors, then \emph{type families} over $A$---not just dependent functions over $A$---can be defined inductively by specifying types for each of the constructors. We will see examples of this soon.

\subsection*{Type theoretic universes}

\begin{defn} A \textbf{universe} is a type $\UU$ in the empty context equipped with a type family $X : \UU \vdash \sT(X) \univ$ over $\UU$ called the \textbf{universal family of types} that is closed under the type forming operations in the sense that it is equipped with the following structure:
\begin{enumerate}
\item $\UU$ contains terms $\check{\emptyset}$, $\check{\1}$, $\check{\bN}$ that satisfy the judgmental equalities
\[ \sT(\check{\emptyset}) \doteq \emptyset, \quad \sT(\check{\1}) \doteq \1, \quad \sT(\check{\bN}) \doteq \bN.\]
\item $\UU$ is closed under coproducts in the sense that it comes equipped with a function
\[ \check{+} \colon \UU \to \UU \to \UU\] that satisfies $\sT(X\check{+}Y) \doteq \sT(X) + \sT(Y)$.
\item $\UU$ is closed under $\Pi$-types in the sense that it comes equipped with a function
\[ \check{\Pi} \colon \Pi_{X: \UU} (\sT(X) \to \UU) \to \UU\] satisfying
\[ \sT(\check{\Pi}(X,P)) \doteq \Pi_{x : \sT(X)} \sT(P(x))\]
for all $X : \UU$ and $P \colon \sT(X) \to \UU$.
\item $\UU$ is closed under $\Sigma$-types in the sense that it comes equipped with a function
\[ \check{\Sigma} \colon \Pi_{X: \UU} (\sT(X) \to \UU) \to \UU\] satisfying
\[ \sT(\check{\Sigma}(X,P)) \doteq \Sigma_{x : \sT(X)} \sT(P(x))\]
for all $X : \UU$ and $P \colon \sT(X) \to \UU$.
\item $\UU$ is closed under identity types in the sense that it comes equipped with a function
\[ \check{\Id} : \Pi_{X : \UU} \sT(X) \to \sT(X) \to \UU\]
satisfying
\[ \sT(\check{\Id}(X,x,y)) \doteq (x = y)\]
for all $X: \UU$ and $x,y : \sT(X)$.
\end{enumerate}
\end{defn} 

\begin{defn} Given a universe $\UU$, we say a type $A$ in context $\Gamma$ is \textbf{small} if it occurs in the universe: i.e., if it comes equipped with a term $\check{A} : \UU$ in context $\Gamma$ for which the judgment
\[ \Gamma \vdash \sT(\check{A}) \doteq A \univ\]
holds. 
\end{defn}

When $A$ is a small type, it's common to write $A$ for both $\check{A}$ and $\sT(A)$. So by $A : \UU$ we mean that $A$ is a small type.

\subsection*{Assuming enough universes}

Most of the time it's sufficient to assume just one universe $\UU$. But on occasion, it is useful to assume that $\UU$ itself is a type in some universe. 

\begin{post} We assume that there are \textbf{enough universes}, i.e., that for every finite list of types in context
\[ \Gamma_1 \vdash A_1 \univ \quad \cdots \quad \Gamma_n \vdash A_n \univ\]
there is a universe $\UU$ that contains each $A_i$ in the sense that $\UU$ has terms
\[ \Gamma_i \vdash \check{A}_i : \UU\] for which $\Gamma_i \vdash \sT(\check{A}_i) \doteq A_i \univ$ holds. 
\end{post}

With this assumption it's rarely necessary to work with more than one universe at the same time. 

As a consequence of our postulate that there exist enough universes, we obtain specific universes:\footnote{In \texttt{agda}, this structure is formalized in the file Agda.Primitive.}

\begin{defn} The \textbf{base universe} $\UU_0$ is obtained by applying the postulate to the empty list of types in context.
\end{defn}

\begin{defn} The \textbf{successor universe} of any universe $\UU$ is the universe $\UU^+$ obtained from the finite list
\[ \vdash \UU \univ \quad X: \UU \vdash \sT(X) \univ\]
\end{defn}
Thus the successor universe contains both $\UU$ and any type in $\UU$. 

\begin{defn} The \textbf{join} of two universes $\UU$ and $\mathcal{V}$ is the universe $\UU \sqcup \mathcal{V}$ obtained by applying the postulate to the type families
\[ X : \UU \vdash \sT_\UU(X) \univ \qquad Y : \mathcal{V} \vdash \sT_{\mathcal{V}}(Y) \univ\]
\end{defn}

\subsection*{Observational equality on \texorpdfstring{$\bN$}{N}}

To illustrate what universes are for, we define a type family $m : \bN, n : \bN \vdash \Eq_\bN(m,n) \univ$ that we call \textbf{observational equality} on $\bN$. Because type families can now be thought of as functions $\Eq_\bN : \bN \to \bN \to \UU$ we can use the induction principle of $\bN$ to define this type family.  We'll then prove that $\Eq_\bN$ is \textbf{logically equivalent} to the identity type family; in fact, we'll later see that these types are \textbf{equivalent}, once we know what that means. The advantage of the type family $\Eq_\bN$ is that it's characterized more explicitly, so this will help us prove theorems about the identity type family over the natural numbers.

\begin{defn} We define \textbf{observational equality} of $\bN$ as the type family $\Eq_\bN : \bN \to \bN \to \UU$ satisfying
\[ \Eq_\bN(0_\bN,0_\bN) \doteq \1 \quad \Eq_\bN(\suc(n),0_\bN) \doteq \emptyset \quad \Eq_\bN(0,\suc(n)) \doteq \emptyset \quad \Eq_\bN(\suc(m), \suc(n)) \doteq \Eq_\bN(m,n).\]
\end{defn}

\begin{lem} Observational equality on $\bN$ is reflexive:
\[ \refl-\Eq_\bN : \Pi_{n : \bN} \Eq_\bN(n,n).\]
\end{lem}
\begin{proof}
We define $\refl-\Eq_\bN$ by induction by $\refl-\Eq_\bN(0_\bN) \coloneq \star$ and $\refl-\Eq_\bN(\suc(n)) \coloneq \refl-\Eq_\bN(n)$.
\end{proof}

\begin{prop} For any $m,n : \bN$, the types $\Eq_\bN(m,n)$ and $(m=n)$ are \textbf{logically equivalent}: that is there are functions
\[ (m = n) \to \Eq_\bN(m,n) \quad \text{and} \quad \Eq_\bN(m,n) \to (m=n).\]
\end{prop}
\begin{proof}
By path induction, there is a function $\term{id-to-eq} : \Pi_{m,n: \bN} (m =n) \to \Eq_\bN(m,n)$ defined by $\term{id-to-eq}(n,\refl_n) \coloneq \refl-\Eq_\bN(n)$. 

For the converse, we define a function $\term{eq-to-id} : \Pi_{m,n : \bN} \Eq_\bN(m,n) \to (m=n)$ by induction on $m$ and $n$. We define $\term{eq-to-id}(0_\bN,0_\bN) : \Eq_\bN(0_\bN,0_\bN) \to (0_\bN = 0_\bN)$, by induction on $\Eq_\bN(0_\bN,0_\bN) \doteq \1$ to be the function that sends $\star : \1$ to $\refl_{0_\bN} : 0_\bN = 0_\bN$. We define the functions $\term{eq-to-id}(\suc(n),0_\bN)$ and $\term{eq-to-id}(0_\bN,\suc(n))$ using $\term{ex-falso}$, since both of these are maps out of the empty type. Finally, to define $\term{eq-to-id}(\suc(m),\suc(n))$ we may use a function $f : \Eq_\bN(m,n) \to (m=n)$, in which case, $\term{eq-to-id}(\suc(m),\suc(n))$  is defined to be the composite function
\[ \Eq_\bN(\suc(m),\suc(n)) \xrightarrow{\id} \Eq(m,n) \xrightarrow{f} (m=n) \xrightarrow{\ap_{\suc}} (\suc(m)=\suc(n)).\]
\end{proof}

\begin{ntn} For types $A$ and $B$, we write $A \leftrightarrow B$ as an abbreviation for the type
\[ (A \to B) \times (B \to A).\]
\end{ntn}

Thus the logical equivalence defines a term in the type
\[ \Pi_{m,n : \bN} \Eq_\bN(m,n) \leftrightarrow (m=n).\]

\subsection*{Peano's axioms}

\begin{thm} For any $m,n : \bN$ we have
\[ (m=n) \leftrightarrow (\suc(m) = \suc(n))\]
\end{thm}
\begin{proof}
The action of paths of the successor function proves the forwards implication
\[ \ap_{\suc} : (m=n) \to (\suc(m) = \suc(n))\]
The direction of interest is the converse which proves that successor is injective.

Using the logical equivalences $(m=n) \leftrightarrow \Eq_\bN(m,n)$ we define the reverse implication to be the composite
\[ (\suc(m) = \suc(n)) \xrightarrow{\term{id-to-eq}(\suc(m),\suc(n))} 
\Eq_\bN(\suc(m),\suc(n)) \xrightarrow{\id} \Eq_\bN(m,n) \xrightarrow{\term{eq-to-id}(m,n)} (m=n).\]
\end{proof}

\begin{thm} For any $n : \bN$, $\neg(0_\bN  = \succ_\bN(n))$.
\end{thm}
\begin{proof}
We have a family of maps
\[ \lambda n, \term{id-to-eq}(0_\bN,n) : \Pi_{n : \bN} (0_\bN = n) \to \Eq_\bN(0_\bN,n).\]
Since $\Eq_\bN(0_\bN, \suc(n)) \doteq \emptyset$ we have
\[ \term{id-to-eq}(0_\bN,\suc(n)) : (0_\bN = \suc(n)) \to \emptyset\]
which is precisely the claim.
\end{proof}

\section*{September 27: Modular arithmetic}

Having fully described Martin-L\"{o}f's dependent type theory, we may now start developing some mathematics in it. The fundamental idea used to develop mathematics is something we've already previewed: the Curry-Howard interpretation.

\subsection*{The Curry-Howard interpretation}

The Curry-Howard interpretation is an interpretation of logic into type theory. In type theory, there is no separation between the logical framework and the general theory of collections of mathematical objects the way there is in the more traditional setup with Zermelo-Fraenkel set theory, which is postulated by axioms in first order logic. The idea is that propositions may be expressed as types with proofs of those propositions expressed as terms in those types. For example:

\begin{defn} We say that a natural number $d$ divides a natural number $n$ if there is a term in the type
\[ d \mid n \coloneq \Sigma_{k : \bN} d \cdot k = n \]
defined using the multiplication $\cdot$ on $\bN$, the identity type of $\bN$, and the dependent sum of the type family $k : \bN \vdash d \cdot k = n \univ$.
\end{defn}

Just as existential quantification $(\exists)$ is expressed using $\Sigma$-types, universal quantification $(\forall)$ is expressed using $\Pi$-types. For example, the type
\[ \Pi_{n : \bN} 1 \mid n\]
asserts that every natural number is divisible by 1. The term
\[ \lambda n. (n, \term{left-unit}(n)) : \Pi_{n : \bN} 1 \mid n\]
proves this result.

\begin{prop} Let $d, m,n : \bN$. If $d$ divides any two of $m$, $n$, and $m+n$, then $d$ divides the third.
\end{prop}
\begin{proof}
We prove only that if $d \mid m$ and $d \mid n$ then $d \mid m+n$.
By hypothesis we have terms:
\[ H : \Sigma_{k : \bN} d \cdot k = m \quad \text{and} \quad K : \Sigma_{k : \bN} d \cdot k = n.\]
By $\Sigma$-induction, we may assume that $H$ is given by a pair $(h : \bN, p : d \cdot h = m)$ and $K$ is given by a pair $(k : \bN, q : d \cdot k = n)$. To get a term in $\Sigma_{x : \bN} d \cdot x = m + n$ we may use $x \coloneq h + k$. Our goal is then to define an identification $d \cdot (h + k) = m + n$ which we obtain as a concatenation
\[
\begin{tikzcd} d \cdot (h+ k ) \arrow[r, equals, "\term{dist}"] & d \cdot h + d \cdot k \arrow[r, equals, "\ap_{+d \cdot k}p"] & m + d \cdot k \arrow[r, equals, "\ap_{m+}q"] & m + n
\end{tikzcd}
\]
\end{proof}

We have observed many similarities between the rules of various type constructors and tautologies from logic. For instance, the elimination rule for the non-dependent function type supplies a function
\[ \term{modus-ponens} : A \times (A \to B) \to B.\]
One important difference is that general types may contain multiple terms that cannot be identified: i.e., for which it is possible to prove that $x =_A y \to \emptyset$. Later we'll study the following predicate on types:
\[ \term{is-prop}(A) \coloneq \Pi_{x,y : A} x =_A y\]
which asserts that \emph{if} $A$ has multiple terms (which it may not) those terms can always be identified. This will be the $n=-1$ level of a hierarchy of $n$-types for $n \geq -2$.

\subsection*{The congruence relations on \texorpdfstring{$\bN$}{N}}

The family of identity types can be understood as a type-valued binary relation on a type.

\begin{defn} For a type $A$, a \textbf{typal binary relation} on $A$ is a family of types $x, y : A \vdash R(x,y) \univ$. A binary relation $R$ is 
\begin{itemize}
\item \textbf{reflexive} if it comes with a term $\rho : \Pi_{x :A} R(x,x)$,
\item \textbf{symmetric} if it comes with a term $\sigma : \Pi_{x,y :A} R(x,y) \to R(y,x)$,
\item \textbf{transitive} if it comes with a term $\tau : \Pi_{x,y,z : A}  R(x,y) \to R(y,z) \to R(x,z)$
\end{itemize}
A \textbf{typal equivalence relation} on $A$ is a reflexive, symmetric, and transitive, typal binary relation.
\end{defn}

For instance, for each $k : \bN$ we can define the relation of congruence modulo $k$ by defining a type
\[ x \equiv y \mod k\]
for each $x,y : \bN$ comprised of proofs that $x$ is equivalent to $y$ modulo $k$. Following Gauss, we say that $x$ is equivalent to $y$ mod $k$ if $k$ divides the symmetric difference $\term{dist}_\bN(x,y)$ defined recursively by
\[ \term{dist}_\bN(0,0) \coloneq 0 \quad \term{dist}_\bN(0, y+1) \coloneq y+1 \quad \term{dist}_\bN(x+1,0) \coloneq x+1, \quad \term{dist}_\bN(x+1,y+1) \coloneq \term{dist}_\bN(x,y).\]

\begin{defn} For $k,x,y : \bN$ define
\[ x \equiv y \mod k \coloneq k \mid \term{dist}_\bN(x,y).\]
Note this defines the \emph{type} $x \equiv y \mod k$. A term is then a pair comprised of an $\ell : \bN$ together with an identification $k \cdot \ell = \term{dist}_\bN(x,y)$.
\end{defn}

We leave the following to the course text:

\begin{prop} For each $k$, the typal relation $\equiv \mod k$ is an equivalence relation.
\end{prop}

There are other important relations on $\bN$ that are not-equivalence relations.

\begin{defn} The binary relation $\leq$ on $\bN$ is defined by induction by
  \[ 0 \leq 0 \coloneq \1 \quad 0 \leq n+1 \coloneq \1 \quad n+1 \leq 0 \coloneq \emptyset \quad m+1 \leq n+1 \coloneq m \leq n.\]
  Similarly, the binary relation $<$ is defined by
  \[ 0 < 0 \coloneq \emptyset \quad 0 < n+1 \coloneq \1 \quad n+1 < 0 \coloneq \emptyset \quad m+1 < n+1 \coloneq m < n.\]
  \end{defn}

\subsection*{The standard finite types}

The standard finite sets are classically defined as the sets $\{ n \in \bN \mid n < k\}$, so how do we interpret a subset $\{ x  \in A \mid P(x)\}$ characterized by a predicate in type theory?

In the Curry-Howard interpretation, the predicate $P(x)$ is interpreted as a type family and the type of terms $x$ in $A$ for which $P(x)$ is true is interpreted by the $\Sigma$-type $\Sigma_{x : A} P(x)$. Note for a general type family $P(x)$ it won't necessarily be the case that the map $\pr_1 \colon \Sigma_{x :A} P(x) \to A$ is a monomorphism\footnote{Though this will be the case if each type $P(x)$ is a proposition in the sense alluded to above.} so this construction operates a bit differently than in set theory.

Through this mechanism it is possible to define the classical finite sets as 
\[ \type{Classical-Fin}_k \coloneq \Sigma_{n : \bN}n < k \]
though the standard definition is as follows:

\begin{defn} We define the type family $\type{Fin}$ of \textbf{standard finite types} inductively (using the induction principle of $\bN$ and the universe $\UU$) as follows:
\[ \type{Fin}_0 \coloneq \emptyset, \quad \type{Fin}_{k+1} \coloneq \type{Fin}_k + \1.\]
\end{defn}

Write $i$ for $\inl : \type{Fin}_k \to \type{Fin}_{k+1}$ and $\star$ for the point $\inr(\star) : \type{Fin}_{k+1}$.

By induction we can define functions $\iota_k \colon \type{Fin}_k \to \bN$ for each $k$. When $k=0$ there is nothing to show. To define $\iota_{k+1} \colon \type{Fin}_{k+1} \to \bN$ we can use $\iota_k$  and define $\iota_{k+1}(i(x)) \coloneq \iota_k(x)$ and $\iota_{k+1}(\star)\coloneq k$.

\subsection*{The natural numbers modulo $k+1$}

Given an equivalence relation $\sim$ on a set $A$ the quotient $A_{/\sim}$ comes equipped with a quotient map $q \colon A \to A_{/\sim}$ that satisfies two important properties:
\begin{enumerate}
\item $q$ is \textbf{effective}: $q(x) = q(y)$ if and only if $x \sim y$
\item $q$ is surjective: for all $[z] \in A_{/\sim}$ there is some $z \in A$ so that $q(z) = [z]$.
\end{enumerate}

Both properties can be expressed in type theory, though there are some subtleties.

\begin{defn} In the context of types $A$ and $B$ there is a type family $\type{is-surj} \colon (A \to B) \to \UU$ defined by
\[ \type{is-surj}(f) \coloneq \Pi_{b : B} \Sigma_{a : A} f(a) =_B b.\]
\end{defn}

The subtlety is that this really defines a \emph{split} notion of surjectivity. A term $p$ in $\type{is-surj}(f)$ defines a function that for each term $b : B$ produces a term of $\Sigma_{a : A} f(a) =_B b$. By compositing $p$ with $\pr_1 : \Sigma_{a : A} f(a) =_B b \to A$, we obtain a function $s \colon B \to A$. By composing $p$ with $\pr_2 : \Sigma_{a : A} f(s(b)) =_B b$ we also obtain a proof that $s$ is a \textbf{section} of $f$. Thus surjective functions in homotopy type theory are really \textbf{split} surjective functions.

Our next challenge is to define the quotient maps $[-]_{k} \colon \bN \to \type{Fin}_{k}$ that compute the remainder modulo $k$. Our strategy will be to define this function by induction on $n : \bN$. The idea is that the term $0_\bN : \bN$ should get sent to some $0$ while successors in $\bN$ should be sent to successors in $\type{Fin}_k$, taken in the cyclic order. We define these auxiliary structures first.

\begin{defn} We define $\term{zero}_k : \type{Fin}_{k+1}$ recursively by
\[ \term{zero}_0 \coloneq \star \quad \term{zero}_{k+1} \coloneq i(\term{zero}_k).\]

We then define $\term{skip-zero}_k : \type{Fin}_k \to \type{Fin}_{k+1}$ recursively by
\[ \term{skip-zero}_{k+1}(i(x)) \coloneq i(\term{skip-zero}_k(x)) \quad \term{skip-zero}_{k+1}(\star) \coloneq \star.\]

Finally, we define $\term{succ}_k : \type{Fin}_k \to \type{Fin}_k$ recursively by
\[ \term{succ}_{k+1}(i(x)) \coloneq \term{skip-zero}_k(x) \qquad \term{succ}_{k+1}(\star) \coloneq \term{zero}_k.\]
\end{defn}


\begin{defn} For any $k : \bN$ define $[-]_{k+1} \colon \bN \to \type{Fin}_{k+1}$ by
\[ [0]_{k+1} \coloneq 0 \quad \text{and} \quad [n+1]_{k+1} \coloneq \term{succ}_{k+1}[n]_{k+1}.\]
\end{defn}

The text goes on to show that 
\begin{itemize}
\item $n \equiv \iota [n]_{k} \mod k$ for all $n$ and $k$,
\item $[n]_k = [m]_k$ if and only of $n \equiv m \mod k$,
\item and the map $[-]_k \colon \bN \to \type{Fin}_k$ is split surjective.
\end{itemize}

Then it is possible to use this quotient map to define the cyclic group structure on $\type{Fin}_k$.

\section*{September 29: Decidability in elementary number theory}

In constructive mathematics it is not possible to prove the law of excluded middle: namely that $P \vee \neg P$ for an arbitrary proposition $P$. Similarly in type theory, it is not possible to construct a term of type $A + \neg A$ for arbitrary $A$. But certain types do come with such terms.

\subsection*{Decidability}

\begin{defn} A type $A$ is \textbf{decidable} if it comes equipped with an element of type
\[ \type{is-decidable}(A) \coloneq A + \neg A.\]
A type family $P \colon A \to \UU$ is \textbf{decidable} if $P(a)$ is decidable for every $a : A$.
\end{defn}

\begin{ex}
The primary way to show that $A$ is decidable is either to provide a term $a : A$ or provide a function $na : A \to \emptyset$. In particular $\1$ is decidable since we have $\inl(\star) : \type{is-decidable}(\1)$. Similarly $\emptyset$ is decidable since we have $\inr(\id) : \type{is-decidable}(\emptyset)$.
\end{ex}

\begin{ex} Since the type families $n, m: \bN \vdash n \leq m \univ$ and $n, m : \bN \vdash n < m \univ$ were defined by induction from the types $\emptyset$ and $\1$, it follows that these type families are decidable.
\end{ex}

\begin{rmk}
If $A$ and $B$ are decidable then so are $A+B$, $A \times B$, and $A \to B$. Proofs use case analysis over the coproduct types $A + \neg A$ and $B + \neg B$. 
\end{rmk}

\begin{defn} A type $A$ \textbf{has decidable equality} if the identity type $x=_Ay$ is decidable for every $x, y : A$. Thus
\[ \type{has-decidable-eq}(A) \coloneq \Pi_{x,y: A} \type{is-decidable}(x=_Ay).\]
\end{defn}

\begin{lem} Suppose $A$ and $B$ are types so that $A \leftrightarrow B$. Then $A$ is decidable if and only if $B$ is decidable.
\end{lem}
\begin{proof}
A proof of $A \leftrightarrow B$ supplies functions $f \colon A \to B$ and $g \colon B \to A$. Using the contrapositive function we obtain $\term{contrapositive}(f) : \neg B \to \neg A$ and $\term{contrapositive}(g) \colon \neg A \to \neg B$. We therefore have functions
\[ f + \term{contrapositive}(g) \colon A + \neg A \to B + \neg B \qquad g + \term{contrapositive}(f) : B + \neg B \to A + \neg A,\]
proving the logical equivalence of $\type{is-decidable}(A)$ and $\type{is-decidable}(B)$. In particular, if either type is inhabited, both must be. 
\end{proof}

\begin{cor} $\bN$ has decidable equality.
\end{cor}
\begin{proof}
We have shown that the identity types of $\bN$ are logically equivalent to the observational equality types, which were defined to be $\1$ or $\emptyset$. As both types are decidable, the identity types of $\bN$ must be as well.
\end{proof}

\begin{rmk} We will prove later that if a type has decidable equality then it must be a \textbf{set} in a technical sense to be introduced. Even so, not all sets have decidable equality unless one assumes that the law of excluded middle is true for all propositions.
\end{rmk}

\subsection*{Case analysis}

Suppose you'd like to define a function by case analysis such as $\term{collatz} : \bN \to \bN$
\[ \term{collatz}(n) \coloneq \begin{cases} n/2 & n\ \text{is~odd} \\ 2n+1 & n\ \text{is~even} \end{cases}\]
To justify this sort of case analysis we use a term
\[ d : \Pi_{n : \bN} \type{is-decidable} (2 \mid n)\]
whose construction we skipped. Note that $2 \mid n$ and $\neg(2 \mid n)$ cannot both hold because if so we could evaluate the function $\term{odd}(n) : \neg(2 \mid n)$ at the term $\term{even}(n) : 2 \mid n$ to get a contradiction. So this $d$ can be thought of as a proof that for all $n : \bN$, $n$ is odd or $n$ is even (but not both).

This puts us into the following abstract setup. Our goal is to define a function $c : \Pi_{x :A} C(x)$, namely the function $\term{collatz} : \bN \to \bN$. We already have a function $d : \Pi_{x :A} B(x)$, namely $d : \Pi_{n : \bN} \type{is-decidable}(2 \mid n)$. So it suffices to define a function $h : \Pi_{x:A} B(x) \to C(x)$ because then we can define $c(x) \coloneq h(x,d(x))$. In this case this means we need a function
\[ h : \Pi_{n : \bN} \type{is-decidable} (2 \mid n) \to \bN\] which we can now define by cases from
\[ h\term{-even}(n) \coloneq \lambda n. n/2 \colon (2 \mid n) \to \bN \quad \text{and} \quad h\term{-odd}(n) \coloneq \lambda n. 3n+1 : \neg(2 \mid n) \to \bN.\]
There is something called the ``with-abstraction'' that gives a concise syntax for functions defined in this manner.

\subsection*{The well-ordering principle of $\bN$}

The traditional well-ordering principle is about subsets of $\bN$, or equivalently, about predicates on $\bN$. In type theory, we replace these by decidable type families over $\bN$.

\begin{defn} Let $P \colon \bN \to \UU$. A number $n : \bN$ is a \textbf{lower bound} for $P$ if it comes equipped with a term in the type
  \[ \type{is-lower-bound}_{P}(n) \coloneq \Pi_{k : \bN} P(k) \to n \leq k\]
  Similarly,
  \[ \type{is-upper-bound}_{P}(n) \coloneq \Pi_{k : \bN} P(k) \to k \leq n\]
  \end{defn}

  \begin{thm}[well-ordering principle]
    Let $P$ be a decidable family over $\bN$ with $d$ a witness that $P$ is decidable. Then there is a function
    \[ w(P,d) : \left( \Sigma_{n : \bN}P(n)\right) \to \left( \Sigma_{m : \bN}P(m) \times \type{is-lower-bound}_P(m)\right).\]
  \end{thm}
  In other words, if $P(n)$ is inhabited for some $n$ then there is a smallest $m : \bN$ so that $P(m)$ is inhabited.

  \begin{proof}
    We will show that for any decidable type family $Q : \bN \to \UU$ that there is a function
    \[ Q(n) \to \Sigma_{m : \bN}Q(m) \times \type{is-lower-bound}_Q(m)
    \]
    by induction on $n$. When $n=0$ we can use $m=0$ since 0 is always a lower bound. For the inductive step we may assume we have the displayed function for every type family $Q$ and consider a decidable type family $Q$ with a term $q : Q(n+1)$. Our goal is to construct a term in the type
    \[ \Sigma_{m : \bN}Q(m) \times \type{is-lower-bound}_{Q}(m)\]. Since $Q(0)$ is decidable it suffices to construct a function
    \[ Q(0) + \neg Q(0) \to  \Sigma_{m : \bN}Q(m) \times \type{is-lower-bound}_{Q}m
    \]
    so we can do a case analysis. If we have $Q(0)$ then it follows immediately that $m=0$ is minimal.  If $\neq Q(0)$, then we can consider the decidable family $Q' \colon \bN \to \UU$ defined by $Q(n) \coloneq Q'(\suc(n))$. Since $q : Q'(n)$ we get a minimal element $m$ for $Q'$ by the inductive hypothesis. But since $Q(0)$ is assumed to be false then $m+1$ is the minimal element for $Q$.   
    \end{proof}
    
  

\subsection*{The infinitude of primes}  

For natural numbers $d$ and $n$ we say $d$ is a \textbf{proper divisor} of $n$ if it comes with a term in the type
\[ \type{is-proper-divisor}(n,d) \coloneq (d \neq n) \times (d \mid n)\]
With this notation we can say a natural number $n$ is \textbf{prime} if it comes with a term in the type
\[ \type{is-prime}(n) \coloneq \Pi_{x : \bN}\type{is-proper-divisor}(n,x) \leftrightarrow (x=1)\]

The proof of the infinitude of primes proceeds by constructing a prime number larger than $n$ for any $n : \bN$. So we can consider the type family for $n,m : \bN$
\[ R(n,m) \coloneq (n < m) \times \Pi_{x : \bN} (x \leq n) \to (x \mid m) \to (x=1)\]
of pairs so that $m$ is greater than $n$ and $m$ is relatively prime to all numbers $x \leq n$. Since $n!+1$ satisfies these properties for any $n$, the type family $m \mapsto R(n,m)$ in context $n : \bN$ is inhabited. Thus, by the well-ordering principle, it has a least element $p$ and this $p$ must be prime.

Using the results we skipped it's possible to prove:

\begin{lem} The type $R(n,m)$ is decidable for each $n, m : \bN$.
\end{lem}

We leave it to the reader to verify that $R(n,n!+1)$ is inhabited. Using these ingredients, we prove the infinitude of primes in the following form:

\begin{thm} For each $n$, there is a prime number $p : \bN$ so that $n < p$.
  \end{thm}
  \begin{proof}
    It suffices to show this for each non-zero $n$ since the case $n=0$ follows. So let $n$ be a non-zero natural number.

    Since the type $R(n,m)$ is decidable for each $m$ and since $R(n,n!+1)$ holds by the well-ordering principle there is a minimal $p : \bN$ so that $R(n,p)$. We will show that $p$ is prime by constructing a term in the type
    \[ \type{is-prime}(p) \coloneq (p \neq 1) \times \Pi_{x: \bN} \type{is-proper-divisor}(p,x) \to (x = 1).\]
    By construction, $n < p$ and $n$ is non-zero so $p \neq 1$. So now let $x$ be a proper divisor of $p$. Since $R(n,p)$ holds by construction we can show that $x=1$ by proving that $x \leq n$. Since $p$ is non-zero and $x \mid p$ we must have $x < p$. By minimality of $p$ it follows that $\neg R(n,x)$ holds. However, any divisor of $x$ must also divide $p$ by transitivity of divisibility, so \[
      \Pi_{y : \bN} (y \leq n) \to (y \mid x) \to (y=1).\]
    Since \[\neg R(n,x) \doteq \neg \left((n < x) \times \Pi_{y : \bN} (y \leq n) \to (y \mid x) \to (y=1) \right)\]
         holds we conclude that $\neg(n < x)$. On account of the logical equivalence $\neg(n < x ) \leftrightarrow (x \leq n)$, it follows that $x \leq n$.
  \end{proof}
 
  
\part{The Univalent Foundations of Mathematics}

The univalent foundations build on Martin-L\"{o}f's dependent type theory by adding a few new axioms inspired by the interpretation of types as $\infty$-groupoids or spaces rather than sets. One of these axioms, Voevodsky's \emph{univalence axiom}, is inconsistent with the interpretation of types as sets. When we meet the hierarchy of truncation levels, we'll see that some types behave like types and some types behave like sets while others have non-trivial higher-dimensional structures. 

\section*{October 4: Equivalences}

Recall the notion of \textbf{logical equivalence} between types $A$ and $B$
\[ A \leftrightarrow B \coloneq (A \to B) \times (B \to A).\]

For instance, you proved on your homework that $\bool$ and $\1+\1$ are logically equivalent by constructing functions
\[
\begin{tikzcd}[row sep=tiny, column sep=large] \bool \arrow[r, "{\term{bool-to-1+1}}"] & \1+\1 & \1+\1 \arrow[r, "\term{1+1-to-bool}"] & \bool \\
\true \arrow[r, mapsto] & \inl(\star) & \inl(\star) \arrow[r, mapsto] & \true \\ \false \arrow[r, mapsto] & \inr(\star) & \inr(\star) \arrow[r, mapsto] & \bool
\end{tikzcd}
\]
These inverse implications are obviously related. Our next goal is to develop language to explain how.

\subsection*{Homotopies}

Surprisingly, we are not able, in dependent type theory, to construct identifications between functions $\term{1+1-to-bool} \circ \term{bool-to-1+1}$ and $\id_\bool$ or between $\suc$ and $\lambda n, n+1$. We can, however, construct \emph{pointwise identifications} between these pairs of functions, which in homotopy type theory are commonly called \textbf{homotopies}:

\begin{defn} Let $f,g : \Pi_{x:A} B(x)$. The type $f\sim g$ of \textbf{homotopies} from $f$ to $g$ is defined to be the type of pointwise identifications:
\[ f \sim g\coloneq \Pi_{x :A} f(x) =_{B(x)} g(x).\]
\end{defn}

\begin{rmk} Given three functions as below
\[
\begin{tikzcd} A \arrow[rr, "h"] \arrow[dr, "f"'] & & C \\ & B \arrow[ur, "g"']
\end{tikzcd}
\]
we say the triangle \textbf{commutes} if $h\sim g \circ f$.
\end{rmk}

Note if $H, K : f \sim g \coloneq \Pi_{x :A} f(x) = g(x)$ are homotopies we can treat them as dependent functions in their own right and consider \textbf{homotopies between homotopies}, i.e., terms of the type $H \sim K \coloneq \Pi_{x :A} H(x) = K(x)$. This continues all the way up.

Indeed, the $\infty$-groupoid structure of identity types extends to homotopies as follows:

\begin{defn} For any type family $B \colon A \to \UU$ we have operations
\[ \term{refl-htpy} : \Pi_{f : \Pi_{x:A}B(x)} f \sim f \quad \term{inv-htpy} : \Pi_{f,g :\Pi_{x:A}B(x)} (f \sim g) \to (g \sim f) \]
\[ \term{concat-htpy} : \Pi_{f,g,h : \Pi_{x:A}B(x)} f \sim g \to g \sim h \to f \sim h\]
defined pointwise by
\[ \term{refl-htpy}(f) = \lambda x .\refl_{f(x)} \quad \term{inv-htpy}(H) \coloneq \lambda x. {H(x)}^{-1} \quad \term{concat-htpy}(H,K) \coloneq \lambda x. H(x) \cdot K(x)\]
We abbreviate these latter two terms by writing $H^{-1}$ and $H \cdot K$.
\end{defn}

Note we don't abbreviate $\term{refl-htpy}_f : f \sim f \coloneq \Pi_{x :A} f(x)=_{B(x)} f(x)$ as $\refl_f : f =_{\Pi_{x:A}B(x)}f$ as these terms live in different types.

\begin{prop} Homotopies satisfy the groupoid laws up to homotopy:
\begin{enumerate}
\item There is a homotopy $\term{assoc-htpy}(H,K,L) : (H \cdot K) \cdot L \sim H \cdot (K \cdot L)$ for any homotopies $H : f \sim g$, $K : g \sim h$, $L \colon h \sim i$.
\item There are homotopies $\term{left-unit-htpy}(H) : \term{refl-htpy}_f \cdot H \sim H$ and $\term{right-unit-htpy}(H) : H \cdot \term{refl-htpy}_g \sim H$.
\item There are homotopies $\term{left-inv-htpy}(H) : H^{-1} \cdot H \sim \term{refl-htpy}_g$ and $\term{right-inv-htpy}(H) \colon H \cdot H^{-1} \sim \term{refl-htpy}_f$.
\end{enumerate}
\end{prop}

In addition to the groupoid operations we make use of the following \textbf{whiskering operations} on homotopies which are relevant in the setting of functions
\[
\begin{tikzcd} A \arrow[r, "f"] & B \arrow[r, bend left, "g"] \arrow[r, bend right, "h"'] & C \arrow[r, "k"] & D
\end{tikzcd}
\]

\begin{defn} Given the functions above and a homotopy $H \colon g \sim h$ define homopies
\[ H \circ f \coloneq \lambda a. H(f(a)) \colon g \circ f \sim h \circ f\]
and
\[
k \circ H \coloneq \lambda b. \ap_k(H(b)) \colon k \circ g \sim k \circ h.\]
\end{defn}

\subsection*{Bi-invertible maps}

We now explain what it means for a function $f \colon A \to B$ between types to define an \textbf{equivalence}. One explanation is that an equivalence is like a homotopy equivalence in topology, but we actually define the type family $\type{is-equiv}$ in a manner that makes equivalences look more like ``bi-invertible maps'' for reasons that we will explain.

\begin{defn} Let $f \colon A \to B$. 
\begin{enumerate}
\item The type of \textbf{sections} of $f$ is defined to be the type
\[ \type{sec}(f) \coloneq \Sigma_{g : B \to A} f\circ g \sim \id_B.\]
\item The type of \textbf{retractions} of $f$ is defined to be the type
\[ \type{retr}(f) \coloneq \Sigma_{h : B \to A} h \circ f \sim \id_A.\]
\item We say $f$ is an \textbf{equivalence} if it has a section and a retraction:
\[ \type{is-equiv}(f) \colon \type{sec}(f) \times \type{retr}(f).\]
\end{enumerate}
We write $A \simeq B$ for the type $\Sigma_{f : A \to B} \type{is-equiv}(f)$ of all equivalences from $A$ to $B$.
\end{defn}

Explicitly the data of a term in $\type{is-equiv}(f)$ involves two maps $g, h : B \to A$ and two homotopies $G : f \circ g \sim \id_B$ and $H \colon h \circ f \sim \id_A$. We have seen a bunch of examples:

\begin{ex} $\quad$
\begin{itemize}
\item Identity functions are equivalences.
\item $\term{bool-to-1+1} \colon \bool \to \1+\1$ and $\term{1+1-to-bool} \colon \1+\1 \to \bool$ are inverse equivalences.
\item $\term{neg-bool} \colon \bool \to \bool$ is an equivalence.
\item $\term{pred} \colon \bZ \to \bZ$ is an equivalence, inverse to $\term{succ} \colon \bZ \to \bZ$.
\end{itemize}
\end{ex}

We might also define
\[ \type{has-inverse}(f) \coloneq \Sigma_{g : B \to A} (f \circ g \sim \id_B) \times (g \circ f \sim \id_A).\]
The reason we did not define equivalences to be functions that have inverses is that we wanted being an equivalence to be a \textbf{property} associated to a map $f$ rather than a \textbf{structure} on the map, in a sense we'll discuss soon. Essentially because of the uniqueness of reflexivity paths, if $f$ is an equivalence then it only has one section and homotopy and only one retraction and homotopy, up to homotopy. We'll see, however, that the data of inverses to $f$ can be more complicated.

But even though the data encoded by terms in $\type{is-equiv}(f)$ and $\type{has-inverse}(f)$ may differ, these types are closely related:

\begin{prop} The types $\type{is-equiv}(f)$ and $\type{has-inverse}(f)$ are logically equivalent. In particular, if $f$ is an equivalence it has a two-sided inverse.
\end{prop}
\begin{proof}
The data of an inverse obviously defines the data of an equivalence, so we have $\type{has-inverse}(f) \to \type{is-equiv}(f)$.

For the converse, suppose we have $g,h \colon B \to A$ and homotopies $G : f \circ g \sim \id_B$ and $H \colon h \circ f \sim \id_A$.  Then for any $b : B$ we have
\[
\begin{tikzcd} g(b) \arrow[r, equals, "H(g(b))^{-1}"] & h(f(g(b))) \arrow[r, equals, "\ap_h(G(b))"] & h(b)
\end{tikzcd}
\]
defining a homotopy $K \colon g \sim h$. Using this we can see that $g$ is also a retraction of $f$ by the identification for any $a :A$
\[
\begin{tikzcd} g(f(a)) \arrow[r, "K(f(a))", equals] & h(f(a)) \arrow[r, "H(a)"] & a
\end{tikzcd}
\]
\end{proof}

\begin{cor} A section or retraction of an equivalence is an equivalence. 
\end{cor}
\begin{proof}
We've just seen that the section of an equivalence is also a retraction and thus is an invertible map with inverse $f$. A dual construction applies to a retraction.
\end{proof}

Up to equivalence, types satisfy many familiar laws, such as
\begin{align*}
A+B &\simeq B + A & A \times B &\simeq B \times A\\
A \times \1 &\simeq A & A+\emptyset &\simeq A \\
A \times (B + C) &\simeq (A \times B) + (A \times C)
 \end{align*}
where the required equivalences and homotopies can be constructed by induction. These equivalences extend to cases such as
\[ \Sigma_{x : \emptyset} B(x) \simeq \emptyset \quad \Sigma_{x : \1}B(x)\simeq B(\star).\]
and
\[ \Sigma_{z : \Sigma_{x : A}B(x)} C(z) \simeq \Sigma_{x :A} \Sigma_{y : B(x)} C(x,y) \quad \Sigma_{w : A +B}C(w) \simeq \Sigma_{x :A} C(\inl x) + \Sigma_{y : B} C(\inr y).\]

In the presence of an additional axiom, we'll be able to prove similar equivalences involving function types, but we can't deduce these just yet.

\subsection*{Characterizing the identity types of \texorpdfstring{$\Sigma$}{Sigma}-types}

We return to the theme of characterizing identity types to characterize the identity type of a $\Sigma$-type, up to equivalence. We follow the same outline used to characterize the identity type family of the natural numbers above:
\begin{enumerate}
\item We define a binary relation $R \colon A \to A \to \UU$ that we suspect is equivalent to the identity type family.
\item Prove reflexivity by constructing a term in $\Pi_{x :A} R(x,x)$.
\item Use reflexivity and path induction to define a canonical map $\Pi_{x,y:A} x=_A y \to R(x,y)$.
\item Show that the map $x=_A y \to R(x,y)$ is an equivalence for each $x,y :A$.
\end{enumerate}
The last step is usually the most difficult and we will refine our techniques for dealing with it soon.

In this section, we consider $B \colon A \to \UU$ and the corresponding type $\Sigma_{x:A} B(x)$. Given dependent pairs $(a,b)$ and $(a',b')$ we might imagine that the data of an identification between them involves a pair of identifications comprised firstly of a path $p : a =_A a'$ and then of a path $q : \tr_B(p, b) = b'$. We first turn this idea into a binary relation.

\begin{defn} Define 
\[ \Eq_\Sigma \colon \left(\Sigma_{x:A}B(x)\right) \to \left(\Sigma_{x:A}B(x)\right) \to \UU\]
by 
\[ \Eq_\Sigma(s,t) \coloneq \Sigma_{p : \pr_1(s) = \pr_1(t)} \tr_B(p, \pr_2(s)) = \pr_2(t).\]
\end{defn}

\begin{lem} The relation $\Eq_\Sigma$ is reflexive.
\end{lem}
\begin{proof} By $\Sigma$-induction it suffices to let $s : \Sigma_{x:A}B(x)$ be a pair $(a : A, b : B(a))$ in which case we have
\[ \lambda a,\lambda b. (\refl_a,\refl_b) \colon \Pi_{x :A}\Pi_{y:B(x)} \Sigma_{p : x =x} \tr_B(p,y) = y\]
since we have a definitional equality $\tr_B(\refl_a,b) \doteq b$.
\end{proof}

By path induction, we may define a map $\term{pair-eq} : s =t \to \Eq_\Sigma(s,t)$ for any $s,t : \Sigma_{x:A}B(x)$ by sending $\refl_s$ to the corresponding reflexivity term.

\begin{thm} For any type family $B \colon A \to \UU$, the map
\[ \term{pair-eq} \colon (s=t) \to \Eq_\Sigma(s,t)\]
is an equivalence for every $s,t : \Sigma_{x:A}B(x)$.
\end{thm}
\begin{proof}
We define an inverse equivalence $\term{eq-pair} \colon \Eq_\Sigma(s,t) \to (s=t)$ by repeated $\Sigma$-induction. For pairs $(a,b)$ and $(a',b')$ we must define
\[ \term{eq-pair} \colon \Sigma_{p : a =a'} \tr_B(p,b)=b' \to ((a,b) = (a',b'))\]
which we again do by $\Sigma$-induction. It suffices to  define a function in the type
\[ \Pi_{p: a = a'} (\tr_B(p,b) = b') \to ((a,b)= (a',b')).\]
By double path induction we may first assume $b'$ is $\tr_B(p,b)$ and the second path is $\refl$. Then by path induction we may assume that $a'$ is $a$ and $p$ is refl in which case we send this pair $(\refl_a,\refl_b)$ to $\refl_{(a,b)} : ((a,b) = (a,b))$.

To see that $\term{eq-pair}$ is a section of $\term{pair-eq}$ we require identifications
\[ \term{pair-eq}(\term{eq-pair}(p,q)) = (p,q)\]
for each $(p,q) : \Sigma_{p : a=a'}\tr_B(p,b)=b'$. By a double path induction it suffices to identify
\[ \term{pair-eq}(\term{eq-pair}(\refl_a,\refl_b)) = (\refl_a,\refl_b)\] and the left-hand side is judgmentally equal to the right-hand side, so we may use $\refl_{(\refl_a,\refl_b)}$.

To see that  $\term{eq-pair}$ is a retraction of $\term{pair-eq}$ we require identifications
\[ \term{eq-pair}(\term{pair-eq} (p)) = p\]
for each $p : s=t$. By path induction we may take $t$ to be $s$ and $p$ to be $\refl_s$. Then we require
\[ \term{eq-pair}(\refl_{\pr_1(s)},\refl_{\pr_2(t)}) = \refl_s.\]
By $\Sigma$-induction we may consider the case of a pair $(a,b)$ in which case we require
\[ \term{eq-pair}(\refl_a,\refl_b) = \refl_{(a,b)}.\]
Since the left-hand side we defined to be the right-hand side, we may use $\refl$.
\end{proof}

\section*{October 6: Contractibility}

Contractible types are singletons up to homotopy. In this section, we'll see several characterizations of contractibility and then relativize our discussion to include so-called ``contractible maps.''

\subsection*{Contractible types}

The term ``contractibility'' is inspired by the homotopical interpretation of type theory but it can also be thought of as an expression of ``uniqueness'': we say that a type $A$ is contractible just when it contains a unique element in a sense encoded by the Curry-Howard interpretation:

\begin{defn} A type $A$ is \textbf{contractible} if it comes equipped with a term in the type
\[ \is{contr}(A) \coloneq \Sigma_{c :A}\Pi_{x :A} c =x.\]
Given $(c,C) : \is{contr}(A)$ we refer to $c :A$ as the \textbf{center of contraction} and $C : \Pi_{x:A} c =x$ as the \textbf{contraction} or \textbf{contracting homotopy}.
\end{defn}

\begin{q} This terminology suggests that $C$ is a homotopy between some pair of functions. Which functions?
\end{q}

\begin{ex} The unit type is easily seen to be contractible. We take $\star : \1$ as the center of contraction and define $C : \Pi_{x:\1} \star = x$ by singleton induction: in the case where $x$ is $\star$, we define $C(\star) = \refl_\star$.
\end{ex}

We've met another example of a contractible type already.

\begin{thm} For any $a : A$ the type
\[ \Sigma_{x:A}a =x\]
is contractible.
\end{thm}
\begin{proof}
We take $(a,\refl_a) : \Sigma_{x:A} a =x$ to be the center of contraction. In our proof of the uniqueness of reflexivity we constructed the required contracting homotopy.
\end{proof}

\subsection*{Singleton induction}

Contractible types satisfy an induction principle similar to singleton types.

\begin{defn} Suppose $A$ comes with a term $a :A$. Then we say $A$ satisfies \textbf{singleton induction} if for every type family $B$ over $A$ the map
\[
\term{ev-pt} : \left(\Pi_{x:A} B(x)\right) \to B(a)
\]
defined by $\term{ev-pt}f \coloneq f(a)$ has a section. The data of this section is then given by a function and a homotopy
\[ \term{ind-sing}_a : B(a) \to \Pi_{x:A} B(x) \quad \text{and} \quad \term{comp-sing}_a : \term{ev-pt}\circ\term{ind-sing}_a \sim \id.\]
\end{defn}

The singleton induction principle is almost the same as the induction principle for the unit type except for one point of difference: the ``computation rule'' for singleton induction is stated using an \emph{identification} rather than a judgmental equality.  Note in particular, that $\star : \1$ satisfies singleton induction with $\lambda x . \refl_x$ as the required homotopy.

\begin{thm} For a type $A$ the following are logically equivalent.
\begin{enumerate}
\item $A$ is contractible.
\item $A$ comes equipped with a term $a : A$ satisfying singleton induction.
\end{enumerate}
\end{thm}
\begin{proof}
Suppose we have $(a,C) : \is{contr}(A) \coloneq \sum_{c :A} \prod_{x:A} c =x$. We may replace the homotopy $C : \term{const}_a \sim \id_A$ by a new homotopy $C'$ defined by $C'(x) = C(a)^{-1} \cdot C(x)$. We then have an identification $\term{left-inv} : C'(a) = \refl_a$. So without loss of generality we suppose $(a,C) : \is{contr}(A)$ comes with a term $p : C(a) = \refl_a$.

Consider a type family $B$ over $A$. For each $b : B(a)$ our goal is to define $\term{ind-sing}_a(b) : \prod_{x:A}B(x)$, which we do by
\[ \term{ind-sing}_a(b) \coloneq \tr_B(C(x),b) : B(x).\]
It remains to construct an identification $\term{ind-sing}_a(b,a) = b$. We have a function
\[ \lambda (q : a=x). \tr_B(q,b)\] that evaluates at the path $C(a)$ to give $\term{ind-sing}_a(b)$ and evalutes at the path $\refl_a$ to give $b$. When we apply this function to the path $p : C(a) = \refl_a$ we get the desired identification.

Conversely, suppose $a :A$ satisfies singleton induction. To prove that $A$ is contractible with center of contraction $a$ we apply singleton induction to the type family $B(x) \coloneq a = x$ to obtain \[\term{ind-sing}_a : a =a \to \Pi_{x:A} a=x.\] Now $\term{ind-sing}_a(\refl_a)$ is a contracting homotopy.
\end{proof}

\subsection*{Fibers}

\begin{defn} Let $f \colon A \to B$ be a function between types and consider $b : B$. The \textbf{fiber} of $f$ over $b$ is the type
\[ \fib_f(b) \coloneq \Sigma_{a:A} f(a) =b.\]
\end{defn}

That is the fiber is what in other contexts might get called the ``homotopy fiber'': it is comprised of those terms $a:A$ whose images $f(a):B$ are identified with $b$. 

It will be useful to identify the identity type of the fiber, which we do by following our usual strategy.

\begin{defn} Let $f : A \to B$ and $b : B$. Given two terms $(a,p), (a',p') : \fib_f(b)$ define a type
\[ \type{Eq-fib}_f((a,p),(a',p')) \coloneq \Sigma_{\alpha : a = a'} p = \ap_f(\alpha) \cdot p'.\]
\end{defn}

Note $\type{Eq-fib}_f :  \fib_f(b) \to \fib_f(b) \to \UU$ is reflexive since we have
\[ \lambda(a,p). (\refl_a,\refl_p) \colon \Pi_{(a,p) :\fib_f(b)} \type{Eq-fib}_f((a,p),(a,p)).\]

\begin{prop} Consider $f \colon A \to B$ and $b :B$. The canonical map
\[ (a,p) =_{\fib_f(b)} (a',p') \to \type{Eq-fib}_f((a,p),(a',p'))\]
induced by the reflexivity term is an equivalence for any pair of points $(a,p), (a',p') : \fib_f(b)$.
\end{prop}
\begin{proof}
For the inverse equivalence, we need a function
\[ \left(\Sigma_{\alpha : a = a'} p = \ap_f(\alpha) \cdot p' \right) \to (a,p) =_{\fib_f(b)} (a',p').\]
By $\Sigma$-induction it suffices to consider the image of a pair $\alpha : a = a'$ and $\beta : p = \ap_f(\alpha) \cdot p'$. By path induction we may take $p$ to be $\ap_f(\alpha) \cdot p'$ and $\beta$ to be $\refl$. By path induction again, we may take $a$ to be $a'$ and $\alpha$ to be $\refl$. Since $\ap_f(\refl)\cdot p'$ is judgmentally equal to $p'$ we may use $\refl$ as our identification between $(a',\ap_f(\refl)\cdot p')$ and $(a',p')$. The construction of the homotopies witnessing the left and right inverses are similar.
\end{proof}


\subsection*{Contractible maps and equivalences}

\begin{defn} We say that a function $f \colon A \to B$ is \textbf{contractible} if it comes equipped with a term of type
\[ \is{contr}(f) \coloneq \Pi_{b:B} \is{contr}(\fib_f(b)).\]
\end{defn}

\begin{thm} Any contractible map is an equivalence.
\end{thm}
\begin{proof}
Suppose $f \colon A \to B$ is contractible. The center of contraction $(g(b),G(b))$ in each fiber gives rise to a dependent function
\[ \lambda b. (g(b),G(b)) \colon \Pi_{b:B} \fib_f(b).\]
In particular $g : B \to A$ defines a map and $G \colon f \circ g \sim \id_B$ defines a homotopy. So $g$ is a section of $f$.

It remains to show that $g$ is also a retraction of $f$ by defining a term in the type $g \circ f \sim \id_A$. For each $a : A$ we have an identification $p : f(g(f(a))) = f(a)$ since $g$ is a section of $f$. So $(g(f(a)),p) : \fib_f(f(a))$. Since this type is contractible there is an identification $\beta : (g(f(a)),p) = (a, \refl_{f(a)})$. The base path $\ap_{\pr_1}(\beta) : g(f(a)) = a$ gives the desired identification.
\end{proof}

In fact, equivalences necessarily also define contractible maps, which we show in a few steps. Recall an \textbf{invertible map} is a map $f \colon A \to B$ equipped with $g \colon B \to A$ and homotopies $G : f \circ g \sim \id$ and $H : g \circ f \sim \id$. Then the whiskered homotopies $G \circ f$ and $f \circ H$ both have the type $f \circ g \circ f \sim f$.

\begin{defn} A map $f \colon A \to B$ is \textbf{coherently invertible} if it comes with
\[ g : B \to A, \quad G : f \circ g \sim \id, \quad H : g \circ f \sim \id, \quad K : G \circ f \sim f \circ H.\]
\end{defn}

\begin{prop} Any coherently invertible map has contractible fibers.
\end{prop}
\begin{proof}
Given $f \colon A \to B$ together with
\[ g : B \to A, \quad G : f \circ g \sim \id, \quad H : g \circ f \sim \id, \quad K : G \circ f \sim f \circ H.\]
we wish to show that $\fib_f(b)$ is contractible for any $b : B$. We take $(g(b), G(b)) : \fib_f(b)$ as the center of contraction. 

For the contracting homotopy it suffices to define a term in the equivalent type
\[ \prod_{a :A} \prod_{p : f(a) = b} \type{Eq-fib}_f((g(b),G(b)), (a,p)).\]
By path induction on $p$ it suffices to define a term in the type
\[ \prod_{a :A} \type{Eq-fib}_f((g(f(a)),G(f(a))),(a, \refl_{f(a)})).\]
By the definition of $\type{Eq-fib}_f$ this means that we need, for each $a:A$, a path $H(a) : g(f(a))=a$ and a further identification
\[ G(f(a)) = \ap_f(H(a)) \cdot \refl_{f(a)}.\]
We have $K(a) : G(f(a)) = \ap_f(H(a))$ so we get the identification we want by composing with $\term{right-unit-htpy}$.\end{proof}

Our next goal is to show that any invertible map $f \colon A \to B$ equipped with $g \colon B \to A$ and homotopies $G : f \circ g \sim \id$ and $H : g \circ f \sim \id$ can be improved to a coherently invertible map at the cost of replacing $G$ with a new homotopy $G'  : f \circ g \sim \id$ satisfying the coherence $K : f \circ H \sim G' \circ f$. The upshot is that we have a map
\[ \type{has-inverse}(f) \to \is{coh-invertible}(f).\]
The construction is by messy path algebra that you can read about in \cite[\S 10.4]{Rijke}.



\begin{cor} For any type $A$ and term $a :A$ the type
\[ \Sigma_{x:A} x =a\] is contractible.
\end{cor}
\begin{proof}
This type is the fiber of the identity function $\id_A \colon A \to A$ over $a :A$. Since $\id_A$ is an equivalence, this type must be contractible.
\end{proof}

Soon we'll have a second proof: we'll be able to use the equivalence $\inv \colon (a =x) \to (x =a)$ to define an equivalence $\lambda x. \inv \colon \Sigma_{x:A} a =x \to \Sigma_{x:A} x =a$. It follows easily that any type equivalent to a contractible type is contractible.

\section*{October 11: The fundamental theorem of identity types}

 \subsection*{Families of equivalences}
 
For any family of maps $f \colon \Pi_{x:A} B(x) \to C(x)$ there is a map
\[ \term{tot}(f) : \Sigma_{x:A} B(x) \to \Sigma_{x:A}C(x)\]
defined by $\lambda(x,y).(x,f(x,y))$. 

\begin{thm} For any  family of maps $f \colon \Pi_{x:A} B(x) \to C(x)$ the following are logically equivalent:
\begin{enumerate}
\item The family $f$ is a \textbf{family of equivalences}: for each $x :A$ the map $f(x)$ is an equivalence.
\item The map $\term{tot}(f)$ is an equivalence.
\end{enumerate}
\end{thm}
\begin{proof}
Recall equivalences are contractible maps: meaning maps whose fibers are all contractible. So it suffices to show that $f(x)$ is a contractible map for each $x$ if and only if $\term{tot}(f)$ is a contractible map. For this, we must show for each $x :A$ and $c : C(x)$ that $\fib_{f(x)}(c)$ is contractible if and only if $\fib_{\type{tot}(f)}(x,c)$ is contractible. But in fact these fibers are always equivalent, as the following lemma shows.
\end{proof}

\begin{lem} For any  family of maps $f \colon \Pi_{x:A} B(x) \to C(x)$ and any term $t : \sum_{x:A}C(x)$ there is an equivalence
\[
\fib_{\term{tot}(f)}(t) \simeq \fib_{f(\pr_1(t))}\pr_2(t).\]
\end{lem}
\begin{proof}
For all ${t: \Sigma_{x:A}C(x)}$ define $\phi(t) \colon  \fib_{\term{tot}(f)}(t) \to \fib_{f(\pr_1(t))}\pr_2(t)$ by pattern matching by taking $(x,f(x,y),(x,y), \refl)$ to $(y,\refl)$. To see that $\phi(t)$ is an equivalence for each $t : \Sigma_{x:A}C(x)$ we construct an inverse by pattern matching \[ \phi(x,f(x,y),y, \refl) \coloneq ((x,y),\refl)\] and homotopies by pattern matching in which case both homotopies reduce to $\refl$.
\end{proof}

Now consider a closely related situation where we are given a map $f \colon A \to B$ and a family $C \colon B \to \UU$. We have a map
\[ \lambda(x,z).(f(x),z): \Sigma_{x:A} C(f(x)) \to \Sigma_{y :B}C(y).\]
Again, by the same style of argument, if $f$ is an equivalence then this map is an equivalence (because the fibers are equivalent), but in this case the converse does not hold: consider $\true : \1 \to \bool$ and the type family $\false = b : \bool \to \UU$.

Nevertheless we can use the one-sided implication to extend the previous theorem as follows. Given $f \colon A \to B$ and a family of maps $g : \Pi_{x:A}C(x) \to D(f(x))$ where $C$ is a type family over $A$ and $D$ is a type family over $B$, we say that $g$ is a \textbf{family of maps over} $f$. Define
\[ \term{tot}_f(g) : \Sigma_{x:A}C(x) \to \Sigma_{y:B}D(y)\] by $\term{tot}_f(g)(x,z) \coloneq (f(x),g(x,z))$.

\begin{thm} Suppose $g$ is a family of maps over $f$ and $f$ is an equivalence. Then the following are logically equivalent:
\begin{enumerate}
\item The family of maps $g$ over $f$ is a family of equivalences.
\item The map $\term{tot}_f(g)$ is an equivalence.
\end{enumerate}
\end{thm}
\begin{proof}
We have a commuting triangle of maps
\[
\begin{tikzcd} \Sigma_{x:A}C(x) \arrow[rr, "\term{tot}_f(g)"] \arrow[dr, "\term{tot}(g)"'] & & \Sigma_{y:B}D(y) \\ & \Sigma_{x:A}D(f(x)) \arrow[ur, "{\lambda(x,z).(f(x),z)}"'] 
\end{tikzcd}
\]
Since $f$ is an equivalence, the bottom right map is an equivalence. The equivalences are closed under the 2-of-3 property (meaning if any two of a composable pair and their composite are equivalences so is the third map). Thus $\term{tot}(g)$ is an equivalence if and only if $\term{tot}_f(g)$ is an equivalence. And by the previous theorem, the first condition asserts that $g$ is a family of equivalences.
\end{proof}

\subsection*{The fundamental theorem}

The fundamental theorem of identity types provides necessary and sufficient conditions for a type family $B \colon A \to \UU$ and terms $a : A$ and $b : B(a)$ to define a family of equivalences $\Pi_{x:A}(a=x) \simeq B(x)$ by $(a,\refl)\mapsto b$. In fact, we'll see we can be a bit less particular about how exactly the family of equivalences is defined.

\begin{defn} Given a type $A$ and a term $a:A$ a \textbf{(unary) identity system} on $A$ at $a$ is given by a type family $B : A \to \UU$ and a term $b : B(a)$ so that for any family of types $P \colon \Sigma_{x:A}B(x) \to \UU$ the function
\[ \ev_{a,b} \colon \Pi_{x:A} \Pi_{y:B(x)}P(x,y) \to P(a,b)\] has a section.
\end{defn}

That is, if $(B,b)$ is an identity system at $(A,a)$ and $P$ is a family of types over $x:A$ and $y:B(x)$ then for each $p : P(a,b)$ there is a dependent function $f :\Pi_{x:A} \Pi_{y:B(x)} P(x,y)$ so that $f(a,b) = p$. This is a variant of the path induction principal where the computation rule is given by an identification.

\begin{thm}[fundamental theorem of identity types] Let $A$ be a type, let $a :A$, and let $B : A \to \UU$. Then the following are logically equivalent for any family of maps \[ f : \Pi_{x:A}(a=x) \to B(x).\]
\begin{enumerate}
\item $f$ is a family of equivalences.
\item The total space $\Sigma_{x:A}B(x)$ is contractible.
\item The family $B$ is an identity system.
\end{enumerate}
In particular, for any $b : B(a)$ the canonical map \[\term{path-ind}_a(b) \colon \Pi_{x:A}(a=x)\to B(x)\] is a family of equivalences if and only if $\Sigma_{x:A}B(x)$ is contractible. 
\end{thm}
\begin{proof}
By our theorem characterizing families of equivalences $f$ is a family of equivalences iff $\term{tot}(f)$ induces an equivalence
\[ \left(\Sigma_{x:A}(a=x) \right) \simeq \left(\Sigma_{x:A}B(x)\right).\]
The left-hand type is contractible so this is the case if and only if $\Sigma_{x:A}B(x)$ is contractible. This proves the equivalence of (i) and (ii). 

For the equivalence of (ii) and (iii) consider the commutative triangle:
\[
\begin{tikzcd} \Pi_{t : \Sigma_{x:A}B(x)} P(t) \arrow[rr, "\term{ev-pair}"] \arrow[dr, "\term{ev-pt}_{(a,b)}"'] & & \Pi_{x:A} \Pi_{y : B(x)} P(x,y) \arrow[dl, "\ev_{(a,b)}"] \\ & P(a,b)
\end{tikzcd}
\]
By $\Sigma$-induction, the top map has a section. It follows that the left map has a section if and only if the right map has a section. The left-hand section is the universal property called singleton induction that is satisfied if and only if the type $\Sigma_{x:A}B(x)$ is contractible, while the right-hand section is the universal property of an identity system. This proves the equivalence of  (ii) and (iii).
\end{proof}

\subsection*{Equality on \texorpdfstring{$\bN$}{N}}

As our first application recall the observational equality type family $\Eq_\bN : \bN \to \bN \to \UU$ satisfying
\[ \Eq_\bN(0_\bN,0_\bN) \doteq \1 \quad \Eq_\bN(\suc(n),0_\bN) \doteq \emptyset \quad \Eq_\bN(0,\suc(n)) \doteq \emptyset \quad \Eq_\bN(\suc(m), \suc(n)) \doteq \Eq_\bN(m,n).\] We previously showed that this type family is logically equivalent to the identity type family for the natural numbers, but we can do better. Using the reflexivity term $\term{refl-Eq}_\bN : \prod_{n :\bN} \Eq_{\bN}(n,n)$ we have a canonical map $(m=n) \to \Eq_\bN(m,n)$ defined by path induction.

\begin{thm} For all $m,n : \bN$ the canonical map
\[ (m=n) \to \Eq_\bN(m,n)\] is an equivalence.
\end{thm}
\begin{proof}
It suffices to show for each $m : \bN$ that the type \[ \Sigma_{n : \bN} \Eq_\bN(m,n)\] is contractible. We take $(m,\term{refl-Eq}_\bN(m))$ as the center of contraction.

The contracting homotopy 
\[ \gamma(m) : \Pi_{n :\bN} \Pi_{e :\Eq_\bN(m,n)} (m,\term{refl-Eq}_\bN(m)) = (n,e)\]
is defined by induction on $m,n : \bN$ from the base case $\gamma(0,0, \star) \coloneq \refl$. If either $m$ or $n$ is 0 and the other is a successor we can define this using ex-falso. 

In the inductive step we seek an identification $\gamma(m+1,n+1,e) : (m+1, \term{refl-Eq}_\bN(m+1)) = (n+1,e)$. To define this we use the map
\[ \lambda(n,e).(n+1,e) : \Sigma_{n:\bN}\Eq_\bN(m,n) \to \Sigma_{n : \bN}\Eq_\bN(m+1,n).\]
Since this map carries $(m,\term{refl-Eq}_\bN(m))$ to $(m+1,\term{refl-Eq}_\bN(m+1))$ we can apply the map to the identification $(m,n,e)$ to get the identification we seek.
\end{proof}

\subsection*{Embeddings}

Our next application will show that equivalences are embeddings, defined as follows:

\begin{defn} An \textbf{embedding} is a map $f \colon A \to B$ that satisfies the property that 
\[ \ap_f : (x=y) \to (f(x)=f(y))\]
is an equivalence for every $x,y :A$.
\end{defn}

Write 
\[ \is{emb}(f) \coloneq \Pi_{x,y:A} \is{equiv}(\ap_f : (x=y) \to (f(x)=f(y))).\]

\begin{thm} Equivalences are embeddings.
\end{thm}
\begin{proof}
Suppose $e : A \simeq B$ is an equivalence and $x:A$. We wish to show that 
\[ \ap_e : (x=y) \to (e(x)=e(y))\] is an equivalence for every $y :A$. For this it suffices to show that $\Sigma_{y:A}e(x) =e(y)$ is contractible. We have an equivalence
\[ \Sigma_{y:A}e(x)=e(y) \simeq \Sigma_{y:A} e(y) = e(x)\]
and the latter type is the fiber $\fib_e(e(x))$. Since $e$ is an equivalence this fiber is contractible so the result follows.
\end{proof}

\subsection*{Disjointness of coproducts}

For a third application, we characterize the identity types of coproducts.

\begin{thm} Let $A$ and $B$ be types. Then for any $a,a' :A$ and $b,b': B$ there are equivalences
\begin{align*} (\inl(a) = \inl(a')) &\simeq (a = a')  \\ (\inl(a) = \inr(b)) &\simeq \emptyset \\ (\inr(b) = \inl(a)) &\simeq \emptyset \\ (\inr(b) = \inr(b')) &\simeq (b = b')
\end{align*}
\end{thm}

We follow our usual strategy first defining a type family
\[ \type{Eq-+}_{A,B} : (A+B) \to (A+B) \to \UU\] 
by induction by
\begin{align*} \type{Eq-+}_{A,B}(\inl(a),\inl(a')) &\simeq (a = a')  \\ \type{Eq-+}_{A,B}(\inl(a),\inr(b)) &\simeq \emptyset \\ \type{Eq-+}_{A,B}(\inr(b),\inr(a)) &\simeq \emptyset \\ \type{Eq-+}_{A,B} (\inr(b), \inr(b')) &\simeq (b = b')
\end{align*}

Again by induction there is a term $\term{Eq-+-refl} : \Pi_{z:A+B} \type{Eq-+}_{A,B}(z,z)$ defined by $\refl$ in both cases. Thus there is a map
\[ \term{Eq-+-eq}: \Pi_{s,t:A+B} (s=t) \to \type{Eq-+}_{A,B}(s,t)\]
defined by path induction. 

\begin{prop} For any $s : A +B$ the total space
\[ \Sigma_{t:A+B}\type{Eq-+}_{A,B}(s,t)\]
is contractible.
\end{prop}
\begin{proof}
By induction on $s$ we have to consider two cases, of which we prove just one: that 
\[ \Sigma_{t:A+B}\type{Eq-+}_{A,B}(\inl(a),t)\]
is contractible. From distributivity of dependent pairs of coproducts we have
\[ \Sigma_{t:A+B}\type{Eq-+}_{A,B}(\inl(a),t) \simeq \Sigma_{x:A} \type{Eq-+}_{A,B}(\inl(a),\inl(x)) + \Sigma_{b:B} \type{Eq-+}_{A,B}(\inl(a),\inr(b)) \simeq \Sigma_{x:A} (a = \inl(x)) + \Sigma_{b:B} \emptyset\]
\[ \simeq  \Sigma_{x:A} (a = \inl(x)) + \emptyset \simeq  \Sigma_{x:A} (a = \inl(x)).  \]
This last type is contractible so the first type is as claimed.
\end{proof}

This establishes the desired family of equivalences of types.

\subsection*{The structure identity principle}

The notion of identity system $B : A \to \UU$ and $b : B(a)$ over a type $A$ and term $a:A$ can be extended to a notion of dependent identity system. A \textbf{dependent identity system} over $(B,b)$ is given by a type family $C : A \to \UU$ together with 
\[ D : \Pi_{x:A} B(x) \to C(x) \to \UU\] and a term $c : C(a)$ so that $z \mapsto D(a,b,z)$ is an identity system at $c$. We leave the details to \cite[\S11.6]{Rijke}.

\section*{October 13: Propositions and sets}

We now formally study propositions in homotopy type theory.

\subsection*{Propositions}

\begin{defn} A type $A$ is a \textbf{proposition} if all of its identity types are contractible: i.e., if it comes with a term of type
\[ \is{prop}(A) \coloneq \Pi_{x,y:A} \is{contr}(x=y).\]
\end{defn}

Given a universe $\UU$ we define $\Prop$ to be the type of all small propositions:
\[ \Prop \coloneq \Sigma_{X: \UU}\isprop(X).\]

\begin{ex} We have shown that identity types of contractible types are contractible. Thus contractible types are propositions.
\end{ex}

\begin{ex} The empty type is also a proposition, for ex-falso inhabits
\[ \Pi_{x,y: \emptyset} \iscontr(x=y).\]
\end{ex}

There are many equivalent ways to assert that a type is a proposition.

\begin{prop} For a type $A$, the following are logically equivalent:
\begin{enumerate}
\item $A$ is a proposition.
\item Any two terms of type $A$ can be identified: i.e., there is a dependent function in the type
\[ \Pi_{x,y:A} x=y.\]
\item The type $A$ is contractible as soon as it is inhabited: i.e., there is a term of type $A \to \iscontr(A)$.
\item The map $\term{const}_\star : A \to \1$ is an embedding. 
\end{enumerate}
\end{prop}
\begin{proof}
(i) clearly implies (ii), by using the center of contraction. Assuming (ii) we have $p : \Pi_{x,y:A} x= y$. Note for any $x$ that $p(x) : \Pi_{y :A} x=y$ is a contracting homotopy onto $x$. Thus, we have a function
\[ \lambda x. (x,p(x)) : A \to \iscontr(A).\]

Next assume (iii) and consider a function $c : A\to \iscontr(A)$. To prove 
\[ \Pi_{x,y :A} \isequiv (\ap_{\term{const}_\star} : (x=y) \to (\star = \star))\] it suffices to prove
\[ A \to \left(\Pi_{x,y :A} \isequiv (\ap_{\term{const}_\star} : (x=y) \to (\star = \star))\right)\]
because then we can use this function $f$ applied to one of the two terms $x,y : A$ to get the data we want. But now our new goal allows us to assume we have a term $a:A$ and so it follows from our assumption that $A$ is contractible. Thus $\term{const}_\star : A \to \1$ is an equivalence and in particular an embedding. This proves (iv).

Finally, $\term{const}_\star : A \to \1$ is an embedding, then the types $(x=y)$ and $(\star=\star)$ are equivalent. The latter type is contractible so the former must be as well. This proves that (iv) implies (i).
\end{proof}

A useful feature of propositions is that logical equivalences become equivalences:

\begin{prop} For propositions $P$ and $Q$
\[ (P \simeq Q) \iff (P \iff Q).\]
\end{prop}
\begin{proof}
Clearly we have $(P \simeq Q) \to (P \iff Q)$ so the content is in the converse. Given $f : P \to Q$ and $g : Q \to P$ we obtain homotopies $f \circ g \sim \id$ and $g \circ f \sim \id$ by the fact that any two elements in $P$ and $Q$ can be identified. Thus, $f$ and $g$ are equivalence inverses.
\end{proof}

\subsection*{Subtypes}

Now that we know about propositions we can say that a type family $P \colon A \to \UU$ is a predicate if for each $a :A$, $P(a)$ is a proposition. In other words, predicates are type families $P \colon A \to \Prop$. Other terminology is commonly in use in this situation.

\begin{defn} A type family $B$ over $A$ is a \textbf{subtype} of $A$ if for each $x:A$, $B(x)$ is a proposition. In this situation we say that $B(x)$ is a \textbf{property} of $x:A$.
\end{defn}

We'll show that for subtypes $B$ over $A$ the map $\pr_1 \colon \Sigma_{x:A} B(x) \to A$ is an embedding. It follows, then, that $(x,y) = (x',y')$ if and only if $x=_Ax'$. To prove this first observe:

\begin{lem} Suppose $e : A\simeq B$. Then 
\[ \isprop{A} \iff \isprop{B}.\]
\end{lem}

\begin{proof}
Since $e$ is an equivalence, $e$ is an embedding, meaning that $\ap_e : (x=_Ay) \to (e(x)=_B e(y))$ is an equivalence. Now if $B$ is contractible then $(e(x)=_Be(y))$ is contractible which then implies that $(x=_Ay)$ is contractible. Thus $\isprop(B) \to \isprop(A)$. The converse is proven similarly using the inverse equivalence to $e$.
\end{proof}

\begin{thm} For $f : A \to B$ the following are logically equivalent:
\begin{enumerate}
\item $f$ is an embedding.
\item $\fib_f(b)$ is a proposition for all $b : B$
\end{enumerate}
\end{thm}
\begin{proof}
By the fundamental theorem of identity types, $f$ is an embedding if and only if $\Sigma_{x:A}f(x)=_B f(y)$ is contractible for each $y :A$. Thus $f$ is an embedding iff $\fib_f(f(y))$ is contractible for each $y : A$. If $b:B$ and $p : f(y) = b$ then transport defines an equivalence
\[ \fib_f(f(y)) \simeq \fib_f(b).\]
Thus $f$ is an embedding iff $\fib_f(b)$ is contractible for each $b : B$ equipped with $p : f(y) = b$ for some $y:A$. This latter condition may be re-expressed as \[ \fib_f(b) \to \iscontr(\fib_f(b)),\]
which is logically equivalent to the assertion that each $\fib_f(b)$ is a proposition.
\end{proof}

\begin{cor} For any family $B : A \to \UU$ the following are logically equivalent:
\begin{enumerate}
\item $\pr_1 \colon \Sigma_{x:A} B(x) \to A$ is an embedding.
\item $B(x)$ is a proposition for each $x:A$.
\end{enumerate}
\end{cor}
\begin{proof}
Since $\fib_{\pr_1}(x) \simeq B(x)$ this follows immediately from the previous theorem.
\end{proof}

\subsection*{Sets}

\begin{defn} A type $A$ is a \textbf{set} if its identity types are propositions:
\[ \is{set}(A) \coloneq \Pi_{x,y:A} \isprop(x=y).\]
\end{defn}

\begin{ex} The type of natural numbers is a set, since we have $(m=n) \simeq \Eq_\bN(m,n)$ and, by induction, the latter types are propositions.
\end{ex}

\begin{thm} For a type $A$ the following are logically equivalent:
\begin{enumerate}
\item $A$ is a set.
\item $A$ satisfies \textbf{axiom K}: that is, $A$ comes with a term in the type
\[ \type{axiom-K}(A) \coloneq \Pi_{x:A} \Pi_{p : x =x} \refl_x = p.\]
\end{enumerate}
\end{thm}
\begin{proof}
If $A$ is a set then $x=x$ is a proposition so any two terms in it can be identified.

Conversely, if axiom-K holds then for any $p,q : x =y$ we can identify $p \cdot q^{-1}$ and $\refl_x$ and it follows that $p=q$. This proves that $x=y$ is a proposition so $A$ must be a set.
\end{proof}

The following result can be used to prove that a type $A$ is a set.

\begin{thm} Let $A$ be a type and suppose $R \colon A \to A \to \UU$ satisifes:
\begin{enumerate}
\item Each $R(x,y)$ is a proposition.
\item $R$ is reflexive, witnessed by $\rho : \Pi_{x:A} R(x,x)$.
\item There is a map $R(x,y) \to (x=y)$ for all $x,y:A$.
\end{enumerate}
Then any family of maps $\Pi_{x,y:A} (x=y) \to R(x,y)$ is a family of equivalences and $A$ must be a set.
\end{thm}
\begin{proof}
By hypothesis we have terms $f : \Pi_{x,y:A} R(x,y) \to (x=y)$ and also $\term{path-ind}(\rho) : \Pi_{x,y} (x=y) \to R(x,y)$. Since each $R(x,y)$ is a proposition we have a homotopy $\term{path-ind}(\rho)(x,y) \circ f(x,y) \sim \id_{R(x,y)}$ proving that $R(x,y)$ is a retract of $x=y$. Thus, $\Sigma_{y:A} R(x,y)$ is a retract of $\Sigma_{y:A} x=y$. Since the latter type is contractible the former must be too. Thus any family of maps $\Pi_{y:A}(x=y) \to R(x,y)$ is a family of equivalences (since its totalization is a map between contractible types and thus an equivalence). 

But now we know that the identity types of $A$ are propositions so $A$ must be a set.
\end{proof}

Recall a type $A$ has decidable equality  if the identity type $x=_Ay$ is decidable for every $x, y : A$, meaning
\[ \Pi_{x,y:A} (x=y) + \neg (x=y).\]

\begin{thm}[Hedberg] Any type with decidable equality is a set.
\end{thm}
\begin{proof} Let $d : \Pi_{x,y:A} (x=y) + \neg (x=y)$ be a witness to the fact that $A$ has decidable equality and let $\UU$ be a universe containing $A$.

Define a type family $R'(x,y) : ((x=y) +\neg(x=y)) \to \UU$ by
\[ R'(x,y, \inl(p)) \coloneq \1 \quad R'(x,y, \inr(p)) \coloneq \emptyset.\]
Note that this is a family of propositions. Now define $R(x,y) \coloneq R'(x,y,d(x,y))$. This defines a family of propositions $R : A \to A \to \UU$. This is a reflexive binary relation so the apply the previous theorem to conclude that $A$ is a set we must only show that $R$ implies identity. 

Since $R$ is defined to be an instance of $R'$ it suffices to construct a function for each $q : (x=y) + \neg(x=y)$ that proves $f(q) : R'(x,y,q) \to (x=y)$. We have this by
\[ f(\inl(p,r)) \coloneq p \qquad f(\inr(p),r) \coloneq \term{ex-falso}(r). \qedhere\]
\end{proof}

\section*{October 18: General Truncation Levels \& Function extensionality}

\subsection*{General truncation levels}

So far we have defined:
\begin{align*}
\iscontr(A) &\coloneq \Sigma_{a:A} \Pi_{x:A} a=x\\
\isprop(A) &\coloneq \Pi_{x,y:A} \iscontr(x=y) \\
\is{set}(A) &\coloneq \Pi_{x,y:A} \isprop(x=y) 
\end{align*}
These define the first few layers of the hierarchy of truncation levels. This hierarchy starts at level -2 with the contractible types and continues at level -1 with the propositions. This makes level 0 the sets, which are typically thought of as ``0-dimensional.''

Let $\bT$ be the inductive type with constructors $-2_\bT : \bT$ and $\term{succ}_\bT : \bT \to \bT$. The natural inclusion $i \colon \bN \to \bT$ is defined recursively by $i(0_\bN) \coloneq \term{succ}_\bT (\term{succ}_\bT (-2_\bT))$ and $i(\suc(n)) \coloneq \term{succ}_\bT (i(n))$. We abbreviate by writing $-2,-1,0,1,2,\ldots$ for the first few terms of $\bT$ when the context is clear.

\begin{defn} Define $\is{trunc} : \bT \to \UU \to \UU$ recursively by
\[ \is{trunc}_{-2}(A) \coloneq \iscontr(A) \qquad \is{trunc}_{k+1}(A) \coloneq \Pi_{x,y:A} \is{trunc}_k(x=_Ay).\]
When $\is{trunc}_k(A)$ holds we say $A$ is \textbf{$k$-truncated} or is a \textbf{$k$-type}. You can prove, inductively in $k : \bT$, that this is logically independent of the universe being used to define $\is{trunc}_k(A)$.
\end{defn}



For $k \geq 0$, we may also say that $A$ is a \textbf{proper $k$-type} if $\is{trunk}_k(A)$ holds but $\is{trunk}_{k-1}(A)$ does not.


\begin{defn} A map $f \colon A \to B$ is \textbf{$k$-truncated} if its fibers are $k$-truncated.
\end{defn}

Given a universe $\UU$, we may also define a universe of $k$-truncated types by
\[ \UU^k \coloneq \Sigma_{X:\UU} \is{trunc}_k(X).\]


The truncation levels are successively contained in one another:

\begin{prop} If $A$ is a $k$-type then $A$ is also a $k+1$-type.
\end{prop}
\begin{proof}
We use induction on $k : \bT$. In the base case, we have shown already that contractible types are propositions. For the inductive step, note that if any $k$-type is a $k+1$-type then this applies to show that the identity types of a $k+1$-type, which are known to be $k$-types, are also $k+1$-types. This proves that any $k+1$-type is a $k+2$-type.
\end{proof}

In particular:

\begin{cor} If $A$ is a $k$-type its identity types are also $k$-types.
\end{cor}

General truncation levels are stable under equivalence:

\begin{prop} If $e : A \simeq B$ and $B$ is a $k$-type so is $A$.
\end{prop}
\begin{proof}
We know this for contractible types, which is the base case. For the inductive step, $e: A \simeq B$ provides an equivalence $\ap_e :(x=y) \to (e(x)=e(y))$ for any $x,y:A$. If $B$ is a $k+1$-type its identity types are $k$-types so the inductive hypothesis implies that $(x=y)$ is also a $k$-type. This proves that $A$ is a $k+1$-type.
\end{proof}

A similar argument shows:

\begin{cor} If $f \colon A \to B$ is an embedding and $B$ is a $k+1$-type, then so is $A$.
\end{cor}

Our final theorem generalizes the result that shows that a map is an embedding if and only if its fibers are propositions.
\begin{thm} For $f \colon A \to B$ the following are logically equivalent:
\begin{enumerate}
\item $f$ is $(k+1)$-truncated.
\item For each $x,y:A$, $\ap_f :(x=y) \to (f(x)=f(y))$ is $k$-truncated.
\end{enumerate}
\end{thm}
\begin{proof}
Both directions use the characterization of identity types of fibers:
\[ ((x,p) =_{\fib_f(b)}(y,q) ) \simeq \Sigma_{\alpha: x=y} p = \ap_f(\alpha) \cdot q.\]

The first statement is about identity types of fibers so consider $s,t : \fib_f(b)$.  We claim there is an equivalence \[ (s=t) \simeq \fib_{\ap_f}(\pr_2(s)\cdot \pr_2(t)^{-1}).\] By $\Sigma$-induction we can construct this for pairs $(x,p), (y,q) : \fib_f(b)$ for which we calculate
\begin{align*} ((x,p)=(y,q)) &\simeq \Sigma_{\alpha : x= y} p = \ap_f(\alpha)\cdot q  \\ &\simeq \Sigma_{\alpha:x=y} \ap_f(\alpha)\cdot q = p \\ &\simeq \Sigma_{\alpha :x=y} \ap_f(\alpha) = p \cdot q^{-1} \\
&\eqcolon \fib_{\ap_f}(p\cdot q{^{-1}}).
\end{align*}
It follows that if $\ap_f$ is $k$-truncated then so each identity type $(s=t)$ is equivalent to a $k$-truncated type and thus $f$ is $k+1$-truncated.

For the converse, we have an equivalence between $\fib_{\ap_f}(p)$ and the identity type $(x,p) =(y,\refl_{f(y)})$ between terms in $\fib_f(f(y))$. So if $f$ is $(k+1)$-truncated these fibers are $k+1$-truncated and thus  their identity types are $k$-types. This proves that the fiber $\fib_{\ap_f}(p)$ is $k$-truncated.
\end{proof}

\subsection*{Function extensionality}

The function extensionality principle characterizes the identity type of an arbitrary dependent function type, asserting that the type $f=g$ of identifications between dependent functions $f,g : \Pi_{x:A} B(x)$ is equivalent to the type of homotopies $f \sim g$. It has several equivalent forms:

\begin{prop} For a type family $B : A \to \UU$ the following are logically equivalent:
\begin{enumerate}
\item The \textbf{function extensionality principle holds} for $f,g : \Pi_{x:A}B(x)$: the family of maps
\[ \term{htpy-eq} : (f=g) \to (f \sim g)\]
defined by sending $\refl$ to $\term{refl-htpy}$ is a family of equivalences.
\item For any $f : \Pi_{x:A}B(x)$, the total space
\[ \Sigma_{g : \Pi_{x:A}B(x)} f \sim g\]
is contractible.
\item The principle of \textbf{homotopy induction} holds: for any family of types $P$ depending on $f,g : \Pi_{x:A}B(x)$ and $H : f \sim g$ the evaluation function
\[ \ev\colon \left( \Pi_{f,g : \Pi_{x:A}B(x)} \Pi_{H : f \sim g} P(f,g,H) \right) \to \Pi_{f : \Pi_{x:A}B(x)} P(f,f, \term{refl-htpy}_f)\]
has a section.
\end{enumerate}
\end{prop}
\begin{proof}
This follows by applying the fundamental theorem of identity types to the type $\Pi_{x:A}B(x)$, term $f : \Pi_{x:A}B(x)$, and type family $g : \Pi_{x:A}B(x) \vdash f \sim g \univ$.
\end{proof}

A fourth equivalent condition is more surprising because it appears to express only a weak function extensionality principle.

\begin{thm} For any universe $\UU$ the following are logically equivalent:
\begin{enumerate}
\item The \textbf{function extensionality principle} holds in $\UU$: for any type family $B$ over $A$ and dependent functions the map 
\[ \term{htpy-eq} : (f=g) \to (f \sim g)\]
is an equivalence.
\item The \textbf{weak function extensionality principle} holds in $\UU$:  for any type family $B$ over $A$ one has
\[ \left( \Pi_{x:A} \is{contr}(B(x)) \right) \to \is{contr}\left( \Pi_{x:A}B(x)\right).\]
\end{enumerate}
\end{thm}
\begin{proof}
Assume (i) and suppose each fiber $B(x)$ is contractible with center of contraction $c(x)$ and contracting homotopy $C_x : \Pi_{y : B(x)} c_x = y$. Define $c = \lambda x. c(x)$ to be the center of contraction of $\Pi_{x:A}B(x)$. For the contraction we require a term of type
\[ \Pi_{f : \Pi_{x : A}B(x)} c =f.\] By function extensionality we have a map $(c \sim f) \to (c=f)$ so it suffices to construct a term of type $c \sim f \coloneq \Pi_{x:A} c(x)= f(x)$ and $\lambda x. C_x(f(x))$ is just such a term.

For the converse, assume (ii). By the previous result it suffices to show that the type
\[ \Sigma_{g : \Pi_{x:A}B(x)} f \sim g\]
is contractible. Note we have a section-retraction pair:
\[ \left(\Sigma_{g : \Pi_{x:A}B(x)} f \sim g \right) \xrightarrow{s} \left( \Pi_{x:A}\Sigma_{y:B(x)} f(x) = y\right) \xrightarrow{r} 
\left(\Sigma_{g : \Pi_{x:A}B(x)} f \sim g \right) \]
defined by
\[ s \coloneq \lambda (g,H). \lambda x.(g(x),H(x)) \quad \text{and} \quad r \coloneq \lambda p. (\lambda x. \pr_1(p(x)), \lambda x. \pr_2(p(x))).\]
The composite is homotopic to the identity function by the computation rules for $\Sigma$ and $\Pi$-types. Here the central type is a product of contractible types so must be contractible by (ii). Since retracts of contractible types are contractible, the claim follows.
\end{proof}

Henceforth, we will assume the function extensionality principle as an axiom:

\begin{ax}[function extensionality] For any type family $B$ over $A$ and any pair of dependent functions $f,g : \Pi_{x:A}B(x)$ the map
\[ \term{htpy-eq} : (f=g) \to (f \sim g)\]
is an equivalence, with inverse $\term{eq-htpy}$.
\end{ax}

That is, we add the following rule to type theory:
\[
\inferrule{ \Gamma, x:A \vdash B(x)\univ \\ \Gamma \vdash f : \Pi_{x:A}B(x) \\ \Gamma \vdash g : \Pi_{x:A}B(x)}
{ \Gamma \vdash \term{funext} : \is{equiv}(\term{htpy-eq}_{f,g})}
\]

There are myriad consequences of the function extensionality axiom. Firstly:

\begin{thm} For any type family $B$ over $A$ one has
\[ \left( \Pi_{x:A} \is{trunc}_k(B(x)) \right) \to \is{trunc}_k\left( \Pi_{x:A}B(x)\right).\]
\end{thm}
\begin{proof}
The theorem states that $k$-types are closed under arbitrary dependent products. We prove this by induction on $k \geq -2$. The base case is the weak function extensionality principle.

For the inductive step assume $k$-types are closed under products and consider a family $B$ of $(k+1)$-types. To show that $\Pi_{x:A}B(x)$ is $(k+1)$-truncated we must show that $f=g$ is $k$-truncated for every $f,g : \Pi_{x:A}$. By function extensionality this is equivalent to the type $f \sim g \coloneq \Pi_{x:A} f(x)=g(x)$ which is defined to be a dependent product of $k$-truncated types and thus is $k$-truncated by hypothesis. Since $k$-truncated types are closed under equivalences, the result follows.
\end{proof}

For a non-dependent family we conclude that: 
\begin{cor} Suppose $B$ is a $k$-type. Then the type of functions $A \to B$ is a $k$-type for any type $A$.
\end{cor}

In particular, $\neg A$ is a proposition for any type $A$!

\section*{October 20: Universal properties}

We can understand the function extensionality axiom as providing a characterization of the identity type of a $\Pi$-type: up to equivalence, for $f,g : \Pi_{x:A}B(x)$, the identity type $f=g$ is equivalent to the type of homotopies $f \sim g$.

\subsection*{The type theoretic axiom of choice}

 First, observe that $\Pi$-types distribute over $\Sigma$-types by the type theoretic axiom of choice.

\begin{thm} For any family of types $x :A, y : B(x) \vdash C(x,y) \univ$ the map
\[ \term{choice} : \left(\Pi_{x:A}\Sigma_{y:B(x)}C(x,y) \right) \to \left( \Sigma_{f: \Pi_{x:A}B(x)} \Pi_{x:A} C(x,f(x))\right)\]
defined by 
\[ \term{choice}(h) \coloneq (\lambda x. \pr_1(h(x)), \lambda x.\pr_2(h(x)))\]
is an equivalence.
\end{thm}

Consequently, whenever we have types $A$ and $B$ and a type family $C$ over $B$ there is an equivalence
\[ \left( A \to \Sigma_{y:B}C(y) \right) \simeq \left( \Sigma_{f:A \to B} \Pi_{x:A} C(f(x))\right)\]

\begin{proof}
Define the inverse map $\term{choice}^{-1}$ by
\[ \term{choice}^{-1}(f,g) \coloneq \lambda x.(f(x).g(x)).\]
For the first homotopy it suffices to define an identification $\term{choice}(\term{choice}^{-1}(f,g)) = (f,g)$. The left-hand side computes to
\[ \term{choice}(\term{choice}^{-1}(f,g))  \doteq \term{choice}(\lambda x.(f(x).g(x))) \doteq (\lambda x.f(x),\lambda x.g(x))\]
which is definitely equal to the right-hand side by the computation rules for function types.

For the second homotopy, we require an identification $\term{choice}^{-1}(\term{choice}(h)) = h$. The left-hand side computes to
\[ \term{choice}^{-1} (\lambda x. \pr_1(h(x)), \lambda x.\pr_2(h(x))) \doteq \lambda x.(\pr_1(h(x)), \pr_2(h(x))).\]
We do not have a definitional equality relating $h(x)$ and $(\pr_1(h(x)), \pr_2(h(x)))$ but in our characterization of the identity type of $\Sigma$-types we do have an identification between them called $\term{eq-pair}(\refl,\refl)$. By function extensionality, the homotopy $\lambda x. \term{eq-pair}(\refl,\refl) : \term{choice}^{-1}(\term{choice}\sim h$ can be turned into an identification and thus a homotopy $\term{choice}^{-1} \circ \term{choice} \sim \id$.
\end{proof}

\subsection*{Universal properties}

More generally, the function extensionality axiom allows us to prove universal properties, which characterize maps out of or into a given type, and characterize that type up to equivalence. Some examples follow.

In our first example, we consider the maps out of $\Sigma$-types. The universal property states that the map
\[ \term{ev-pair} : \left( \left( \Sigma_{x:A}B(x)\right) \to C \right) \to \left( \Pi_{x:A}B(x) \to C \right)\]
given by $f \mapsto \lambda x.\lambda y. f(x,y)$ is an equivalence for any type $C$. But the analogous result is true for type familyes $C$ that depend on the type $\Sigma_{x:A}B(x)$ so we prove the result in that form.

\begin{thm}[universal property of \texorpdfstring{$\Sigma$}{Sigma}-types]
Let $B$ be a type family over $A$ and let $C$ be a type family over $\Sigma_{x:A}B(x)$. Then the map 
\[ \term{ev-pair} : \left( \Sigma_{z: \Sigma_{x:A}B(x)} C(z) \right) \to \left( \Pi_{x:A}\Pi_{y:B(x)} C(x,y) \right)\]
given by $f \mapsto \lambda x.\lambda y. f(x,y)$ is an equivalence
\end{thm}
\begin{proof}
The inverse map is given by the induction principle for $\Sigma$-types:
\[ \ind_\Sigma : \left( \Pi_{x:A}\Pi_{y:B(x)} C(x,y) \right) \to \left( \Sigma_{z: \Sigma_{x:A}B(x)} C(z) \right) .\]
By the computation rule for $\Sigma$ types, we have the homotopy 
\[ \term{refl-htpy} : \term{ev-pair} \circ\ind_\Sigma \sim \id,\]
which shows that $\ind_\Sigma$ is a section of $\term{ev-pair}$.

Function extensionality is used to construct the other homotopy. To define a homotopy $\ind_\Sigma \circ \term{ev-pair} \sim \id$ requires identifications $\ind_\Sigma(\lambda x. \lambda y. f(x,y)) = f$. By function extensionality it suffices to show that
\[ \Pi_{z: \Sigma_{x:A}B(x)} \ind_\Sigma(\lambda x. \lambda y. f(x,y))(t) = f(t).\] By $\Sigma$-induction it suffices to prove this for pairs in which case req require identifications
\[ \ind_\Sigma(\lambda x. \lambda y. f(x,y)(a,b) = f(a,b),\]
but this holds definitionally by the computation rule for $\Sigma$ types.
\end{proof}

In the non-dependent case we have as a corollary:

\begin{cor} For types $A$ and $B$ and $C$,
\[ \term{ev-pair} : (A \times B \to C) \to (A \to B \to C)\]
given by $f \mapsto \lambda a. \lambda b. f(a,b)$ is an equivalence.
\end{cor}

\subsection*{The universal property of identity types}

The universal property for identity types can be understood as an (undirected) type theoretic version of the Yoneda lemma. In the most familiar case, when $B$ is a type family over $A$, it says that the map
\[ \term{ev-refl} : \left( \Pi_{x:A}(a=x) \to B(x) \right) \to B(a)\]
given by $f \mapsto f(a,\refl_a)$ is an equivalence. As before, though, it generalizes to a dependent version of the undirected Yoneda lemma, where the type family $B$ is allowed to depend on $x :A$ and $p: a =x$.

\begin{thm} Consider a type $A$, a term $a :A$, and a type family $B(x,p)$ over $x:A$ and $p: a=x$. Then the map
\[ \term{ev-refl} : \left( \Pi_{x:A}\Pi_{p:a=x} B(x,p) \right) \to B(a,\refl_a)\]
defined by $f \mapsto f(a,\refl_a)$ is an equivalence.
\end{thm}
\begin{proof}
The inverse map is
\[ \pathind_a : B(a,\refl_a) \to \left( \Pi_{x:A}\Pi_{p:a=x} B(x,p) \right),\]
which is a section by the computation rule of the path induction principle.

For the other homotopy $\pathind_a \circ \term{ev-refl} \simeq \id$ let $f : \Pi_{x:A} \Pi_{p:a=x}B(x,p)$. To prove that 
$\pathind_a(f(a,\refl_a)) = f$ we apply function extensionality twice so that it suffices to show that
\[ \Pi_{x:A} \Pi_{p:a=x} \pathind_a(f(a,\refl_a),x,p) = f(x,p).\] This follows from path induction on $p$ since $\pathind_a(f(a,\refl_a),a,\refl_a) \doteq f(a,\refl_a)$ by the computation rule for path induction.
\end{proof}

\subsection*{Composing with equivalences}

Another useful consequence is the fact that $f : A \to B$ is an equivalence if and only if precomposing with $f$ is an equivalence.

\begin{thm} For any map $f \colon A \to B$ the following are logically equivalent:
\begin{enumerate}
\item $f$ is an equivalence
\item For any type family $P$ over $B$ the map
\[ \left( \Pi_{b:B} P(b) \right) \to \left( \Pi_{a:A} P(f(a))\right)\]
given by $h \mapsto h \circ f$ is an equivalence.
\item For any type $C$ the map
\[ (B \to C) \to (A \to C)\]
given by $g \mapsto g \circ f$ is an equivalence.
\end{enumerate}
\end{thm}
\begin{proof}
(ii) immediately implies (iii) by choosing a constant family. 

Assuming (iii) we can take $C=A$ and use the fact that the fibers of the equivalence
\[ - \circ f : (B \to A) \to (A \to A)\]
are contractible to find a point $(h, H) : \fib_{-\circ f}(\id_A) \doteq \Sigma_{h:B \to A} h \circ f = \id_A$.
To see that $h$ is also a section of $f$ we choose $C=B$ and use the fiber of the equivalence
\[ -\circ f : (B \to B) \to (A \to B)\]
over $f$. We have $(\id_B,\refl_f)$ in this fiber but also the point $(f \circ h, fH)$ where $fH$ is the name for the identification derived from the whiskered homotopy $f \cdot H : f \circ h \circ f \sim f$. Since the ifber is contractible, we must have an identification $f \circ h = \id_B$ as desired.

Thus, it remains to prove that (i) implies (ii) which is the hard part. The first step is to promote the equivalence $f$ to a coherently invertible equivalence, involving $g : B \to A$, homopies $G$ and $H$, and a higher homotopy $K : G \cdot f \sim f \cdot H$. We leave the details to \cite[13.4.1]{Rijke}.
\end{proof}

\subsection*{The strong induction principle of \texorpdfstring{$\bN$}{the natural numbers}}

A final application of function extensionality is to prove the strong induction principle for the natural numbers. We give the statement and leave the proof to \cite[\S13.5]{Rijke}. Function extensionality is needed to give the computation rules.

\begin{thm} Consider a type family $P$ over $\bN$ with $p_0 : P(0)$ and
\[ p_S : \Pi_{n: \bN} \left( \Pi_{m: \bN}(m \leq n) \to P(m)\right) \to P(n+1).\]
Then there is a dependent function
\[ \term{strong-ind}_\bN(p_0,p_S) : \Pi_{n : \bN}P(n) \]
so that $\term{strong-ind}_\bN(p_0,p_S,0)  = 0$ and 
\[ \term{strong-ind}_\bN(p_0,p_S, n+1) = p_S(n, \lambda m.\lambda p.\term{strong-ind}_\bN(p_0,p_s,m)).\]
\end{thm}



\section*{October 25: Propositional truncation}

There is a distinction made in mathematics between \emph{properties} and extra \emph{structure}. For instance, we can ask whether a given function $f \colon A \to B$ is surjective or not. In type theory, this is the case just when 
\[ \Pi_{b:B} \Sigma_{a:A} f(a)=b.\]
But we've seen that there is an equivalence of types 
\[ \left( \Pi_{b:B} \Sigma_{a:A} f(a)=b \right) \simeq \left( \Sigma_{s:A \to B} \Pi_{b:B} f(s(b))=b \right).\]
In particular, the data provided by a term in this type provides an explicit section $s : B \to A$ which is additional structure.

To correctly capture the mere property of being surjective, we need a way to assert the \emph{proposition} that a type is inhabited without providing the \emph{data} of a specific inhabitant. The proposition that a type $A$ is inhabited is called the \textbf{propositional truncation} of $A$.

\subsection*{The universal property of propositional truncations}

The propositional truncation of a type $A$ is a type $\mere{A}$ equipped with a map $\eta \colon A \to \mere{A}$ with a universal property to be described. The map ensures that if $a :A$ then the proposition $\mere{A}$ that $A$ is inhabited holds.

\begin{defn} Let $A$ be a type and let $f \colon A \to P$ be a map whose codomain is a proposition. We say that $f$ is a \textbf{propositional truncation} of $A$ if for every proposition $Q$ the map
\[ - \circ f : (P \to Q) \to (A \to Q)\]
is an equivalence.
\end{defn}

This definition describes the \textbf{universal property of the propositional truncation}. It can be reformulated as follows. Note the fiber of the map 
\[ - \circ f : (P \to Q) \to (A \to Q)\]
over $g : A \to Q$ is the type
\[ \sum_{h : P \to Q} h \circ f = g.\]
Thus, $f$ satisfies the universal property of the propositional truncation if and only if these fibers are contractible, meaning that for each map $g : A \to Q$ into a proposition there is a unique map $h : P \to Q$ for wich $h \circ f = g$, a circumstance we might summarize by saying that every map $g : A \to Q$ into a proposition \textbf{extends uniquely along} $f$ as indicated
\[
\begin{tikzcd} A \arrow[dr, "g"] \arrow[d, "f"'] \\ P \arrow[r, dashed, "\exists !"'] & Q
\end{tikzcd}
\]

\begin{rmk} By (weak) function extensionality, the types $(P \to Q)$ and $(A \to Q)$ are propositions, since $Q$ is a proposition. Recall that equivalences between propositions are just logical equivalences. Thus, to prove that \[ - \circ f : (P \to Q) \to (A \to Q)\] is an equivalence, it suffices to construct a function 
\[  (A \to Q) \to (P \to Q)\]
for every proposition $Q$.
\end{rmk}

\begin{prop} Let $A$ be a type and consider two maps $f\colon A \to P$ and $f' \colon A \to P'$ into propositions. If any two of the following hold so does the third:
\begin{enumerate}
\item $f$ is a propositional truncation
\item $f'$ is a propositional truncation
\item There is a (unique) equivalence $P \simeq P'$, commuting with the maps from $A$.
\end{enumerate}
\end{prop}
\begin{proof}
Given (i) and (ii) the universal properties induce maps $P \to P'$ and $P' \to P$ under $A$ that are necessarily an inverse equivalence. This proves (iii). 

Given (iii), we have an equivalence between $(P \to Q)$ and $(P' \to Q)$ and moreover the equivalence $P \leftrightarrow P'$ commutes with the maps from $A$, since by function extensionality any two terms in the types $A \to P$ and $A \to P'$ must be identifiable. But now by the 2-of-3 property for equivalences, if either of the two dashed maps below is an equivalence both are. 
\[
\begin{tikzcd}  (P \to Q) \arrow[rr, leftrightarrow, "\simeq"] \arrow[dr, dashed, "- \circ f"']& & (P' \to Q) \arrow[dl, dashed, "- \circ f'"] \\ & (A \to Q) 
\end{tikzcd}
\] 
Thus when (iii) holds (i) holds if and only if (ii) holds.
\end{proof}

It is tempting to think that a type is inhabited if and only if it is non-empty. That it, it is tempting to wonder whether the canonical map $\lambda x \to \ev_x : A \to \neg\neg A$ is a propositional truncation, since after all $\neg\neg A$ is always a proposition. One can verify that any map $A \to \neg\neg Q$ extends to a map $\neg\neg A \to \neg\neg Q$ proving that the map
\[ (\neg\neg A \to \neg\neg Q) \to (A \to \neg\neg Q)\]
is an equivalence. However, this universal property with respect to doubly negated propositions cannot be extended to general propositions. Indeed, propositional truncations are not guaranteed to exist in Martin L\"{o}f's dependent type theory; see ``Notions of anonymous existence in Martin-L\"{o}f type theory'' by Altenkirch, Coquand, Escard\'{o}, and Kraus for a discussion. However, if we add a new rule to the type theory, we can guarantee their existence.

\subsection*{Propositional truncations as higher inductive types}

The propositional truncation of a general type $A$ can be constructed as an instance of something called a \textbf{higher inductive type}. Higher inductive types are similar to ordinary inductive types but have an additional feature that constructors can be used to generate identifications. As in ordinary inductive types, there are \textbf{point constructors} which introduce new terms, but now these are supplemented by \textbf{path constructors} which introduce new identifications.

In the case of the propositional truncation, for any type $A$, $\mere{A}$ is the type given by one point constructor $\eta \colon A \to \mere{A}$ and one path constructor $\alpha \colon \Pi_{x,y : \mere{A}} x= y$. It follows immediately from the existence of the term $\alpha$ that $\mere{A}$ is a proposition.

The induction principle for the propositional truncation tells us how to construct terms $h : \Pi_{t : \mere{A}} Q(t)$ for any family of types (not only families of propositions). It says that for any family of types $Q$ over $\mere{A}$ if we have
\[ f : \Pi_{a:A}Q(\eta(a))\] and if we can construct identifications $\tr_Q(\alpha(x,y),u)=v$ for all $x,y : \mere{A}$ and all $u : Q(x)$ and $v : Q(y)$ then we obtain a dependent function $h : \Pi_{t : \mere{A}}Q(t)$ equipped with a homotopy $h \circ \eta \sim f$. This homotopy should be thought of as a homotopical version of the computation rule for ordinary inductive types.

\begin{rmk} Although the induction principle for propositional truncations does not a priori require that the type family is a family of propositions, once the second required term
\[ \beta : \Pi_{x,y : \mere{A}} \Pi_{u : Q(x)} \Pi_{v : Q(y)} \tr_Q(\alpha(x,y),u)=v\] exists it follows that $Q$ is a family of propositions. Recall that transporting along a path defines an equivalence and in particular an embedding. Thus
\[ (\tr_Q(\alpha(x,y),u) = \tr_Q(\alpha(x,y),w)) \simeq (u=w)\] for any $u,w : Q(x)$. Taking $v  =  \tr_Q(\alpha(x,y),w))$, we see that $\beta$ defines a term in the left-hand type so it follows that any $u,w : Q(x)$ are identifiable. Thus $Q(x)$ must be a proposition.
\end{rmk}

Since the induction principle of the propositional truncation is only applicable in families of propositions there are no interesting computation rules: there was no need to mention the homotopy $h \circ \eta \sim f$. After all any identification in a proposition just holds!


\begin{thm} The map $\eta \colon A \to \mere{A}$ satisfies the universal property of propositional truncation.
\end{thm}
\begin{proof}
It suffices to construct a map
\[ (A \to Q) \to (\mere{A} \to Q)\]
for any proposition $Q$, which we do by the induction principle of propositional truncation. To construct a term in $\mere{A} \to Q$ we need a term $f : A \to Q$ and also have to prove that $\tr_{Q}(\alpha(x,y), u)=v$ holds for any $u, v :Q$ and any $x,y : \mere{A}$. But $Q$ is a proposition so this is automatic. Thus the map that sends $f : A \to Q$ to the induced function $\mere{A} \to Q$ defines the required function $(A \to Q) \to (\mere{A} \to Q)$.
\end{proof}

Next we show that $\mere{-}$ acts functorially on functions.

\begin{prop} For any pair of types $A$ and $B$ there is a map
\[ \mere{-} \colon (A \to B) \to (\mere{A} \to \mere{B})\]
satisfying $\mere{\id} \sim \id$ and $\mere{g \circ f} \sim \mere{g} \circ \mere{f}$.
\end{prop}
\begin{proof}
For any $f : A \to B$, $\mere{f}$ may be defined to be the unique extension
\[
\begin{tikzcd} A \arrow[r, "f"] \arrow[d, "\eta"'] & B \arrow[d, "\eta"] \\ \mere{A} \arrow[r, dashed, "\mere{f}"'] & \mere{B}
\end{tikzcd}
\]
Note by definition that $\id_{\mere{A}}$ and $\mere{g}\circ\mere{f}$ are similarly extensions of $\id_A$ and $g \circ f$ along $\eta$, and thus must agree up to homotopy with $\mere{\id_A}$ and $\mere{g \circ f}$ by uniqueness.
\end{proof}

\subsection*{Logic in type theory}

Propositional truncations can be used to extend the interpretation of logic in type theory via the Curry-Howard correspondence. This refines our previous discussion by replacing structures with properties.

\begin{defn} Given two propositions $P$ and $Q$ we define their \textbf{disjunction} to be
\[ P \vee Q \coloneq \mere{P + Q}.\]
\end{defn}

\begin{defn} Given a family of propositions $P$ over a type $A$, define
\[ \exists_{x :A} P(x) \coloneq \mere{\Sigma_{x:A}P(x)}.\]
\end{defn}

One can verify the expected logical equivalences involving these notions. For instance:

\begin{prop} For any family of propositions $P$ over $A$ there is a dependent function
\[ \epsilon : \Pi_{a:A} \left( P(a) \to \exists_{x:A}P(x) \right).\]
Furthermore, for any proposition $Q$ we have
\[ \left( (\exists_{x:A}P(x)) \to Q \right) \leftrightarrow \left( \Pi_{x:A}P(x) \to Q \right).\]
\end{prop}
\begin{proof}
Define $\epsilon(a,p) \coloneq \eta(a,p)$. Now consider the following composition of maps
\[ \left( (\exists_{x:A}P(x)) \to Q \right) \to \left( (\Sigma_{x:A} P(x)) \to Q\right) \to \left( \Pi_{x:A}P(x) \to Q \right).\]
The first map is an equivalence by the uinversal property of the propositional truncation while the second is an equivalence by the universal property of $\Sigma$-types.
\end{proof}


\subsection*{Mapping from propositional truncations into sets}

In general it is tricky to map out of propositional truncations into general types but some tricks may help. To define a map $\mere{A} \to X$ one could search for a type family $P$ over $X$ so that $\Sigma_{x:X}P(x)$ is a proposition. Then the universal property of propositional truncation can be used to define a map $\mere{A} \to \Sigma_{x:X}P(x)$ and compositing with $\pr_1$ then defines  map to $X$.

When $X$ is a set there is another strategy. The propositional truncation $\mere{A}$ can be thought of as a quotient of the type $A$ by the equivalence relation that identifies any two terms in $A$ together. We will prove that to extend a map $f : A \to X$ into a set to a map $\mere{A} \to X$ it suffices to define identifications $f(x) =f(y)$ for all $x,y : A$.

\begin{defn} A map $f \colon A \to B$ is \textbf{weakly constant} if it comes with a term in the type
\[ \Pi_{x,y:A} f(x) = f(y).\]
\end{defn}

If $B$ has a term $b$, then weakly constant maps are homotopic to constant maps $\term{const}_b$ but in general there is no requirement for $B$ to have any terms.

\begin{lem} Consider a commutative triangle where $B$ is an arbitrary type
\[
\begin{tikzcd} A \arrow[dr, "f"] \arrow[d, "\eta"'] \\ \mere{A} \arrow[r, "g"'] & B
\end{tikzcd}
\]
then $g$ is weakly constant.
\end{lem}

Kraus observed that any weakly constant map $f : A \to B$ into a set $B$ extends uniquely to a map $\mere{A} \to B$. Thus to define a map $\mere{A} \to B$ into a set it suffices to define $f : A \to B$ and show that it is weakly constant. 

\begin{thm}[Kraus]  For any type $A$ and set $B$ the map
\[  (\mere{A} \to B) \to \Sigma_{f:A \to B} \Pi_{x,y:A} f(x) = f(y)\]
given by $g \mapsto (g \circ \eta, \lambda x .\lambda y. \ap(\alpha(x,y)))$ is an equivalence.
\end{thm}

For proof see \cite[\S 14.4]{Rijke}.

\section*{October 27: The image factorization}

Propositional truncation can be used to define the \textbf{image} of a map $f \colon A \to X$, which can be thought of as the smallest subtype of $X$ that contains all of the values of $f$. More precisely, we'll define a commutative triangle
\[
\begin{tikzcd} A \arrow[rr, "f"] \arrow[dr, "q"'] & & X \\ & \im{f} \arrow[ur, "i", hook]
\end{tikzcd}
\]
in which $i$ is an embedding.

\subsection*{The image of a map}

\begin{defn} Let $f \colon A \to X$ and $g  \colon B \to X$ be maps. A \textbf{morphism} from $f$ to $g$ over $X$ is a map $h \colon A \to B$ together with a homotopy $H \colon f \sim g \circ h$ witnessing commutativity of the following triangle
\[
\begin{tikzcd} A \arrow[rr, "h"] \arrow[dr, "f"'] & & B \arrow[dl, "g"] \\ & X
\end{tikzcd}
\]
Thus we define the type
\[ \hom_X(f,g) \coloneq \Sigma_{h:A \to B} f \sim g \circ h.\]
Composition of morphisms over $X$ is defined by
\[ (k,K) \circ (h,H) \coloneq (k \circ h, H \cdot (K \cdot h)).\]
\end{defn}


\begin{lem} For any $f \colon A \to X$ and any $m : B \to X$ the type, $\hom_X(f,m)$ is a proposition.
\end{lem} 
\begin{proof}
We have an equivalence
\[ \hom_X(f,m) \coloneq  \Sigma_{h:A \to B} f \sim m \circ h \coloneq \Sigma_{h:A \to B} \Pi_{a :A}  f(a) = m(h(a)) \simeq \Pi_{a:A} \Sigma_{b :B} f(a) = m(b) \simeq  \Pi_{a:A} \fib_m(f(a)).\]
Since $m$ is an embedding its fibers are propositions. By weak function extensionality, it follows that $\hom_X(f,m)$ is a proposition.
\end{proof}


\begin{prop}
Consider a commutative triangle 
\[
\begin{tikzcd} A \arrow[rr, "q"] \arrow[dr, "f"'] & & I \arrow[dl, "i"] \\ & X
\end{tikzcd}
\]
with $H : f \sim i \circ q$. 
We say that $i$ satisfies the \textbf{universal property of the image of} $f$ if either of the following logically equivalent conditions hold:
\begin{enumerate}
\item The precomposition function 
\[ - \circ (q,H) : \hom_X(i,m) \to \hom_X(f,m)\]
is an equivalence for any embedding $m \colon B \hookrightarrow X$.
\item For every embedding $m : B \to X$ there is a map
\[ \hom_X(f,m) \to \hom_X(i,m).\]
\end{enumerate}
\end{prop}
\begin{proof}
Since $\hom_X(i,m)$ and $\hom_X(f,m)$ are propositions any map between them is an equivalence if and only if there is exists any map in the other direction.
\end{proof}

Propositional truncation can be used to construct the image of a map:

\begin{defn} For any map $f \colon A \to X$ we define the \textbf{image} of $f$ to be the type
\[ \im{f} \coloneq \Sigma_{x:X} \mere{\fib_f(x)}\]
The \textbf{image inclusion} $i_f \colon \im{f} \to X$ is the first projection $\pr_1$. The map $q_f \colon A \to \im{f}$ is given by
\[ q_f(a) \coloneq (f(a), \eta(a,\refl_{f(a)})).\] The homotopy $I_f : f \sim i_f \circ q_f$ is given by $I_f(a) \coloneq \refl_{f(a)}$.
\end{defn}

We now verify that this construction has the required properties.

\begin{lem} The image inclusion $i_f \colon \im{f} \to X$ is an embedding.
\end{lem}
\begin{proof}
The fiber of $\pr_1 \colon \Sigma_{x:X} \mere{\fib_f(x)} \to X$ is equivalent to $\mere{\fib_f(x)}$, which is a proposition. Thus $i_f \coloneq \pr_1$ is an embedding.
\end{proof}

Theorem \cite[15.1.7]{Rijke} verifies the following:

\begin{thm} For any $f \colon A \to X$ the image inclusion $i_f \colon \im{f} \to X$ satisfies the universal property.
\end{thm}

\subsection*{Surjective maps}

As mentioned above, our previous notion of surjectivity of a map $f \colon A \to B$ is more properly ``split surjectivity'' as 
\[ \left( \Pi_{b:B} \Sigma_{a:A} f(a) =b \right) \simeq \left( \Sigma_{s : A \to B} \Pi_{a:A} f(s(a)) = b\right) \eqcolon  \left( \Sigma_{s: A \to B} f \circ s \sim \id_B \right).\]
The traditional notion is more closely analogous to:

\begin{defn} A map $f \colon A \to B$ is \textbf{surjective} if there is a term in the type
\[ \is{surj}(f) \coloneq \Pi_{b:B} \mere{\fib_f(b)}.\]
\end{defn}

Note that having a section is stronger than surjectivity because we have a map $\fib_f(b) \to \mere{\fib_f(b)}$ but don't typically have a map in the reverse direction.

Surjective maps also have a universal property recorded by the following theorem. See \cite{Rijke} for a proof:

\begin{prop} For a map $f \colon A \to B$, the following are logically equivalent:
\begin{enumerate}
\item $f \colon A \to B$ is surjective.
\item For any family $P$ of propositions over $B$, 
\[ -\circ f : \left( \Pi_{b:B} P(b) \right) \to \left( \Pi_{a:A} P(f(a)) \right)\]
is an equivalence.
\end{enumerate}
\end{prop}
%\begin{proof}
%Suppose that $f$ is surjective and consider the square
%\[
%\begin{tikzcd}
%\Pi_{b:B} P(b) \arrow[r, "-\circ f"] \arrow[d, "{h \mapsto \lambda b. \term{const}_{h(b)}}"'] & \Pi_{a:A} P(f(a)) \\\Pi_{b:B} \mere{\fib_f(b)} \to P(b) \arrow[r, "h \mapsto h(-)\circ \eta"'] & \Pi_{b:B} \fib_f(b) \to P(b) \arrow[u, "{h \mapsto \lambda a . h(f(a), (a, \refl))}"']
%\end{tikzcd}
%\]
%\end{proof}


It follows that:

\begin{cor} For any $f \colon A \to P$ into a proposition, the following are logically equivalent:
\begin{enumerate}
\item $f \colon A \to P$ is a propositional truncation of $A$.
\item $f \colon A \to P$ is surjective.
\end{enumerate}
\end{cor}
\begin{proof}
The second equivalent condition above is the universal property of propositional truncation, except without the hypothesis that $B$ itself is a proposition.
\end{proof}

We now see that the map $q$ in the image factorization is surjective:

\begin{thm} Consider a commutative triangle
\[
\begin{tikzcd} A \arrow[rr, "f"] \arrow[dr, "q"'] & & X \\ & B \arrow[ur, "m"']
\end{tikzcd}
\]
in which $m$ is an embedding. Then $m$ is the image inclusion of $f$ if and only if $q$ is surjective.
\end{thm}
\begin{proof}
First suppose $m$ is the image inclusion of $f$. In that case the function
\[
\begin{tikzcd} \left( \Sigma_{b:B} \mere{\fib_q(b)} \right) \arrow[r, "\pr_1"] & B \arrow[r, "m"] & X
\end{tikzcd}
\]
is an embedding as a composite of embeddings. By the universal property of $m$ there is a unique map 
\[
\begin{tikzcd} B \arrow[dr, "m"'] \arrow[rr, dashed, "h"] & & \left( \Sigma_{b:B} \mere{\fib_q(b)} \right)  \arrow[dl, "m \circ \pr_1"]
\\ & X
\end{tikzcd}
\]
making the triangle commute. Thus $m \circ (\pr_1 \circ h) \sim m$ but also $m \circ \id  \sim m$. By the uniqueness in the universal property of $m$, it follows that $\pr_1 \circ h \sim\id$. Thus $h$ is a section of the projection map. In particular, this defines a dependent function in
\[  \Pi_{b:B} \mere{\fib_q(b)}\]
proving that $q$ is surjective.

Conversely, if $q$ is surjective, we can prove that $m$ is the image of $f$ by constructing an equivalence
\[ \hom_X(f,m') \to \hom_x(m,m')\]
for any embedding $m' \colon B' \to X$. Using the equivalence noted above, we calculate
\[ \hom_X(m,m') \simeq \Pi_{b:B} \fib_{m'}(m(b)) \simeq \Pi_{a:A} \fib_{m'}(m(q(a))) \simeq \Pi_{a:A} \fib_{m'}(f(a)) \simeq \hom_X(f,m'),\] where the second equivalence uses the hypothesis that $q$ is surjective and the third equivalence follows from the homotopy $f \sim m \circ q$.
\end{proof}

\begin{cor} Every map factors uniquely as a surjective map followed by an embedding.
\end{cor}
\begin{proof}
If $f \colon A \to X$ admits two such factorizations $I : f \sim  i\circ q$ and $I': f \sim i' \circ q'$ then both embeddings $i$ and $i'$ have the universal property of the image of $f$. It follows that there is an equivalence $(e,H) : \hom_X(i,i')$ and moreover $(e,H) \circ (q,I) = (q',I')$
\end{proof}

\subsection*{Cantor's diagonalization argument}

\begin{defn} For any type $X$ and universe $\UU$ define the $\UU$-power set of $X$ to be 
\[ P_{\UU}(X) \coloneq X \to \type{Prop}_{\UU}\]
using the universe of propositions in $\UU$.
\end{defn}

\begin{thm} For any type $X$ and universe $\UU$ there is no surjective function $f \colon X \to P_{\UU}(X)$.
\end{thm}
\begin{proof}
We're asked to prove a negation so we may consider a function $f \colon X \to (X \to \type{Prop}_{\UU})$ and suppose that $f$ is surjective. Following Cantor's diagonalization argument, define the subset $P \colon X \to \type{Prop}_{\UU}$ by
\[ P(x) \coloneq \neg(f(x,x)).\]
Since $f$ is assumed to be surjective and our goal is to reach a contradiction, it suffices to show that
\[ \mere{\Sigma_{x:X} f(x)=P} \to \emptyset.\]
Since $\emptyset$ is a proposition, by the universal property of propositional truncation it is equivalent to show that
\[ \left( {\Sigma_{x:X} f(x)=P}  \right) \to \emptyset.\]
So we consider $x:X$ and an identification $f(x)=P$. From the identification it follows that the propositions $f(x,y)$ and $P(y)$ are logically equivalent for all $y : Y$. In particular $f(x,x)$ is logically equivalent to $P(x)$ but since $P(x) \coloneq \neg f(x,x)$ we have a logical equivalence between $f(x,x)$ and $\neg(f(x,x))$. This gives our desired contradiction.
\end{proof}

\section*{November 1: The univalence axiom}

The univalence axiom characterizes the identity type of a universe, asserting that identification between types is equivalent to equivalence between types.  We shall see that there are several equivalent ways to state the univalence axiom arising from the fundamental theorem of identity types.

\subsection*{Equivalent forms of the univalence axiom}

The univalence axiom asserts that the identity type family $A =_\UU B$ is equivalent to the family of equivalences $A \simeq B$. Immediately from our universal property of identity type families, we have three equivalent forms of this result:

\begin{thm} For a universe $\UU$ the following are equivalent:
\begin{enumerate}
\item $\UU$ is \textbf{univalent}: for any $A, B : \UU$, the map
\[ \term{equiv-eq} : (A = B) \to (A \simeq B)\]
defined by $\term{equiv-eq}(\refl) \coloneq \id$ is an equivalence.
\item The type
\[ \Sigma_{B: \UU}A \simeq B\]
is contractible for each $A : \UU$.
\item $\UU$ satisfies the principle of \textbf{equivalence induction}: for any $A : \UU$, and type family $P(X,e)$ indexed by $X : \UU$ and $e : A \simeq X$, the evaluation map
\[ \left( \Pi_{X: \UU} \Pi_{e: A \times X} P(X,e) \right) \to P(A,\id)\]
given by $f \mapsto f(A,\id)$ has a seciton.
\end{enumerate}
\end{thm}

Henceforth, we will assume:
\begin{ax}[univalence]
All postulated universes are univalent. We write $\term{eq-equiv} : (A \simeq B) \to (A=B)$ for the inverse of $\term{equiv-eq}$.
\end{ax}

Our first consequence of univalence is \textbf{propositional extensionality}, which proves that logically equivalent propositions can be identified. To prove this, we first demonstrate that univalence also characterizes the identity type of any subuniverse.

\begin{prop} Let $\UU$ be a univalent universe and let $P$ be family of propositions over $\UU$. Then the family of maps
\[ \term{equiv-eq} : (A =B ) \to (\pr_1(A) \simeq \pr_1(B))\]
indexed by $A,B : \Sigma_{X:\UU} P(X)$ given by $\term{equiv-eq}(\refl) \coloneq \id$ is an equivalence.
\end{prop}
\begin{proof}
We've seen that for any family of propositions, the projection map $\pr_1$ is an embedding. Therefore we see that the asserted map is the composite of the equivalences:
\[
\begin{tikzcd} A =_{\Sigma_{X:\UU} P(X)} B \arrow[r, "\ap_{\pr_1}"] & (\pr_1(A) =_\UU \pr_1(B)) \arrow[r, "\term{equiv-eq}"] & (\pr_1(A) \simeq \pr_1(B)).
\end{tikzcd}\qedhere
\]
\end{proof}

\begin{ntn} Given $A : \Sigma_{X:\UU} P(X)$ it's common to above notation and write $A$ for $\pr_1(A)$. A similar convention makes sense for terms in any subtype $z : \Sigma_{x:A} P(x)$ where $P$ is a family of propositions over $A$. Technically speaking the terms in $\Sigma_{x:A} P(x)$ should be regarded as pairs $(x :A, y : P(x))$ but since $y$ is a term in a proposition no data is lost by forgetting exactly what term is declared beyond simply remembering that $P(x)$ is true for the particular term $x:A$.
\end{ntn}

Important examples of subuniverses include the universe $\type{Prop}_\UU$ or universes $\UU^{\leq k}$ of types at any truncation level.

\begin{thm} Propositions satisfy \textbf{proposition extensionality}: for any propositions $P$ and $Q$ the canonical map
\[ \term{iff-eq} :(P=Q) \to (P \leftrightarrows Q)\]
defined by $\term{iff-eq}(\refl)=(\id,\id)$ is an equivalence. Moreover, the type of propositions is a set.
\end{thm}
\begin{proof}
By function extensionality
\[ \isprop{X} \coloneq \Pi_{x,y : X} x=y\]
is a proposition, so the previous result applies to show that the natural map $(P =Q) \to (P \simeq Q)$ is an equivalence. We've previously defined a logical equivalence $(P \simeq Q) \leftrightarrows (P \leftrightarrows Q)$ which we can now upgrade to an equivalence since by function extensionality both types are propositions.\footnote{In general, $A \simeq B$ is a $k$-type if both $A$ and $B$ are $k$-types.} Thus 
\[ (P=Q) \simeq (P \simeq Q) \simeq (P \leftrightarrows Q).\]
\end{proof}

\begin{cor} The type of decidable propositions in any universe is equivalent to $\bool$.
\end{cor}
\begin{proof}
Since $\Sigma$ distributes over coproducts we have
\[ \Sigma_{P : \Prop} \is{decidable}(P) \coloneq \Sigma_{P: \Prop} P +\neg P \simeq \left( \Sigma_{P: \Prop} P \right) + \left( \Sigma_{Q : \Prop} \neg Q\right).\] We claim that both components are contractible. For the former, we use $(\1,\star)$ as the center of contraction, while for the latter we use $(\emptyset, \id)$. For the contractions, it suffices to show that $\1=P$ for any proposition $P$ with $p : P$ and that $\emptyset = Q$ for any proposition $Q$ with $q: \neg Q$. Both identifications follow easily from propositional extensionality.
\end{proof}

\subsection*{Univalence implies function extensionality}

We've added two big axioms to Martin-L\"{o}f's dependent type theory: univalence and function extensionality. We'll see now that the latter follows from the former using a lemma.

\begin{lem} For any equivalence $e : X \simeq Y$ in a univalent universe $\UU$ and type $A$, the map
\[ e \circ - : (A \to X) \to (A \to Y)\]
is an equivalence.
\end{lem}
\begin{proof}
Since $\UU$ is univalent it satisfies equivalence induction. Consider the type family $P(X,e) \coloneq \isequiv(e \circ -)$. To prove this, it suffices to show that $\id\circ - \colon (A \to X) \to (A \to X)$ is an equivalence. But this map is just the identity map so it follows.
\end{proof}

We'll also use a lemma that we've cited already that does not require univalence, which we now pause to prove:

\begin{lem} For any type family $B$ over $A$ the fiber of the map $\pr_1 \colon \Sigma_{x:A} B(x) \to A$ over $a :A$ is equivalent to $B(a)$.
\end{lem}
\begin{proof}
The comparison maps are defined by
\[
\begin{tikzcd}[row sep=tiny] B(a) \arrow[r, "s"] & \Sigma_{z: \Sigma_{x:A}B(x)} \pr_1(z)=a \arrow[r, "r"] & B(a) \\ b \arrow[r, maps to] & ((a,b),\refl_a) \\
& ((x,y),p) \arrow[r, maps to] & \tr_B(p,y)
\end{tikzcd}
\]
Note $r(s(b)) \doteq \tr_B(\refl_a,b)) \doteq b$ so $\refl$ provides a homotopy $r \circ s \sim \id_{B(a)}$. 

We calculate that
\[ s(r((x,y),p)) \doteq s(\tr_B(p,y)) \doteq ((a, \tr_B(p,y)), \refl_a)\] so for the other homotopy we require a path from $((x,y),p)$ to $((a, \tr_B(p,y)), \refl_a)$ for all $a$, $x$, $y$, and $p$. By path induction on $p$ it suffices to define this in the case where $a$ is $x$ and $p$ is $\refl_x$, in which case the reflexivity path will do.
\end{proof}


\begin{thm} For any universe $\UU$, univalence implies function extensionality.
\end{thm}
\begin{proof} It suffices to show that univalence implies weak function extensionality, so consider a family $B \colon A \to \UU$ of contractible types. It follows that $\pr_1 \colon \Sigma_{x:A} B(x) \to A$ is an equivalence. We'd like to show that $\Pi_{x:A} B(x)$ is contractible.

By the lemma we know that
\[ \pr_1 \circ - \colon (A \to \Sigma_{x:A}B(x)) \to (A \to A)\]
is an equivalence, so in particular the fiber at $\id_A$ must be contractible. We'll show that $\Pi_{x:A} B(x)$ is a retract of this fiber
\[ \Sigma_{f: A \to  \Sigma_{x:A}B(x)} \pr_1 \circ f = \id_A.\]
Note that terms in  $\Pi_{x:A} B(x)$ are sections of the type family, while terms in $\Sigma_{f: A \to  \Sigma_{x:A}B(x)} \pr_1 \circ f = \id_A$ are sections up to homotopy.

The section is defined by
\[ i(f) \coloneq (\lambda x, (x,f(x)), \refl_\id).\]

For the retraction consider $h : A \to \Sigma_{x:A}B(x)$ with $p : \pr_1 \circ h = \id$. We then have $\term{htpy-eq}(p) : \pr_1 \circ h \simeq \id$ and $\pr_2(h(x)) :B(\pr_1(h(x)))$. We define
\[ r((h,p),x) \coloneq \tr_B (\term{htpy-eq}(p,x), \pr_2(h(x))).\]

It remains to construct a homotopy $H : r \circ i \simeq \id$ but in this case we may compute
\[ r(i(f)) \doteq r(\lambda x, (x,f(x)), \refl_\id) \doteq \tr_B(\term{htpy-eq}(\refl,x),\pr_2(x,f(x))) \doteq \tr_B(\refl,f(x)) \doteq f(x).\]
Thus we may define $H(f) \doteq \refl$.
\end{proof}

\subsection*{Maps and families of types}

An important consequence of univalence is the following:

\begin{thm} For any type $A$ and any univalent universe $\UU$ containing $A$ the map
\[ \left( \Sigma_{X:\UU} X \to A \right) \to (A \to \UU)\]
given by $(X,f) \mapsto \fib_f$ is an equivalence.
\end{thm}
\begin{proof}
The map in the converse direction is 
\[ B \mapsto \left( \Sigma_{x:A}B(x),\pr_1\right).\]

To see that this map is a section, we must prove that $\fib_{\pr_1} = B$ for any $B \colon A \to \UU$. By function extensionality and the univalence axiom, this is equivalent to showing that
\[ \Pi_{x:A} \fib_{\pr_1}(x) \simeq B(x), \] which is the result of the lemma in the previous section that does not require univalence.

We must also verify that \[(X,f) = \left( \Sigma_{a:A} \fib_f(a), \pr_1\right).\]
For this, first observe that the identity type $(X,f) = (Y,g)$ in the type $\Sigma_{X: \UU} X \to A$ is equivalent to the type of pairs $(e,f)$ given by $e : X \simeq Y$ and a homotopy $f \sim g \circ e$. This follows from the universal property of identity types using the fact that the type
\[ \Sigma_{Y : \UU} \Sigma_{g \colon Y \to A} \Sigma_{e : X \simeq Y} f \sim g \circ e\]
is contractible by a result we skipped called the ``structure identity principle.'' Using this result it suffices to construct an equivalence $e \colon X \simeq \Sigma_{a:A} \fib_f(a)$ and homotopy $f \sim \pr_1 \circ e$. Intuitively, this follows from the observation that
\[ \Sigma_{a:A} \fib_f(a) \coloneq \Sigma_{a:A} \Sigma_{x:X} f(x) =a \simeq \Sigma_{x:X}\Sigma_{a:A} f(x) =a \simeq \Sigma_{x:X} \1 \simeq X.\]
The full details are left to the exercises.
\end{proof}

We can extend this result as follows. For any family of types $P$ indexed by $\UU$ write 
\[ \UU_P \coloneq \Sigma_{X:\UU} P(X).\] If $P$ is a family of propositions this is a subuniverse of $\UU$ but we can consider this construction more generally. 


\begin{thm} 
For any type $A$, any univalent universe $\UU$ containing $A$, and any family of types $P$ indexed by $\UU$, the map
\[ \left( \Sigma_{X:\UU} \Sigma_{f : X \to A} \Pi_{a:A} P(\fib_f(a)) \right) \to (A \to \UU_P)\]
given by $(X,f,p) \mapsto \lambda a (\fib_f(a)p(a))$ is an equivalence.
\end{thm}
\begin{proof}
The map is homotopic to the composite of equivalences
\[ \Sigma_{X:\UU} \Sigma_{f : X \to A} \Pi_{a:A} P(\fib_f(a)) \simeq \Sigma_{(X,f) : \Sigma_{X:\UU}X \to A} \Pi_{a:A} P(\fib_f(a)) \simeq \Sigma_{B: A \to \UU} \Pi_{a:A}P(B(a)) \simeq A \to \Sigma_{X:\UU} P(X). \qedhere\]
\end{proof}

As a special case, we have an equivalence between families of propositions and embeddings.

\begin{cor} For any type $A$ and any univalent universe $\UU$ containing $A$ the map
\[ \left( \Sigma_{X:\UU} X \hookrightarrow A \right) \to (A \to \Prop)\]
given by $(X,f) \mapsto \fib_f$ is an equivalence.
\end{cor}

\section*{November 3: Classical mathematics with the univalence axiom}

The univalence axiom asserts that identifications $A =_{\UU} B$ in the universe of types are equivalent to equivalences $A \simeq B$ between types. This interpretation is incompatible with an interpretation of type theory in which types are interpreted by sets and identity types are interpreted by the equality relation on those sets. In particular, if $\UU$ is interpreted by a set then for any $A : \UU$ the set intepreting $A =_\UU A$ has exactly one element (the reflexivity term). But 
\[ A \simeq A \coloneq \Sigma_{f : A \to A} \Pi_{a :A} \iscontr{\left(\Sigma_{x:A} f(x) = a \right)}\]
is the set of bijective functions $f \colon A \to A$. In particular, if the set interpreting $A$ has more than one element $A = A$ and $A \simeq A$ cannot be equivalent.

That said, the univalent foundation system \emph{is} consistent with classical mathematics: provided one allows the existence of types, such as $\UU$, which are not mere sets. We'll now explore this compatibility in more detail.

\subsection*{Classical mathematics with the univalence axiom}

The univalence axiom \emph{is} consistent with the axiom of choice provided that care is taken to make choice about sets.

To reason about this concretely, consider the type
\[ \FF_2 \coloneq \Sigma_{X: \UU} \mere{ \Fin_2 \simeq X}\]
of \textbf{2-element types}. Here $\Fin_2 \coloneq \1 + \1$ is the standard 2-element type. We write $i(\star)$ for $\inl(\star) : \Fin_2$ and $\star$ for $\inr(\star) : \Fin_2$.

\begin{prop} The canonical family of maps
\[ \ev_\star : (\Fin_2 \simeq X) \to X\]
is a family of equivalences. Consequently, the type
\[ \Sigma_{X: \FF_2} X \]
of pointed 2-element types is contractible.
\end{prop}
\begin{proof}
By the univalence axiom, the type
\[ \Sigma_{X: \FF_2} \Fin_2 \simeq X\]
is contractible. To see that $\Sigma_{X : \FF_2} X$ is contractible, it suffices to show the maps $\ev_\star : (\Fin_2\simeq X) \to X$ define a family of equivalences, since then they induce an equivalence between the $\Sigma$-types. 

Since $X : \FF_2$ we have an assumption of the form $\mere{\Fin_2 \simeq X}$. Since our goal is to prove a proposition, namely
\[ \isequiv{ (\ev_\star :  (\Fin_2 \simeq X) \to X)}\]
we may assume we have a term $\alpha : \Fin_2 \simeq X$. Now we can proceed by equivalence induction on $\alpha$, meaning it suffices to assume $X$ is $\Fin_2$ and $\alpha$ is the identity equivalence, in which case our goal is to show that
\[ \ev_\star : (\Fin_2 \simeq \Fin_2) \to \Fin_2\]
is an equivalence. In this case we can define an inverse equivalence $g : \Fin_2 \to (\Fin_2 \simeq \Fin_2)$ by $g(\star) \coloneq \id$ and $g(i(\star)) \coloneq \term{succ}_2$ (the non-identity equivalence). It is straightforward to verify that these maps are inverse equivalences.
\end{proof}

Consequently:

\begin{cor} There is no dependent function
\[ \Pi_{X: \FF_2} X\]
that chooses an element of every 2-element set.
\end{cor}
\begin{proof} By the previous proposition we have an equivalence
\[ \left( \Pi_{X: \FF_2} \Fin_2 = X \right) \simeq \left( \Pi_{X: \FF_2} X \right).\]
Note the left-hand side is the type of contracting homotopies for $\FF_2$ using $\Fin_2 : \FF_2$ as the center of contraction. So it suffices to show that $\FF_2$ is not contractible (which can only be the case if this type has no terms). In the previous proposition, we proved that $(\Fin_2 \simeq \Fin_2) \simeq \Fin_2$. Thus, by univalence, the identity type $\Fin_2 = \Fin_2$ of the term $\Fin_2 : \FF_2$ is not contractible. Thus $\FF_2$ must not be contractible.
\end{proof}

As a corollary, we can conclude more generally that there is not way to construct a term of an arbitrary inhabited type.

\begin{thm} If $\UU$ is a univalent universe, then there is no function
\[ \Pi_{A: \UU} \mere{A} \to A.\]
\end{thm}
\begin{proof}
If we had such a term $f$ we could restrict to the type of 2-element types to obtain a function
\[ \Pi_{A: \FF_2} \mere{A} \to A.\]
Since every 2-element type $A$ is inhabited there is a term of type $\mere{A}$. To see this, assume $\mere{\Fin_2 \simeq A}$. To produce a term of type $\mere{A}$ it suffices to assume that $e: \Fin_2 \simeq A$. Now $e(\star) : A$ and $\eta(e(\star)) : \mere{A}$.

 Thus, by evaluating at this term $\eta(e(\star)) : \mere{A}$, we obtain a function
\[ \Pi_{A: \FF_2} A\]
which we've just shown is impossible.
\end{proof}

The statement 
\[ \Pi_{A: \UU} \mere{A} \to A\]
is called the \textbf{principle of global choice}. We've just shown that this principle is incompatible with the univalence axiom: in other words, we cannot obtain a term of type $A$ from the assumption $\mere{A}$ that $A$ is inhabited. What goes wrong? If we did have such a function $\term{global-choice} : \Pi_{A: \UU} \mere{A} \to A$ it would necessarily be invariant under identifications in $\UU$: $\apd_{\term{global-choice}}$ is a dependent function that takes a path $p : A = B$ to an identification between the transport of the function $\term{global-choice} : \mere{A} \to A$ along $p$ and the function $\term{global-choice} : \mere{B}  \to B$. 

By univalence, anything that respects identification between types (which is to say, every construction in homotopy type theory) must also be invariant under equivalences between types. But no choices of an element of $A$ can be invariant under all automorphisms of $A$ (unless $A$ is contractible). For instance, when $A \coloneq \Fin_2$, there is no fixed point of the equivalence $\term{succ}_2 : \Fin_2 \simeq \Fin_2$.


In a sense the principle of global choice is taking the wrong point of view on the traditional axiom of choice, which is really an axiom about \emph{sets}. The inconsistency of the global choice function is tied to the inconsistency in defining any sections of the type family $\lambda X.X : \FF_2 \to \UU$ of inhabited types. Here the fibers of this type family, the 2-element types $X$, are sets, but the base type $\FF_2$ is not a set but rather a 1-type. The axiom of choice is more properly an assertion that only applies to type families $B \colon A \to \UU$ in which both the base type $A$ and the fibers $B(x)$ are sets.

\begin{defn} The \textbf{axiom of choice} asserts that for any family $B$ of inhabited sets indexed by a set $A$ the type of sections of $B$ is also inhabited:
\[ \term{AC}_\UU \coloneq \Pi_{A: \Set}\Pi_{B : A \to \Set} \left( \Pi_{x:A} \mere{B(x)}\right) \to \mere{ \Pi_{x:A} B(x)}.\]
\end{defn}

The consistency of this axiom with univalence is established by Voevodsky's model of homotopy type theory in the category of simplicial sets (when the sets are taken to be classical sets). This version of the axiom of choice asserts essentially that every surjective function between sets has a section.

Similar care has to be taken with the type theoretic formulation of the law of the excluded middle. Recall for a type $X$, 
\[ \is{decidable}(X) \coloneq X + \neg X.\]
With univalence, it is inconsistent to assume that every type is decidable:

\begin{thm} There is no dependent function
\[ \Pi_{X: \UU} \is{decidable}(X).\]
\end{thm}
\begin{proof}
If such a function existed, it would restrict to a dependent function
\[ d : \Pi_{X : \FF_2} \is{decidable}(X).\]
Since each 2-element type is inhabited $\neg (X) \to \emptyset$, so $\is{decidable}(X) \to X$. Thus from $d$ we would obtain a dependent function in $\Pi_{X: \FF_2} X$, which we've seen does not exist.
\end{proof}

The remedy is similar to the discussion above. We've argued that the axiom of choice is really an axiom about \emph{sets}. Similarly, the law of excluded middle is really an axiom about \emph{propositions}, and it is consistent with univalence to assume that every proposition is decidable.

\begin{defn} The \textbf{law of excluded middle} asserts that every proposition is decidable
\[ \term{LEM}_\UU : \Pi_{P :\Prop} \is{decidable}(P).\]
\end{defn}

Again, the consistency of this axiom with univalence is established by Voevodsky's model of homotopy type theory in the category of simplicial sets, in which case the propositions are the subobjects of the one-point simplicial set. 

We will not assume either $\term{AC}_\UU$ or $\term{LEM}_\UU$ going forward but nevertheless it is reassuring to know that these assumptions are consistent.

\section*{November 8: Groups in univalent mathematics}

 In order to demonstrate a typical way to use the univalence axiom, we tour the theory of groups in univalent mathematics. By something called the \emph{structure identity principle}, we will see that univalence implies that isomorphic groups can be \emph{identified}. 
 
 \subsection*{The type of all groups}
 
We introduce the group axioms in stages. Recall a type $A$ is a set if
\[ \Pi_{x,y:A} \Pi_{p,q: x=y} \iscontr{p=q}.\]

\begin{defn} A \textbf{semi-group} consists of a set $G$ equipped with a term of type \type{has-associative-mul}$(G)$, which is the type of pairs $(\mu_G,\term{assoc}_G)$ comprised of
\[ \mu_G : G \to G \to G\] anda  homotopy
\[ \term{assoc}_G : \Pi_{x,y,z:G} \mu_G(\mu_G(x,y),z) = \mu_G(x,\mu_G(y,z)).\]
\end{defn}

We write
\[ \type{Semi-Group} \coloneq \Sigma_{G: \Set}\Sigma_{\mu_G :G \to G \to G} \Pi_{x,y,z:G} \mu_G(\mu_G(x,y),z) = \mu_G(x,\mu_G(y,z)).\]

\begin{defn} A semi-group $G$ is a \textbf{unital semi-group} or a \textbf{monoid} if it comes equipped with a \textbf{unit} $e_G : G$ satisfying left and right unit laws:
\[ \term{left-unit}_G : \Pi_{y:G} \mu_G(e_G,y) = y  \qquad \term{right-unit}_G :\Pi_{x:G} \mu_G(x,e_G) = x.\]
\end{defn}

We write
\[ \is{unital}(G) \coloneq  \Sigma_{e_G: G} \left( \Pi_{y:G} \mu_G(e_G,y) = y  \right) \times \left( \Pi_{x:G} \mu_G(x,e_G) = x \right).\]

In classical mathematics, the unit of a semi-group is unique once it exists. In univalent mathematics, this is expressed by the following result:

\begin{lem} For a semi-group $G$, the type $\is{unital}(G)$ is a proposition.
\end{lem}

In other words, being unital is a \emph{property} of semi-groups rather than \emph{structure} on semi-groups.

\begin{proof}
Since a semi-group $G$ is a set, the types of the left and right unit laws are propositions. Therefore it suffices to show that any two terms $e,e' : G$ satisfying the left and right unit laws can be identified. This is easy using the right-unit law for $e'$ and the left-unit law for $e$:
\[ \inv(\term{right-unit}_G(e)) \cdot \term{left-unit}_G(e') : e = \mu_G(e,e') = e'. \qedhere\]
\end{proof}

\begin{defn} Let $G$ be a unital semi-group. We say $G$ \textbf{has inverses} if it comes with an operation $x \mapsto x^{-1} : G \to G$ satisfying the left and right inverse laws:
\[ \term{left-inv}_G : \Pi_{x:G} \mu_G(x^{-1},x) = e_G \qquad \term{right-inv}_G : \Pi_{x:G} \mu_G(x,x^{-1}) = e_G.\]
\end{defn}

We write
\[ \is{group}(G) \coloneq \Sigma_{e_G: \is{unital}(G)} \Sigma_{x \mapsto x^{-1} :G \to G} \left(\Pi_{x:G} \mu_G(x^{-1},x) = e_G\right) \times \left( \Pi_{x:G} \mu_G(x,x^{-1}) = e_G \right).\]

\begin{lem} For any semi-group $G$, the type $\is{group}(G)$ is a proposition.
\end{lem}
\begin{proof}
We have seen already that $\is{unital}(G)$ is a proposition so it suffices to show that \[
\Sigma_{x \mapsto x^{-1} :G \to G} \left(\Pi_{x:G} \mu_G(x^{-1},x) = e\right) \times \left( \Pi_{x:G} \mu_G(x,x^{-1}) = e \right)\]
is a proposition for any $e : \is{unital}(G)$. Since semi-groups are sets, the types of the inverse laws are propositions, so it suffices to show that any two operations satisfying the inverse laws are homotopic. To that end consider $x \mapsto x^{-1}$ and $x \mapsto \bar{x}^{-1}$. Then we have
\[ x^{-1} = \mu_G(e, x^{-1}) = \mu_G(\mu_G(\bar{x}^{-1},x),x^{-1}) = \mu_G(\bar{x}^{-1},\mu_G(x,x^{-1}) = \mu_G(\bar{x}^{-1}, e) = \bar{x}^{-1}. \qedhere\]
\end{proof}

\begin{defn} A \textbf{group} is a unital semi-group with inverses. We write 
\[\type{Group} \coloneq \Sigma_{G: \Set}\Sigma_{\mu_G :G \to G \to G} \Sigma_{\term{assoc}_G : \Pi_{x,y,z:G} \mu_G(\mu_G(x,y),z) = \mu_G(x,\mu_G(y,z))} \is{group}(G).\]
 for the type of all groups in $\UU$.
\end{defn}

Recall a groupoid is a ``group with many objects.'' This suggests that one-object groupoids give examples of groups:

\begin{ex} An important example of groups consist of \textbf{loop spaces} $x=_Xx$ for any 1-type $X$ and any $x:X$. We write $\Omega(X,x)$ for the loop space. Since $X$ is a $-1$ type $\Omega(X,x) \coloneq x=_Xx$ is a set. Then we have
\[ \refl_x : \Omega(X,x) \qquad \inv : \Omega(X,x) \to \Omega(X,x) \qquad \concat : \Omega(X,x) \to \Omega(X,x) \to \Omega(X,x)\]
satisfying all of the required laws, as special cases of the groupoid laws for identity types.
\end{ex}

\begin{ex} The type of integers $\bZ \coloneq \bN + (\1 + \bN)$ can be given the structure of a group with addition as the group operation. The proof that $\bZ$ is a set is similar to the proof that $\bN$ is a set. The group laws were shown in the exercises.
\end{ex}

\begin{ex}
A final example is given by an \textbf{automorphism group} of a set. Given a set $X$ define
\[ \type{Aut}(X) \coloneq (X \simeq X).\]
The group operation is composition of equivalences and the unit is the identity function. While composition os functions is strictly associative and strictly unital, composition of equivalences only satisfies the group laws up to identification because this also requires a composite of the equivalence data.

As an important special case we define the \textbf{symmetric groups}
\[ S_n \coloneq \type{Aut}(\Fin_n).\]
\end{ex}

\subsection*{Group homomorphisms}

\begin{defn} Let $G$ and $H$ be semi-groups. A \textbf{homomorphism} of semi-groups is a pair $(f,\mu_f)$ comprised of a function $f \colon G \to H$ between their underlying types and a term
\[ \mu_f : \Pi_{x,y:G} f(\mu_G(x,y)) = \mu_H(f(x),f(y))\]
witnessing that $f$ preserves the binary operations. We write
\[ \type{hom}(G,H) \coloneq \Sigma_{f:G \to H} \Pi_{x,y:G}  f(\mu_G(x,y)) = \mu_H(f(x),f(y))\]
for the type of all semi-group homomorphisms.
\end{defn}

Since it is a property for a function to preserve the multiplication of a semi-group, it follows that the identity type between two terms $f,f' :\type{hom}(G,H)$ is equivalent to the type of homotopies between their underlying functions. In particular $\type{hom}(G,H)$ is a set. 

\begin{ex} The \textbf{identity homomorphism} on a semi-group $G$ is given by $\id: G \to G$ and \[\lambda x.\lambda y. \refl_{\mu_G(x,y)} : \Pi_{x,y:G} \mu_G(x,y) = \mu_G(x,y).\]
\end{ex}

\begin{rmk} If $f \colon G \to H$ and $g \colon H \to K$ are semi-group homomorphisms, their composite $g \circ f \colon G \to K$ is also a semi-group homomorphism using the composite identification
\[ g(f(\mu_G(x,y)) = g(\mu_H(f(x),f(y)) = \mu_K(g(f(x)), g(f(y))).\]

The following coherence laws can be verified
\[ \id \circ f = f \qquad g \circ \id = g \qquad (h \circ g) \circ f = h \circ (g \circ f),\]
using the fact that identity types of semi-group homomorphisms are equivalent to the identity types between the underlying functions.
\end{rmk}

\begin{defn} Let $G$ and $H$ be groups. A \textbf{homomorphism} of groups from $G$ to $H$ is defined to be a semi-group homomorphism between their underlying semi-groups. We will write
\[ \type{hom}(G,H)\]
for the type of all group homomorphisms.
\end{defn}

Why this definition? On the one hand, you might remember that the classical definition of group homomorphism only requires compatibility with multiplication: the preservation of units and inverses comes for free. If you recall the proof of this, you'll be lead to define, for instance, a composite identification:
\[ e_H = \mu_H(f(e_G), f(e_G)^{-1}) = \mu_H(f(\mu_G(e_G,e_G)), f(e_G)^{-1}) = \mu_H(\mu_H(f(e_G),f(e_G)), f(e_G)^{-1}) \] \[ = \mu_H(f(e_G), \mu_H(f(e_G),f(e_G)^{-1}) = \mu_H(f(e_G), e_H) = f(e_G).\]
Since the identity types in a set are propositions, there is no data defined by an explicit identification beyond its mere existence. 
\subsection*{Isomorphic groups are equal}

\begin{defn}A  homomorphism of semi-groups $h : \type{hom}(G,H)$ is said to be an \textbf{isomorphism} if it comes with a term of type $\is{iso}(h)$ consisting of triples $(h^{-1},p,q)$ given by $h^{-1} : \type{hom}(H,G)$ and
\[ p : h^{-1} \circ h = \id_G \qquad \text{and} \qquad q : h \circ h^{-1} = \id_H\]
witnessing that $h^{-1}$ satisfies the inverse laws.
\end{defn}

Write \[G \cong H \coloneq \Sigma_{h: \type{hom}(G,H)} \Sigma_{k: \type{hom}(H,G)} (k \circ h = \id_G) \times (h \circ k = \id_H).\]

If $h$ is an isomorphism its inverse is unique. In other words, being an isomorphism is a property:

\begin{lem} For any semi-group homomorphism $h : \type{hom}(G,H)$, the type $\is{iso}(h)$ is a proposition. Thus, for any two semi-groups $G \cong H$ is a set.
\end{lem}
\begin{proof}
Suppose $k, k' : \type{hom}(H,G)$ are two inverses of $h$. Since the type of semi-group homomorphisms is a set, we have that $h \circ k = \id$ and $k \circ h = \id$ are propositions, and similarly for $k'$, so it suffices to check that $k = k'$. We've observed that this identity type is equivalent to the type of homotopies $k \sim k'$ and we can construct one by the usual argument: applying $k$ to the inverse of the coherence $h \circ k' = \id$ at $y : H$ and concatenating with the coherence $k \circ h = \id$ at $k'(y) : G$ yields:
\[ k(y) = k(h(k'(y))) = k'(y).\]
\end{proof}

\begin{lem} A semi-group homomorphism $h : \type{hom}(G,H)$ is an isomorphism if and only if its underlying map is an equivalence. Consequently there is an equivalence 
\[ (G \cong H ) \simeq \Sigma_{e: G \simeq H} \Pi_{x,y: G} e(\mu_G(x,y)) = \mu_H(e(x),e(y)).\]
\end{lem}
\begin{proof}
If $h : \type{hom}(G,H)$ is an isomorphism, then the inverse semi-group homomorphism also provides an inverse to the underlying map of $h$. Thus $h$ must be an equivalence.

For the converse, suppose $h : \type{hom}(G,H)$ is a semi-group homomorphism whose underlying map $h : G \to H$ is an equivalence, with equivalence inverse $k : H \to G$. Then for all $x,y : G$
\[ h( \mu_G(k(x), k(y))) = \mu_H (h(k(x)), h(k(y))) = \mu_H(x,y) = hk(\mu_H(x,y)).\]
Since $h$ is an equivalence it follows that $\mu_G(k(x),k(y)) = k(\mu_H(x,y))$ so $k$ is a semi-group homomorphism. The homotopies of the equivalence provide the homotopies of the group isomorphism.
\end{proof}

\begin{defn} Let $G$ and $H$ be semi-groups. We define the map
\[
\term{iso-eq} : (G=H) \to (G \cong H)\]
by path induction taking $\refl_G$ to $\id_G$. 
\end{defn}

\begin{thm} The map 
\[
\term{iso-eq} : (G=H) \to (G \cong H)\]
is an equivalence for any two semi-groups $G$ and $H$.
\end{thm}
\begin{proof}
By the fundamental theory of identity types, it suffices to show that 
\[ \Sigma_{G' : \type{Semi-Group}} G \cong G'\]
is contractible. This is equivalent to the type
\[ \Sigma_{G' : \type{Semi-Group}} \Sigma_{e: G \simeq G'} \Pi_{x,y: G} e(\mu_G(x,y)) = \mu_{G'}(e(x),e(y)).\]
Since
\[ \type{Semi-Group} \coloneq \Sigma_{G: \Set} \type{has-associative-mul}(G),\]
we have
\[ \left( \Sigma_{G' : \type{Semi-Group}} \Sigma_{e: G \simeq G'} \Pi_{x,y: G} e(\mu_G(x,y)) = \mu_{G'}(e(x),e(y)) \right) \] \[\simeq \left( \Sigma_{G' : \Set} \Sigma_{e : G \simeq G'} \Sigma_{ \mu_{G'} : \type{has-associative-mul}(G')}\Pi_{x,y: G} e(\mu_G(x,y)) = \mu_{G'}(e(x),e(y)) \right). \]
Thus, it suffices to show that the type 
$\Sigma_{G' : \Set} G \simeq G'$
is contractible, which follows by the univalence axiom, and uses $(G,\id_G)$ as the center of contraction, and then show that the type
\[ \Sigma_{\mu' : \type{has-associative-mul}(G)} \Pi_{x,y: G} \mu_G(x,y) = \mu_{G'}(x,y)\] is contractible. This holds by function extensionality, with $(\mu_G, \refl)$ as the center of contraction.
\end{proof}

\begin{cor} The type $\type{Semi-Group}$ is a 1-type.
\end{cor}
\begin{proof}
We've just shown that $(G=H) \simeq (G \cong H)$ for semi-groups $G$ and $H$. It's straightforward to see, using the fact that $G$ and $H$ are sets, that $G \cong H$ is a set.
\end{proof}

The results for groups follow similarly though the types $G =_{\type{Semi-Group}} H$ and $G =_{\type{Group}} H$ are not equal. 

\begin{defn} Let $G$ and $H$ be groups. We define the map
\[
\term{iso-eq} : (G=H) \to (G \cong H)\]
by path induction taking $\refl_G$ to $\id_G$. 
\end{defn}

\begin{thm} The map 
\[
\term{iso-eq} : (G=H) \to (G \cong H)\]
is an equivalence for any two groups $G$ and $H$.
\end{thm}
\begin{proof}
Let $G$ and $H$ be group and write $UG$ and $UH$ for their underlying semi-groups. Then we have a commutative triangle
\[
\begin{tikzcd} (G = H) \arrow[rr, "{\ap_{\pr_1}}"] \arrow[dr, "\term{iso-eq}"'] & & (UG = UH) \arrow[dl, "\term{iso-eq}"] \\ & (G \simeq H)
\end{tikzcd}
\]
Since being a group is a property of semi-groups, the projection map $\pr_1 : \type{Group} \to \type{Semi-Group}$ is an embedding. Thus the top map is an equivalence, as is the right map by the previous theorem. The result follows.
\end{proof}

\begin{cor} The type of groups is a 1-type.
\end{cor}

These results follow a general pattern. The \textbf{Structure Identity Principle} states that any property of set-level structures (e.g., posets, groups, rings, fields) definable in Univalent Foundations is invariant under isomorphism. More specifically, identifications of structures coincide with isomorphisms. There is some subtlety in the correct formulation of this result which we illustrate next time by considering categories in univalent mathematics.

\section*{November 10: Categories in univalent mathematics}

Traditional group theory fits very comfortably into the set-theoretical foundations of mathematics but category theory is less comfortable there. A key problem is that most of category theory is invariant under weaker notions of ``sameness'' than equality, such as isomorphism in ac category of equivalence of categories, in a way that set theory fails to capture. But this is the same sort of problem that the univalence axiom solves for types. Thus, in univalent foundations, it makes sense to consider a notion of ``category'' in which equality of objects is identified with isomorphism in a similar way. 

We'll actually introduce two definitions, which following \cite{book-hott} are called \emph{precategories} and \emph{categories}, the latter of which might be thought of as the ``univalent'' categories. 

An illustration of the difference between precategories and categories comes from the behavior of equivalences between such notions. In classical mathematics the statement that ``every fully faithful and essentially surjective functor is an equivalence of categories'' is equivalent to the axiom of choice. For precategories, there is no consistent axiom of choice, which can make it true. For categories, it is provable without any axiom of choice. We won't have time to prove this here but see \cite[\S 9.4]{book-hott}, which also explores a third notion of \emph{strict categories}.


\subsection*{Precategories and categories}

\begin{defn} A \textbf{precategory} $A$ consists of:
\begin{itemize}
\item A type $A_0$ of objects. We write $a : A$ to mean $a : A_0$.
\item For each $a, b : A$, a set $\hom_A(a,b)$ of \textbf{arrows} or \textbf{morphisms}
\item For each $a :A$ a morphism $1_a : \hom_A(a,a)$.
\item For each $a,b,c : A$ a function
\[ \hom_A(b,c) \to \hom_A(a,b) \to \hom_A(a,c)\] denoted by $g \mapsto f \mapsto g \circ f$.
\item For each $a, b :A$ and $f : \hom_A(a,b)$ proofs that $f = 1_b \circ f$ and $f = f \circ 1_a$.
\item For each $a,b,c,d : A$ and $f : \hom_A(a,b)$, $g : \hom_A(b,c)$ and $h : \hom_A(c,d)$ a proof that $h \circ (g \circ f) = (h \circ g) \circ f$.
\end{itemize}
\end{defn}

The problem with precategories is there are a priori two distinct notions of sameness for terms $a,b :A$, one given by the identity type and the other given by the categorical notion of isomorphism:

\begin{defn} A term $f : \hom_A(a,b)$ is an \textbf{isomorphism} if there is a term of type
\[ \is{iso}(f) \coloneq \Sigma_{g: \hom_A(b,a)} (g \circ f= 1_a) \times (f \circ g = 1_b).\]
\end{defn}

For instance, $1_a$ is an isomorphism with $1_a$ and the unit coherences defining the required term of $\is{iso}(f)$.

\begin{lem} For any $f : \hom_A(a,b)$, the type $\is{iso}(f)$ is a proposition. Thus the type
\[ a \cong b \coloneq \Sigma_{f: \hom_A(a,b)} \is{iso}(f)\] 
is a set.
\end{lem}
\begin{proof}
Given $(g,\eta,\epsilon), (g', \eta',\epsilon') : \is{iso}(f)$ we must construct an identification between them. Since hom-sets are sets, their identity types are propositions and it suffices to construct an identification $g = g'$. For this we have
\[ g' = 1_a \circ g' = (g \circ f) \circ g' = g \circ (f \circ g') = g.\]

Thus $\is{iso} : \hom_A(a,b) \to \Prop$ is a family of propositions, so $\pr_1 : a \cong b \to \hom_A(a,b)$ is an embedding. Since $\hom_A(a,b)$ is a set, $a \cong b$ must be as well.
\end{proof}

When $f$ is an isomorphism, $\is{iso}(f)$ is contractible. In particular, we may write $f^{-1} : \hom_A(b,a)$ for its uniquely determined inverse morphism.

\begin{defn} If $A$ is a precategory and $a,b :A$ there is a map
\[ \term{iso-id} : (a=b) \to (a \cong b)\] defined by path induction by $\refl_a \mapsto \id_a$.
\end{defn}

A category is a precategory with a unified notion of equivalence.

\begin{defn} A \textbf{category} is a precategory so that for all $a,b$ the map $\term{iso-id} : (a=b) \to (a \cong b)$ is an equivalence.
\end{defn}

\begin{cor} In any category, the type of objects is a 1-type.
\end{cor}
\begin{proof}
Since $a \cong b$ is a set, $a=b$ is a set, making $A$ into a 1-type.
\end{proof}

\begin{ex} The type $\Set$ is a category with $\hom(A,B) \coloneq A \to B$ in any universe large enough to contain $\Set$. Here we have $(A \cong B) \simeq (A \simeq B) \simeq (A = B)$ by the univalence axiom.
\end{ex}

\begin{ex} The types $\type{SemiGroup}$ and $\type{Group}$ are also categories in sufficiently large universes with the hom-sets given by the types of (semi-)group homomorphisms.
\end{ex}

\begin{ex} If $X$ is any 1-type, there is a category with $X$ as its type of objects and $\hom(x,y) \coloneq (x=y)$. In this category every morphism is an isomorphism, so $X$ might be called a \textbf{groupoid}. 
\end{ex}

\begin{ex} A precategory $A$ in which each set $\hom_A(a,b)$ is a proposition is called a \textbf{preorder}. Equivalently, this data is given by a type $A_0$ equipped with a proposition-valued relation $\leq$ that is reflexive $(a \leq a)$ and transitive $(b\leq c) \to (a \leq b) \to (a \leq c)$.

A unique morphism $f : \hom_A(a,b) \simeq a \leq b$ is an isomorphism just when $b \leq a$. Thus $a \cong b$ is the proposition $(a \leq b) \times (b \leq a)$. Thus, we see that a preorder is category just when $a=b$ is a proposition and the relation $\leq$ is anti-symmetric: $(a \leq b) \times (b \leq a) \to (a=b)$.
\end{ex}

\begin{ex} If $A$ is a category then $A_0$ is a set if and only if $a \cong b$ is a proposition. In particular, every automorphism in $a \cong a$ must be an identity. In fact, it's typically understood to mean that every \emph{isomorphism} in $a \cong b$ is an identity, meaning it corresponds to $\id_a : a \cong a$ under the transport equivalence $(a \cong a) \simeq (a \cong b)$ induced by the corresponding path in $a =b$. This is a strong condition on a category that goes by the name of \textbf{gaunt}.
\end{ex}

\ifmine
Since gaunt categories are relatively special we typically restrict the notion of strict category as follows:

\begin{defn} A \textbf{strict category} is a precategory whose type of objects is a set.
\end{defn}

Note that strict categories are not necessarily categories!
\fi

\subsection*{Functors and natural transformations}

\begin{defn} For precategories $A$ and $B$ a \textbf{functor} $F \colon A \to B$ consists of
\begin{itemize}
\item A function $F_0 : A_0 \to B_0$ generally also denoted by $F$.
\item For each $a,b :A$, a function $F_{a,b} : \hom_A(a,b) \to \hom_B(Fa,Fb)$.
\item Proofs, for each $a :A$, that $F(1_a) = 1_{Fa}$.
\item Proofs, for each $a,b, c:A$, $f: \hom_A(a,b)$ and $g: \hom_A(b,c)$ that $F(g \circ f) = Fg \circ Ff$.
\end{itemize}
\end{defn}

%Note that functors $F \colon A \to B$ and $G \colon B \to C$ can be composed by composing the functions $F_0$ and $G_0$ and $F_{a,b}$ and $G_{Fa,Fb}$.

\begin{defn} For functors $F,G: A \to B$ between precategories a \textbf{natural transformation} $\gamma \colon F \to G$ consists of
\begin{itemize}
\item A dependent function $\gamma : \Pi_{a:A} \hom_B(Fa,Ga)$ defining the components of the natural transformation.
\item For each $a,b :A$ and $f: \hom_A(a,b)$, a proof that $Gf \circ \gamma_a = \gamma_b \circ Ff$, the naturality axiom.
\end{itemize}
\end{defn}

\begin{defn} For precategories $A$ and $B$ there is a pre-category $B^A$ defined by taking $(B^A)_0$ to be the type of functors $A \to B$ and $\hom_{B^A}(F,G)$ to be the type of natural transformations from $F$ to $G$. Note that since the hom types in precategories are sets, two natural transformations $\gamma, \gamma' : F \to G$ are equal just when their components are equal. In particular, by function extensionality, the type of natural transformations is a set.

The identity element $1_F$ is the natural transformation whose components $(1_F)_a \coloneq 1_{Fa}$ are identities. Similarly, composition of natural transformations is componentwise.
\end{defn}

The traditional categorical proof shows:

\begin{lem} A natural transformation $\gamma \colon F \to G$ is an isomorphism if and only if each of its components are isomorphisms. \qed
\end{lem}

Using this, we may show

\begin{thm} If $A$ is a precategory and $B$ is a category then $B^A$ is a category.
\end{thm}
\begin{proof}
For functors $F, G : A \to B$ we must show that $\term{iso-id} : (F =G) \to (F \cong G)$ is an equivalence. To define its inverse suppose $\gamma : F \cong G$. By the lemma this means we have an isomorphism $\gamma_a : \hom_B(Fa,Ga)$ for every $a :A$. Since $B$ is a category, we have identities $\term{id-iso}(\gamma_a) : Fa =_B Ga$. By function extensionality this proves that $\bar{\gamma} : F_0 =_{A_0 \to B_0} G_0$. 

Our next task is to show that $F_{a,b} : \hom_A(a,b) \to \hom_B(Fa,Fb)$ equals $G_{a,b} : \hom_A(a,b) \to \hom_B(Ga,Gb)$ after transporting the former along $\bar{\gamma}$. In fact this is all that remains to show since the final axioms of a functor are propositions. By a lemma below, for $f : \hom_A(a,b)$ the transport of $Ff : \hom_B(Fa,Fb)$ along $\bar{\gamma}$ is equal to the composite $\gamma_b \circ Ff \circ \gamma_a^{-1} : \hom_B(Ga,Gb)$. By naturality and $\is{iso}(\gamma_a)$, we have
\[ \gamma_b \circ Ff \circ \gamma_a^{-1} = Gf \circ \gamma_a \circ \gamma_a^{-1} = Gf\] as required.

This defines a function $(F \cong G) \to (F=G)$. A further argument is needed to prove that this function is an inverse equivalence to $\term{iso-id} : (F=G) \to (F \cong G)$. See \cite[9.2.5]{book-hott}.
\end{proof}

\begin{lem} For a precategory $A$, $f : \hom_A(a,b)$ and $p : a = a'$ and $q : b = b'$
\[ \tr_{\hom}((p,q),f) = \term{iso-id}(q) \circ f \circ \term{iso-id}(p)^{-1}.\]
\end{lem}
\begin{proof} By path induction, we may assume $p$ is $\refl_a$ and $q$ is $\refl_b$ in which case the transport of $f$ is just $f$. We have $\term{iso-id}(\refl) = \id$ and $f = \id_b \circ f \circ \id_a^{-1}$ so the result follows.
\end{proof}

\subsection*{Equivalence of categories}
 
We now study the various ways in which a functor $F \colon A \to B$ can define an equivalence of categories. As with the question of when a function defines an equivalence of types, there is some subtlety in formulating a \emph{proposition} $\is{equiv}(F)$. One solution is to use the concept of an adjunction.

\begin{defn} A functor $F \colon A \to B$ between precategories is a \textbf{left adjoint} when there exists:
\begin{itemize}
\item a functor $G \colon B \to A$,
\item a natural transformation $\eta \colon 1_A \to G \circ F$.
\item a natural transformation $\epsilon \colon F \circ G \to 1_B$.
\item proofs that $G\epsilon \cdot \eta G = \id_G$ and $\epsilon F \cdot F\eta = \id_F$.
\end{itemize}
\end{defn}

This definition uses various concepts we have not defined: identity functors, composition of functors, whiskering of functors and natural transformations, and identity natural transformations.

Importantly:

\begin{lem} If $F \colon A \to B$ is a functor and $A$ is a category then $\is{left-adjoint}(F)$ is a proposition.
\end{lem}
\begin{proof}
Given two terms $(G,\eta,\epsilon), (G',\eta',\epsilon') : \is{left-adjoint}(F)$ the standard category theoretic argument constructs a unique natural isomorphism $\gamma : G \to G'$ commuting with the natural transformations. If $A$ is a category then $A^B$ is a category so $\term{id-iso} : G \cong G' \to G = G'$ converts $\gamma$ into an identity so that the transport of $\eta$ and $\epsilon$ along this path is identifiable with $\eta'$ and $\epsilon'$.
\end{proof}

\begin{defn} A functor $F \colon A \to B$ defines an \textbf{equivalence} of precategories if $F$ is a left adjoint in which $\eta$ and $\epsilon$ are isomorphisms.
\end{defn}

We write $A \simeq B \coloneq \Sigma_{F: A \to B} \is{equiv}(F)$, with the sum over functors between precategories, for the type of equivalences from $A$ to $B$. We state the following results and refer to \cite{book-hott} for their proofs.

\begin{lem} For precategories $A$ and $B$ and a functor $F \colon A \to B$ the following types are equivalent:
\begin{enumerate}
\item $\is{equiv}(F)$ asserting that $F$ is an equivalence of precategories.
\item The type
\[ \left( \Pi_{a,a': A} \is{equiv}(F_{a,a'}) \right) \times \left( \Pi_{b:B} \Sigma_{a:A} Fa \cong b \right)\]
 asserting that $F$ is \textbf{fully faithful}, meaning each $F_{a,a'} : \hom_A(a,a') \to \hom_B(Fa,Fa')$ is an equivalence, and \textbf{split essentially surjective}, meaning $\Pi_{b:B} \Sigma_{a:A} Fa \cong b$.
\end{enumerate}
\end{lem}

If $A$ is a category and $F$ is fully faithful then for any $b : B$ the type $\Sigma_{a:A} Fa \cong b$ is a proposition: if given $(a,f),(a',f') : \Sigma_{a:A} Fa \cong b$ then $f'^{-1} \circ f \colon Fa \cong Fa'$ is an isomorphism. Since $F$ is fully faithful then $a \cong a'$ and since $A$ is a category $a=a'$ and one can verify that transport along this path identifies $f$ with $f'$. In particular, in this context the notion of split essentially surjective could be replaced by the notion of essentially surjective, meaning $\Pi_{b:B} \|\Sigma_{a:A} Fa \cong b\|$, without change.

\begin{defn} A functor $F \colon A \to B$ is an \textbf{isomorphism} of precategories if $F$ is fully faithful and $F_0 : A_0 \to B_0$ is an equivalence of types.
\end{defn}

We write $A \cong B$ for the type of isomorphisms between precategories.

\begin{lem} For categories $A$ and $B$, a functor $F \colon A \to B$ is an equivalence if and only if it is an isomorphism of categories.
\end{lem}

By univalence: 
\begin{lem} If $A$ and $B$ are precategories then the function 
\[ \term{iso-id} : (A=B) \to (A \cong B)\]
defined by induction by $\refl_A \mapsto 1_A$ is an equivalence.
\end{lem}

Thus:

\begin{thm} If $A$ and $B$ are categories, then the function 
\[ \term{equiv-id} : (A=B) \to (A \simeq B)\]
defined by induction by $\refl_A\mapsto 1_A$ is an equivalence.
\end{thm}


\section*{November 15: The real numbers in univalent mathematics}

In this section we'll describe and compare two different approaches to constructing the real numbers in univalent mathematics following \cite[Chapter 10]{book-hott}. The first of these constructs the \emph{Cauchy reals} using Cauchy sequences, while the second constructs the \emph{Dedekind reals}, using Dedekind cuts. Our constructions will use some properties of the universe $\Set$ of sets that we have not proven, which we will provide references for.

\subsection*{The rational numbers}

To define the rational numbers we need to know how to form set quotients in homotopy type theory. Let $A$ be a set and let $R \colon A \to A \to \Prop$ be a propositional relation on $A$ that is reflexive, symmetric, and transitive, as discussed above. 

\begin{defn} Define $A/R$ to be the higher inductive type generated by
\begin{enumerate}
\item A function $q \colon A \to A/R$.
\item For each $a,b :A$ so that $R(a,b)$, an equality $q(a)=q(b)$.
\item The 0-truncation constructor: for all $x,y : A/R$ and $r,s : x= y$, an equality $r=s$.
\end{enumerate}
\end{defn}

Another equivalent construction is described in \cite[\S 18.1]{Rijke}. For example, this construction gives us a new way to think about the type of integers $\ZZ$.

\begin{ex} We may define the integers $\ZZ$ as the set quotient $\NN \times \NN_{/\sim}$ where $\sim$ is the equivalence relation defined by
\[ (a,b) \sim (c,d) \coloneq (a+d = b +c).\]
\end{ex}

In this case, there are canonical representatives for equivalence classes: each $(a,b) : \NN \times \NN$ is equivalent to a pair of the form $(n,0)$ or $(0,n)$ dependent on whether $a \geq b$ or not (and this relation is decidable). The function $r \colon \NN \times \NN \to \NN \times \NN$ defined by
\[ r(a,b) \coloneq \begin{cases} (a-b,0) & a \geq b \\ (0, b-a) & a < b \end{cases}\]
defines an \textbf{idempotent}, meaning $r \circ r =r $. 

\begin{lem} Suppose $\sim$ is an equivalence relation on $A$ and there is an idempotent $r \colon A \to A$ for all $x,y :A$ so that $(r(x)=r(y)) \simeq (x \sim y)$. Then the type
\[ A/\sim \coloneq \Sigma_{x:A} r(x)=x\]
is the set quotient of $A$ by $\sim$. In other words, there is a map $q \colon A \to A/\sim$ such that for every set $B$ the type $(A /\sim) \to B$ is equivalent to
\[ \Sigma_{g : A \to B} \Pi_{x,y:A} (x \sim y) \to (g(x)=g(y))\]
via precomposition with $q$.
\end{lem}
 See \cite[6.10.8]{book-hott}.
 
\begin{defn} Similarly we define the rationals $\QQ$ as the quotient $(\ZZ \times \NN)/\sim$ by the equivalence relation
\[ (u,a) \sim (v,b) \coloneq (u(b+1) = v(a+1)).\]
Here $(u,a)$ represents the rational numbers $u/(a+1)$, with the 1 added so we don't have to worry about division by 0. 
\end{defn}

Again we have an idempotent $r \colon \ZZ \times \NN \to \ZZ \times \NN$ that sends a pair $(u,a)$ to $r(u,a) \coloneq (u',a')$ where $u'/(a'+1)$ is the same fraction as $u/(a+1)$ but in lowest terms. It follows that $\QQ$ is a set with decidable equality and decidable order. 

\subsection*{Dedekind reals}
 
 The Dedekind reals are defined to be the set of Dedekind cuts of $\QQ$, which are defined as follows.

\begin{defn} A \textbf{Dedekind cut} consists of a pair $L : \QQ \to \Prop$ and $U : \QQ \to \Prop$ of predicates,  called the \textbf{lower} and \textbf{upper cut}, respectively, which are:
\begin{enumerate}
\item inhabited: 
\[ \mere{ \Sigma_{q:\QQ}L(q)} \qquad \text{and} \qquad \mere{\Sigma_{r:\QQ}U(r)}\]
\item rounded: for all $q, r:\QQ$
\[ L(q) \leftrightarrow \mere{\Sigma_{r:\QQ} (q < r) \times L(r)} \qquad \text{and}\qquad U(r) \leftrightarrow \mere{\Sigma_{q:\QQ} (q<r) \times U(r)}.\]
\item disjoint: \[\Pi_{q: \QQ} \neg (L(q) \times U(q)).\]
\item located: \[\Pi_{q,r: \QQ} (q <r) \to L(q) \vee U(r).\]
\end{enumerate}
\end{defn}

Define $\is{Cut}(L,U)$ to be the conjunction of these conditions. The type of \textbf{Dedekind reals} is 
\[ \RR_d \coloneq \Sigma_{L,U : \QQ \to \Prop} \is{Cut}(L,U).\]

\begin{rmk}
The problem with using $\Prop$ is the codomain for the predicates $L$ and $U$ is that it makes $\RR_d$ a type in a higher universe $\UU^+$. This problem can be dealt with in a number of ways. One solution is to add a \textbf{propositional resizing} axiom. Our axioms for universes imply that there is a map $\UU \to \UU^+$ that restricts to define a map $\Prop \to \type{Prop}_{\UU^+}$. Propositional resizing asserts that this map is a universe, which means in practice that any proposition in $\UU^+$ can be ``resized'' to one in the smaller universe $\UU$. With propositional resizing, we may as well collapse all the way down and write $\Omega : \UU_0$ for our base universe of propositions and write $L, U : \QQ \to \Omega$.

Another option is to assert the law of excluded middle for propositions in which case it's possible to use $\Omega = \1 + \1$ for the universe of propositions. 

A third option is to just carefully keep track of universe levels and let $\RR_d$ live where it lives. We adopt one of these solutions and won't worry about this anymore.
\end{rmk}

Note since $\is{Cut}(L,U)$ is a proposition, $\RR_d$ is a set. There is an embedding $\QQ \to \RR_d$ which associates each $q : \QQ$ with the cut
\[ L_q(r) \coloneq (r <q) \qquad \text{and} \qquad U_q(r) \coloneq (q<r).\]

\subsection*{The Cauchy reals}

The Cauchy reals are defined to be the completion of $\QQ$ under limits of Cauchy sequences. The classical construction first considers the set of all Cauchy sequences in $\QQ$ and then forms a quotient under a suitable equivalence relation. To prove that this quotient is Cauchy complete one must consider a Cauchy sequence in the quotient, lift it to a Cauchy sequence of Cauchy sequences, and construct the limit using this lift. However, the lifting step requires the axiom of countable choice or the law of excluded middle, which we may wish to avoid. The standard way out of this conundrum is either to 
\begin{enumerate}
\item Form the Cauchy reals as a setoid: in this case, a Cauchy real is a Cauchy sequence of rationals, and the equivalence relation is carried through all constructions.
\item Accept the axiom of countable choice.
\item Use the Dedekind reals instead.
\end{enumerate}

Homotopy type theory presents a fourth alternative using higher inductive types. Essentially we define the Cauchy reals to be the free complete metric space generated by $\QQ$, which is formed by iteratively attaching limits to Cauchy sequences. In the presence of the axiom of choice, you can prove that this set must only be done once, but this gadget can be reasoned about even in the absence of a more explicit construction.

We will define the Cauchy reals $\RR_c$ and a relation $\sim_\epsilon \colon \RR_c \to \RR_c \to \Prop$ for any positive rational number $\epsilon : \QQ_+$ whose intended meaning is $x \sim_\epsilon y$ if the distance between $x$ and $y$ is less that $\epsilon$. This requires a \emph{higher inductive-inductive definition}.

\begin{rmk} An inductive-inductive definition defines a type $A$ and a type family $B \colon A \to \UU$ simultaneously by means of an induction in which constructors of the $B(a)$s and of $A$ itself can take inputs from the other types. These are closely related to inductive-recursive types, where the type family $B$ is defined recursively using the constructors of $A$ (which may take inputs from $B$). It is implemented in \texttt{agda} but still considered somewhat experimental.
\end{rmk}

\begin{defn} 
A function $x \colon \NN \to \QQ$ is a \textbf{Cauchy sequence} when it satisfies
\[ \Pi_{\epsilon : \QQ_+} \Sigma_{n :\NN} \Pi_{m,k \geq n} |x_m-x_k| < \epsilon.\]
\end{defn}
When this holds, then by the type theoretic axiom of choice there is a function $M : \QQ_+ \to \NN$ called the \textbf{modulus of convergence} that sends $\epsilon$ to a natural number $M(\epsilon)$ so that $m,k \geq M(\epsilon)$ implies that $|x_m-x_k| < \epsilon$. Note in particular that for any $\epsilon,\delta : \QQ_+$ that $|x_{M(\epsilon/2)} - x_{M(\delta/2)} | < \epsilon + \delta$ so the map $\epsilon \mapsto x_{M(\epsilon/2)} : \QQ_+ \to \QQ$ carries the same information about the limit as the original Cauchy sequence did. We refer to this data as a \textbf{Cauchy approximation}. 

\begin{defn} Let $\RR_c$ and the relation $\sim \colon \QQ_+ \times \RR_c \times \RR_c \to \UU$ be the higher inductive-inductive type family generated by the following constructors:
\begin{itemize}
\item rational points: for any $q : \QQ$ there is a real $\term{rat}(q) : \RR_c$.
\item limit points: for any $x : \QQ_+ \to \RR_c$ such that 
\[ \Pi_{\delta,\epsilon :\QQ_+} x_\delta \sim_{\delta+\epsilon} x_\epsilon\]
there is a point $\term{lim}(x) : \RR_c$. We call $x$ a \textbf{Cauchy approximation}.
\item paths: for $u,v : \RR_c$ such that
\[ \Pi_{\epsilon : \QQ_+} u \sim_\epsilon v\]
there is a path $\term{eq}_{\RR_c}(u,v) : u =_{\RR_c} v$.
\end{itemize}
Simultaneously, the type family $\sim \colon \RR_c \to \RR_c \to \QQ_+ \to \UU$ is generated by the following constructors for all $q,r : \QQ$, $\delta, \epsilon,\eta : \QQ_+$, $u,v : \RR_c$, and Cauchy approximations $x$ and $y$:
\begin{itemize}
\item for all $q,r,\epsilon$ if $-\epsilon < q-r < \epsilon$ then $\term{rat}(q) \sim_\epsilon \term{rat}(r)$
\item for all $q,y,\epsilon,\delta$ if $\term{rat}(q) \sim_{\epsilon-\delta} y_\delta$ then $\term{rat}(q) \sim_\epsilon \term{lim}(y)$
\item for all $x,r,\epsilon,\delta$ if $x_\delta \sim_{\epsilon-\delta} \term{rat}(r)$ then $\term{lim}(x) \sim_\epsilon \term{rat}(r)$
\item for all $x,y,\epsilon,\delta,\eta$ if $x_\delta \sim_{\epsilon-\delta-\eta} y_\eta$ then $\term{lim}(x) \sim_\epsilon \term{lim}(y)$
\item for all $u,v,\epsilon$, if $\zeta, \xi : u\sim_\epsilon v$ then $\zeta = \xi$. This is propositional truncation on the relation $\sim$.
\end{itemize}
\end{defn}

\subsection*{Comparison between the Cauchy and Dedekind reals}

\begin{thm} There is an embedding of ordered fields $\RR_c \to \RR_d$ which fixes the rational numbers.
\end{thm}

There are two proofs, both discussed in \cite{book-hott}. One strategy is to prove the universal property of $\RR_d$, namely that it is the terminal archimedean ordered field $F$ for which the strict order $<$ on $F$ is a map $< : F \to F \to \Omega$, where $\Omega$ is whatever universe of propositions was used to define Dedekind cuts. Here the archimedian principle states that for all $x,y : F$ if $x < y$ then there merely exists some $q: \QQ$ so that $x < q < y$. Then you show that $\RR_c$ is also an archimediate ordered field with $< \colon \RR_c \to \RR_c \to \Omega$. Consequently, it may be realized as a subfield of $\RR_d$.

An alternate strategy uses the universal property of $\RR_c$, which states that the Cauchy reals embed into every Cauchy complete archimedian ordered field. One then shows that the archimedian ordered field $\RR_d$ is Cauchy complete.

Without further assumptions, we do not expect $\RR_c$ and $\RR_d$ to coincide. However:

\begin{lem} If for every $x : \RR_d$ there merely exists
\[ c : \Pi_{q,r: \QQ} (q <r) \to ((q <x) + (x <r))\]
then the Cauchy and Dedekind reals coincide.
\end{lem}
\begin{proof}
It suffices to show that every Dedekind real merely is the limit of a Cauchy sequence of rational numbers. 

Consider any $x : \RR_d$. By the assumption that there merely exists a $c$ as in the statement and by the inhabitation of cuts, there merely exists $a, b : \QQ$ so that $a < x < b$. We construct 
\[f : \NN \to \Sigma_{(q,r): \QQ \times \QQ} q < r\]  by recursion. Set $f(0) = (a,b)$. Then if $f(n) \coloneq (q_n,r_n)$ with $q_n < r_n$ Define $s \coloneq (2q_n+r_n)/3$ and $t \coloneq (q_n+2r_n)/3$ and use $c(s,t)$ to decide between $s <x$ and $x < t$. If it decides $s < x$ set $f(n+1) \coloneq (s,r_n)$ and set $f(n+1) \coloneq (q_n,t)$ otherwise.

By construction $q_n < x < r_n$ and $|q_n-r_n| \leq (2/3)^n\cdot |q_0 - r_0|$ for all $n : \NN$. Thus both $q : \NN \to \QQ$ and $r \colon \NN \to \QQ$ define Cauchy sequence converging to the Dedekind cut $x$. We have shown that for every $x: \RR_d$ there merely exists a Cauchy sequence converging to $x$.
\end{proof}


\begin{cor} If excluded middle or countable choice holds then $\RR_c$ and $\RR_d$ are equivalent.
\end{cor}
\begin{proof}
If excluded middle holds then $(x<y) \to ((x<z)+ (z<y))$ can be proved: either $x < z$ or $\neg (x<z)$. In the former case, we are done, while in the latter we have $z  \leq x < y$. This allows us to apply the lemma.

If countable choice holds then we use the fact that the set $S = \Sigma_{(q,r): \QQ \times \QQ} q < r$ is equivalent to $\NN$. So we may apply countable choice to the statement 
\[ \Pi_{(q,r) : S} \mere{(q<x) + (x<r)}\]
which says that $x$ is located. This is a curried form of the statement we need.
\end{proof}




\part{Synthetic Homotopy Theory}

In the final part of the course we tour a very small portion of the synthetic homotopy theory that has been developed in homotopy type theory, starting by studying the circle.

\section*{November 17: The circle}

\subsection*{The induction principle of the circle}

Geometrically, the circle can be built by attaching a loop to a point. This definition is efficiently captured by the following higher inductive type.

\begin{defn} The circle is the type $\Sone$ freely generated by a term $\base : \Sone$ and a loop $\lloop : \base = \base$.
\end{defn}

Just like for ordinary inductive types, higher inductive types come with an induction principle that can be used to construct sections of type families $B : \Sone \to \UU$. Suppose given a section $f : \Pi_{x : \Sone} B(x)$. Then in particular this gives a term $f(\base) : B(\base)$ and a path $\apd_f( \lloop) : \tr_B(\lloop, f(\base)) =_{B\base} f(\base)$. We can record this data via a map

\begin{defn} For any type family $B : \Sone \to \UU$, there is a map
  \[ \term{dgen}_{\Sone} : \left( \Pi_{x: \Sone} B(x) \right) \to \left(\Sigma_{b : B(\base)} \tr_B(\lloop, b) = b\right)\]
  given by $\term{dgen}_{\Sone}(f) \coloneq (f(\base), \apd_f(\lloop))$. This is the dependent action of $f$ on the generators $\base$ and $\lloop$ of $\Sone$.
\end{defn}

\begin{defn} The \textbf{induction principle of the circle} provides for each type family $B : \Sone \to \UU$ a map
  \[ \ind_{\Sone} : \left( \Sigma_{b : B(\base)} \tr_B(\lloop, b) = b \right) \to \left(\Pi_{x:\Sone} B(x)\right)\]
and a homotopy $\term{comp}_{\Sone} \colon \term{dgen}_{\Sone}\circ \ind_{\Sone} \sim \id$  witnessing that $\ind_{\Sone}$ is a section of $\term{dgen}_{\Sone}$.
\end{defn}

The type of identifications $(b,p) = (b',p')$ in the type $\Sigma_{b : B(\base)} \tr_B(\lloop, b) = b$ is equivalent to the type of pairs $(\alpha, \beta)$ consisting of a path $\alpha \colon b = b'$ and a path $\beta$ defining a homotopy between the square of paths
\[
  \begin{tikzcd}
\tr_B(\lloop, b) \arrow[d, equals, "p"'] \arrow[dr, phantom, "\beta"]\arrow[r, equals, "\ap_{\tr_B(\lloop)}(\alpha)"] & \tr_B(\lloop,b') \arrow[d, equals, "p'"] \\ b \arrow[r, equals, "\alpha"'] & b'
  \end{tikzcd}
\]

Thus the induction principle of the circle says that for any $b : B(\base)$ and $p : \tr_B(\lloop,b) = b$ there is a function $f : \Pi_{x:\Sone} B(x)$ equipped with identifications $\alpha : f(\base) =b$ and $\beta$ defining a homotopy in the square of paths
\[
  \begin{tikzcd}
\tr_B(\lloop, f(\base)) \arrow[d, equals, "\apd_f(\lloop)"'] \arrow[dr, phantom, "\beta"]\arrow[r, equals, "\ap_{\tr_B(\lloop)}(\alpha)"] & \tr_B(\lloop,b) \arrow[d, equals, "p"] \\ f(\base) \arrow[r, equals, "\alpha"'] & b
  \end{tikzcd}
\]

\subsection*{The dependent universal property of the circle}

The dependent universal property of the circle states that $\ind_{\Sone}$ and $\term{dgen}_{\Sone}$ define an inverse equivalence for any type family $B \colon \Sone \to \UU$.

\begin{thm} For any type family $B \colon \Sone \to \UU$, the map
  \[ \term{dgen}_{\Sone} : \left( \Pi_{x: \Sone} B(x) \right) \to \left(\Sigma_{b : B(\base)} \tr_B(\lloop, b) = b\right)\]
  given by $\term{dgen}_{\Sone}(f) \coloneq (f(\base), \apd_f(\lloop))$ is an equivalence.
\end{thm}
\begin{proof}
The inverse equivalence and one homotopy are given by $\ind_{\Sone}$ and $\term{comp}_{\Sone}$. It remains only to construct the final homotopy
\[
\ind_{\Sone} \circ \term{dgen}_{\Sone} \sim \id.  
\]
Thus for any $f : \Pi_{x:\Sone} B(x)$ we require an identification $\ind_{\Sone}(\term{dgen}_{\Sone}(f)) = f$. By function extensionality, it suffices to give identifications $\ind_{\Sone}(\term{dgen}_{\Sone}(f(x))) = f(x)$ for each $x : \Sone$. That is, we must define a term in the type
\[ \Pi_{x : \Sone}\ind_{\Sone}(\term{dgen}_{\Sone}(f(x))) = f(x).\]
By the induction principle of the circle it suffices to construct a pair of terms
\[ \alpha :\ind_{\Sone}(\term{dgen}_{\Sone}(f(\base))) = f(\base)\]
and
\[ \beta : \tr (\lloop, \alpha) = \alpha\]
where the transport is in the family
$x \mapsto \ind_{\Sone}(\term{dgen}_{\Sone}(f(x))) = f(x)$. By the lemma below to construct the second path it suffices instead to define a homotopy $\beta$ in the square
\[
  \begin{tikzcd}
    \tr_B(\lloop, f(\base)) \arrow[d, equals, "\apd_f(\lloop)"'] \arrow[dr, phantom, "\beta"]\arrow[r, equals, "\ap_{\tr_B(\lloop)}(\alpha)"] & \tr_B(\lloop,b) \arrow[d, equals, "p"] \\ f(\base) \arrow[r, equals, "\alpha"'] & b
      \end{tikzcd}
    \]
But this is exactly the data we're given in the computation rule for the circle.
  \end{proof}

\begin{lem} For any type family $B : A \to \UU$, $f,g : \Pi_{x :A } B(x)$, $p : x = x'$, $q :g(x)=f(x)$ and $r : g(x') = f(x')$ there is a function
\[ \left( \apd_g(p) \cdot r = \ap_{\tr_B(p)}(q) \cdot \apd_f(p) \right) \to \left( \tr_{x \mapsto g(x)=f(x)}(p,q) =r \right).\]
\end{lem}
\begin{proof} By path induction on $p$ it suffices to define a function
\[ \left(\refl \cdot r = q \cdot \refl \right) \to \left( q = r \right)\]
which can be done by combining composing with the unit homotopies with the function $\inv \colon (r=q) \to (q=r)$.
\end{proof}

Note that a corollary of the equivalence is that for each $b : B(\base)$ and $p : \tr_B(\lloop, b) =b $ the type of dependent functions $f : \Pi_{x:\Sone} B(x)$ equipped with $\alpha \colon f(\base) = b$ and $\beta$ in the square above is contractible.

Another corollary of the dependent universal property of the circle is the non-dependent universal property:

\begin{thm} For any type $X$, the action on generators
  \[ \term{gen}_{\Sone} \colon (\Sone \to X) \to \Sigma_{x: X} x =x \]
  given by $f \mapsto (f(\base), \ap_f(\lloop))$ is an equivalence.
\end{thm}
\begin{proof} We will show that there is a commutative triangle
  \[
    \begin{tikzcd}
      & \Sone \to X \arrow[dl, "\term{gen}_{\Sone}"'] \arrow[dr, "\term{dgen}_{\Sone}"] \\ \left( \Sigma_{x:X} x=x \right) \arrow[rr, "\simeq"] & & \left( \Sigma_{x:X} \tr_{X}(\lloop,x) =x \right)
    \end{tikzcd}\]
    in which the bottom map is an equivalence. Here the transport is in the constant family over $\Sone$. 

 We first must define the bottom map. For this note, that if $B$ is a constant type family over $A$ and $p : a =_A a'$ then for any $b : B$ there is an identification $t_{p,b} : \tr_B(p,b)=b$ defined by path induction on $p$ by $\refl_a \mapsto \refl_b$.    The bottom map is then defined by composition with $t_{p,b}$. Since composition with a path is an equivalence, this map is an equivalence, as claimed.

 It remains to show that the triangle of maps commutes up to homotopy. Given $f \colon \Sone \to X$, we must construct an identification in the triangle of paths
 \[
 \begin{tikzcd}
    & \tr_X(\lloop, f(\base)) \arrow[dr, equals, "\apd_f(\lloop)"] \arrow[dl, equals, "t_{\lloop,f(\base)}"'] \\ f(\base) \arrow[rr, equals, "\ap_f(\lloop)"'] && f(\base)
 \end{tikzcd}  
 \]
This holds for completely general reasons. For any $f : A \to B$ and $p : a=_A a'$ the triangle
\[
 \begin{tikzcd}
    & \tr_B(p, f(a)) \arrow[dr, equals, "\apd_f(p)"] \arrow[dl, equals, "t_{p,f(a)}"'] \\ f(a) \arrow[rr, equals, "\ap_f(p)"'] && f(a')
 \end{tikzcd}  
 \]
 commutes by path induction on $p$.
  \end{proof}

  \begin{rmk}
    Note that $\neg(\lloop = \refl_\base)$. Because if so then for any type $X$ and any loop $p : x = x$ we would get a function $f : \Sone \to X$ together with paths $\alpha : f(\base) = x$ and $\beta : \tr_{x \mapsto x = x}(\alpha, \ap_f(\lloop)) = p$. By composing paths we have
    \[ p = \tr(\alpha,\ap_f(\lloop)) = \tr(\alpha,\ap_f(\refl_\base)) = \tr(\alpha,\refl_{f(\base)}) = \refl_x.\]
    This proves that
    \[
    (\lloop = \refl_\base ) \to \left(\Pi_{X: \UU}\Pi_{x : X}\Pi_{p : x = x} p = \refl_x  \right).
    \]
   The conclusion of this implication is ``axiom K,'' which is equivalent to the assertion that $X$ is a set. Since not all types are sets, we can't have $\lloop = \refl_\base$.
  \end{rmk}
  

  \begin{cor} For any loop $\ell : x = x$ in $X$ the type of maps $f : \Sone \to X$ equipped with an identification $\alpha : f(\base) =x$ and a homotopy $\beta$ in the square
    \[
      \begin{tikzcd}
        f(\base)\arrow[dr, phantom, "\beta"] \arrow[d, equals, "\ap_f(\lloop)"'] \arrow[r, equals, "\alpha"] & x \arrow[d, "\ell", equals] \\ f(\base) \arrow[r, equals, "\alpha"'] & x
      \end{tikzcd}\]
      is contractible.
    \end{cor}

    \subsection*{Multiplication on the circle}

Classically, the circle can be identified with the space of complex numbers at distance 1 from the origin. This space is a topological abelian group, with complex multiplication. We can define an analogous multiplication operation on the $\Sone$ of homotopy type theory despite the fact this was constructed in a very different way.

\begin{defn} There is a binary operation $\mul_{\Sone} \colon \Sone \to \Sone \to \Sone$ defined by applying the universal property of the circle to the type $\Sone \to \Sone$.  Using the universal property of the circle we may construct a term $\ind_{\Sone}(b,p)$ in the type $\Sone \to \Sone \to \Sone$ from a term in the type
 \[ (b,p) : \Sigma_{e : \Sone \to \Sone} e =e.\] 

 The computation rule provides identifications $\alpha : \ind_{\Sone}(b,p) (\base)= b$ and $\beta$. If we want $\ind_{\Sone}(b,p)$ to be $\mul_{\Sone}$ and $\base : \Sone$ to be the unit for the multiplication, then $\mul_{\Sone}(\base)$ should be the identity function. Thus we take $\id : \Sone \to \Sone$ for the term $b$ and write $H : \id \sim \id$ for the homotopy, to be defined later, whose corresponding path $\term{eq-htpy}(H) : \id = \id$ is the path $p$. We then define
 \[ \mul_{\Sone} \coloneq \ind_{\Sone}(\id,\term{eq-htpy}(H)).\]

 It takes some effort to define the correct homotopy $H$, for which we're guided by the computation rule which tells us that the function $\mul_{\Sone}$ is related to the generating data $(\id,\term{eq-htpy}(H))$ by paths and homotopies
 \[
   \begin{tikzcd}
     \mul_{\Sone}(\base) \arrow[r, equals, "\term{base-mul}_{\Sone}"] \arrow[d, equals, "\ap_{\mul_{\Sone}}(\lloop)"'] \arrow[dr, phantom, "\term{loop-mul}_\Sone"] & \id \arrow[d, equals, "\term{eq-htpy}(H)"] \\ 
     \mul_{\Sone}(\base) \arrow[r, equals, "\term{base-mul}_{\Sone}"'] & \id
   \end{tikzcd}\]
  where $\term{base-mul}_{\Sone}$ is the path $\alpha$ above and $\term{loop-mul}_{\Sone}$ is $\beta$. Applying the dependent universal property of the circle we may define $H$ to be the unique dependent function $H : \Pi_{x:\Sone} x =x$ equipped with an identification $\alpha : H(\base) = \lloop$ and an identification $\beta$ in the square
  \[\begin{tikzcd}
    \tr(\lloop, H(\base)) \arrow[d, equals, "\apd_H(\lloop)"'] \arrow[dr, phantom, "\beta"] \arrow[r, equals, "\ap_{\tr(\lloop)}(\alpha)"] & \tr(\lloop, \lloop) \arrow[d, equals, "\gamma"] \\ H(\base) \arrow[r, equals, "\alpha"'] & \lloop
  \end{tikzcd}\]
where the transport is in the family $x \mapsto x=x : \Sone \to \UU$. Now it just remains to define the path $\gamma : \tr(\lloop, \lloop) = \lloop$.
 
By the lemma in the previous section we have a function
\[ ( p \cdot r = q \cdot p) \to \left( \tr_{x \mapsto x = x} (p,q) =r \right)\]
for any $p : \base = x$, $q : \base = \base$, and $r : x = x$. In particular, we have a function
\[ ( \lloop \cdot \lloop) = \lloop \cdot \lloop) \to \left( \tr_{x \mapsto x = x} (\lloop,\lloop) =\lloop \right).\] We apply this to $\refl_{\lloop\cdot\lloop}$ to obtain the desired identification $\gamma$.
\end{defn}

What just happened? By path induction on $p$, transport $\tr_{x \mapsto x = x}(p,q)$ in the family $x \mapsto x = x$ of a term $q : a = a$ along a path $p : a = b$ is identifiable with the path $p^{-1}\cdot q \cdot p : b = b$. So $\gamma$ may be identified with a path of paths $\gamma : \lloop^{-1} \cdot \lloop \cdot \lloop = \lloop$, namely the path defined by canceling the inverses.

It takes some effort to see that this function deserves to be called ``complex multiplication.''

As evidence, note first that the path $\term{base-mul}_{\Sone}$ proves the left unit law $\mul_{\Sone}(\base,x) = x$ for each $x : \Sone$.

\begin{prop} The function $\mul_{\Sone}$ satisfies the right unit law: we have
  \[ \mul_{\Sone}(x,\base) = x\]
  for all $x : \Sone$.
\end{prop}
\begin{proof}
We prove this by induction on the circle. In the base case we have $\mul_{\Sone}(\base,\base) = \base$ by the left unit law $\term{left-unit}_{\Sone}(\base)$. So it remains to show that
$\tr_P(\lloop,\term{left-unit}_{\Sone}(\base)) = \term{left-unit}_{\Sone}(\base)$ where $P : \Sone \to \UU$ is the family defined by $P(x) \coloneq \mul_{\Sone}(x,\base) = x$. To construct this identification it suffices to define a homotopy in the square
\[ 
\begin{tikzcd}
  \mul_{\Sone}(\base,\base) \arrow[r, equals, "\term{left-unit}_{\Sone}(\base)"] \arrow[d, equals, "\term{htpy-eq}(\ap_{\mul_{\Sone}}(\lloop))(base)"'] & \base \arrow[d, equals, "\lloop"] \\ \mul_{\Sone}(\base,\base) \arrow[r, equals, "\term{left-unit}_{\Sone}(\base)"'] & \base
\end{tikzcd}
\]
From our construction of the homotopy $H$ we have an identification $\alpha : H(\base) = \lloop$ (which proves that $H$ is not the trivial homotopy). Thus there is a homotopy in the previous square if and only if there is one in the square
\[ 
\begin{tikzcd}
  \mul_{\Sone}(\base,\base) \arrow[r, equals, "\term{left-unit}_{\Sone}(\base)"] \arrow[d, equals, "\term{htpy-eq}(\ap_{\mul_{\Sone}}(\lloop))(base)"'] & \base \arrow[d, equals, "H(\base)"] \\ \mul_{\Sone}(\base,\base) \arrow[r, equals, "\term{left-unit}_{\Sone}(\base)"'] & \base
\end{tikzcd}
\]
and this can be constructed out of the term $\term{loop-mul}_{\Sone}$.
\end{proof}

\section*{November 29: The universal cover of the circle}

Recall the circle $\Sone$ is the higher inductive type freely generated by a term $\base : \Sone$ and an identification $\lloop : \base =_{\Sone} \base$. Our aim is to calculate the \textbf{loop space} of $\Sone$. In other words, we will characterize the identity type $\base =_{\Sone} \base$.

\subsection*{Families over the circle}

The type of small families over the circle is just the function type $\Sone \to \UU$, so we may use the universal property of the circle to construct a small family of types over it. By that universal property, small families over $\Sone$ are equivalently described as pairs $(X,p)$ where $X: \UU$ and $p : X =X$. By the univalence axiom, $(X = X) \simeq (X \simeq X)$. Thus we may equivalently describe a small family as a pair $(X,e)$ where $X : \UU$ and $e : X\simeq X$.

The type $\Sigma_{X : \UU} X \simeq X$ is referred to as the type of \textbf{descent data} for the circle.

\begin{prop}
There is a commutative triangle of equivalences of types
\[
\begin{tikzcd} & \Sone \to \UU \arrow[dl, "\term{gen}_{\Sone}"'] \arrow[dr, "\term{desc}_{\Sone}"] \\
 \Sigma_{X: \UU} X =X  \arrow[rr, "\term{tot}(\term{equiv-eq})"'] & &  \Sigma_{X : \UU} X \simeq X
 \end{tikzcd}
 \]
 where the map $\term{desc}_{\Sone}$ is given by $P \mapsto (P(\base), \tr_P(\lloop))$.
 \end{prop}
 \begin{proof}
 By path induction, $\term{equiv-eq}(\term{ap}_P(\lloop)) = \tr_P(\lloop)$ for each dependent type $P : \Sone \to \UU$. This proves that the triangle of functions commutes up to homotopy. The bottom map is an equivalence by the univalence axiom and the theorem about families of equivalences. The left-hand map is the equivalence that expresses the (non-dependent) universal property of $\Sone$. Thus the right-hand map is an equivalence as well.
 \end{proof}
 
  This means that for every type $X$ and equivalence $e : X \simeq X$, there is a type family $D(x,e) : \Sone \to \UU$ so that $(D(X,e,\base), \tr_{D(X,e)}(\lloop)) = (X,e)$.

\subsection*{The universal cover of the circle}

The \textbf{universal cover} of the circle is a family of sets over the circle with contractible total space. Classically the universal cover is described as a map $\RR \to \Sone$ that winds the real line around the circle, but in HoTT there is no analogue of such a construction. As a homotopy type the real line $\RR$ is contractible. (For similar reasons, this line $\RR$ is not the type of real numbers constructed above.)

What we do have is the type of integers $\ZZ \coloneq \NN + (\1 + \NN)$ together with an autoequivalence $\term{succ}_\ZZ : \ZZ \simeq \ZZ$. We'll use this to define a type family over $\Sone$. We'll define an equivalence from $\ZZ$ to the fiber over $\base : \Sone$ and the construct a sequence of paths between the points in this fiber --- forming the segments of the helix. Finally, we'll show that this total space is contractible, but first we give the definition:

\begin{defn} The \textbf{universal cover} of the circle is the dependent type $E_{\Sone} : D(\ZZ, \term{succ}_\ZZ)$. 
\end{defn}

By the work of the previous section, we can understand the universal cover as coming with an equivalence $e \colon \ZZ \simeq E_{\Sone}(\base)$ and a homotopy witnessing the commutativity of the square
\[ 
\begin{tikzcd}
\ZZ \arrow[d, "\term{succ}_\ZZ"']  \arrow[r, "e", "\simeq"'] & E_{\Sone}(\base) \arrow[d, "\tr_{E_{\Sone}}(\lloop)"] \\ \ZZ \arrow[r, "e"', "\simeq"] & E_{\Sone}(\base)
\end{tikzcd}
\]

For convenience we write $k_E \coloneq e(k) : E_{\Sone}(\base)$ for any $k : \ZZ$. The type family $E_{\Sone} : \Sone \to \UU$ has an associated total space $\Sigma_{t: \Sone} E_\Sone(t)$ inhabited by terms $(\base, k_E)$ for each $k : \ZZ$. The following lemma constructs a sequence of paths between these terms.

\begin{lem} For any $k : \ZZ$ there is an identification
\[ \term{segment-helix}_k : (\base, k_E) = (\base, \term{succ}_\ZZ(k)_E)\]
in the total space $\Sigma_{t: \Sone} E_\Sone(t)$.
\end{lem}
\begin{proof}
Recall that paths in a $\Sigma$-type are given by pairs of paths. Thus we wish to inhabit the type
\[ \Pi_{k : \ZZ} \Sigma_{\alpha : \base = \base} \tr_{E_{\Sone}}(\alpha,k_E) = \term{succ}_\ZZ(k)_E.\] For any $k : \ZZ$ we may take $\alpha$ to be $\lloop$. Then the commuting square
\[ 
\begin{tikzcd}
\ZZ \arrow[d, "\term{succ}_\ZZ"']  \arrow[r, "e", "\simeq"'] & E_{\Sone}(\base) \arrow[d, "\tr_{E_{\Sone}}(\lloop)"] \\ \ZZ \arrow[r, "e"', "\simeq"] & E_{\Sone}(\base)
\end{tikzcd}
\]
gives exactly the identification we seek.
\end{proof}

\subsection*{Contractibility of total spaces}

Our goal is to prove that the total space $\Sigma_{t: \Sone} E_\Sone(t)$ is contractible, which we do by first considering a more general version of this problem.

Consider a type $X$, a family $P$ over $X$, and an element $c : \Sigma_{x:X} P(x)$. To construct a contraction, a term of type
\[ \Pi_{t : \Sigma_{x:X}P(x)} c  =t,\] we can apply the induction principle of $\Sigma$ types to reduce the problem to constructing a dependent function of type
\[ \Pi_{x:X} \Pi_{y: P(x)} c = (x,y).\]

In the case where $P$ is the universal cover of the circle, we have $(\base,0_E)$ as the proposed center of contraction and must therefore define a dependent function
\[
\Pi_{x : \Sone} \Pi_{y : E_\Sone(x)} (\base,0_E) = (x,y).\]
By the dependent universal property of $\Sone$ such a dependent function can be induced from a pair whose first term is the data of such a function at the point $\base : \Sone$. Thus, for this piece we need a term of type 
\[\Pi_{y: E_\Sone(\base)} (\base,0_E)=(\base,y) .\]
 Using the equivalence $e : \ZZ \simeq E_{\Sone}(\base)$, we obtain an equivalence
\[ 
\left(\Pi_{y: E_\Sone(\base)} (\base,0_E)=(\base,y) \right) \to \left(\Pi_{k :\ZZ} (\base,0_E) = (\base,k_E) \right),\]
so for this first piece it suffices to construct a term of type 
\[
 \left(\Pi_{k :\ZZ} (\base,0_E) = (\base,k_E) \right).\]

The second piece of required data is an identification involving the transport along the path $\lloop$. Since we will define the required dependent function by concatenating the paths $\term{segment-helix}_j$ to define a path from $(\base,0_E)$ to $(\base,k_E)$, this second piece of data has the form of the homotopy stated in the following result:

\begin{prop} To prove that the total space $\Sigma_{t: \Sone} E_\Sone(t)$ is contractible with $(\base,0_E)$ as its center of contraction, it suffices to construct a function
\[ h :  \Pi_{k :\ZZ} (\base,0_E) = (\base,k_E) \]
equipped with a homotopy
\[ H : \Pi_{k : \ZZ} h(\term{succ}_\ZZ(k)_E) = h(k) \cdot \term{segment-helix}_k.\]
\end{prop}

See \cite[\S 21.3]{Rijke} for further discussion and proof.

\subsection*{The dependent universal property of the integers}

This proposition tells us what data is needed to prove that $\Sigma_{t: \Sone} E_\Sone(t)$ is contractible without supplying the missing data. For this we make use of the dependent universal property of the integers:

\begin{lem} Let $B$ be a type family over $\ZZ$ equipped with a term $b_0 : B(0)$ and an equivalence $e_k : B(k) \simeq B(\term{succ}_\ZZ(k))$ for each $k : \ZZ$. Then there is a dependent function $f : \Pi_{k:\ZZ}B(k)$ equipped with identifications $f(0) = b_0$ and $f(\term{succ}_\ZZ(k)) = e_k(f(k))$ for each $k : \ZZ$.
\end{lem}
\begin{proof}
We use the induction principle of $\ZZ$ as an inductive type $\ZZ \coloneq \NN + (\1 + \NN)$. By the induction principle of the integers we may define $f: \Pi_{k : \ZZ}B(k)$ by giving terms
\[ f(-1) \coloneq e^{-1}(b_0), \quad f(0) \coloneq b_0 , \quad f(1) \coloneq e(b_0)\]
and functions
\[ \lambda n, e^{-1}_{-n-1} : \Pi_{n : \NN} B(-n) \to B(-n-1) \qquad \lambda n, e_n : \Pi_{n : \NN} B(n) \to B(n+1).\]
The computation rules for $\ZZ$ give us the judgmental identifications $f(0) \doteq b_0$, $f(1) \doteq e(b_0)$, and $f(-1) \doteq e^{-1}(b_0)$ and homotopies $f(n+1)=e_n (f(n))$ for positive integers and $f(-n-1) = e_{-n-1}^{-1} f(-n)$ for negative integers. These latter homotopies can be whiskered with the identifications $e_ke_k^{-1} = \id$ to give ones in the form we desire.
\end{proof}

\begin{ex} For any type $A$ with $a :A$ and $e : A \simeq A$, we obtain a map $f \colon \ZZ  \to A$ such that $f(0)=a$ and the square
\[
\begin{tikzcd}
 \ZZ \arrow[r, "f"] \arrow[d, "\term{succ}_\ZZ"'] & A \arrow[d, "e"] \\ \ZZ \arrow[r, "f"'] & A
\end{tikzcd}
\]
commutes. 
\end{ex}

\begin{ex}
In particular, we could take $A \coloneq (x =_X x)$ to be the loop space at $x$ for some other type $X$. Then for any $p : x = x$ we have an equivalence $\lambda q. p \cdot q : (x=x) \to (x=x)$. From this data we obtain a map

\[ k \mapsto p^k : \ZZ \to (x=x)\]
for any $p : x=x$.
\end{ex}

The universal property of $\ZZ$ says that $\ZZ$ is the initial type equipped with a term $0 : \ZZ$ and an automorphism $\term{succ}_\ZZ : \ZZ \simeq \ZZ$. In other words, the dependent function constructed in the lemma is unique:

\begin{thm} Consider a type family $B: \ZZ \to \UU$ with $b : B(0)$ and a family of equivalences
\[ e : \Pi_{k : \ZZ} B(k) \simeq B(\term{succ}_\ZZ(k)).\]
Then the type
\[ \Sigma_{f: \Pi_{k: \ZZ} B(k)} (f(0)=b) \times \Pi_{k :\ZZ} f(\term{succ}_\ZZ(k)) = e_kf(k)\]
is contractible.
\end{thm}

See \cite[\S 21.4]{Rijke}. In the non-dependent cases:

\begin{cor} For any type $X$ with $x_0 : X$ and $e : X \simeq X$ the type
\[ \Sigma_{f : \ZZ \to X} (f(0)=x_0) \times ((f \circ \term{succ}_\ZZ) \simeq (e \circ f))\]
is contractible.
\end{cor}

\subsection*{The identity type of the circle}

We now prove:

\begin{thm} The total space $\Sigma_{t : \Sone} E_\Sone(t)$ of the universal cover of the circle is contractible.
\end{thm}
\begin{proof}
It suffices to construct a function
\[ h :  \Pi_{k :\ZZ} (\base,0_E) = (\base,k_E) \]
equipped with a homotopy
\[ H : \Pi_{k : \ZZ} h(\term{succ}_\ZZ(k)_E) = h(k) \cdot \term{segment-helix}_k.\]
For both of these we use the universal property of $\ZZ$. For the first, the type family $P(k) \coloneq (\base,0_E) = (\base,k_E)$ over $k : \ZZ$ comes with an element $\refl : P(0)$ and a family of equivalences
\[ \lambda k,p \to p \cdot \term{segment-helix}_k : \Pi_{k : \ZZ} P(k) \simeq P(\term{succ}_\ZZ(k)).\]
The homotopy $H$ comes from the data that witnesses the uniqueness of this function.
\end{proof}

We have a family of maps $\Pi_{t : \Sone} (\base=t) \to E_{\Sone}(t)$ defined by path induction by sending $\refl_\base$ to $0_E$. By the universal property of identity types we conclude from the fact that the total space $\Sigma_{t: \Sone} E_\Sone(t)$ is contractible that:

\begin{cor} The family of maps $\Pi_{t : \Sone} (\base=t) \to E_{\Sone}(t)$ defined by path induction by sending $\refl_\base$ to $0_E$ is a family of equivalence. In particular, the loop space $(\base=\base)$ is equivalent to $E_\Sone(\base)\simeq \ZZ$.
\end{cor}

Now that we have calculated that $(\base=\base) \simeq \ZZ$ we can further conclude that:

\begin{cor} The circle is a 1-type and not a 0-type.
\end{cor}
\begin{proof}
We have shown that $\lloop \neq \refl_\base$. Thus the circle is not a 0-type. To see that $\Sone$ is a 1-type we must show for every $s,t : \Sone$ that $s=t$ is a 0-type. The dependent universal property of the circle specializes, in the case of a family of \emph{propositions} $P$ over the circle, to the statement that $P(\base) \to \Pi_{t : \Sone} P(t)$. Applying this twice to the family of propositions $\is{set}(s=t)$, we see that it suffices to prove that $\base=\base$ is a set. But this follows from the fact that $\ZZ$ is a set.
\end{proof}



\section*{December 1: Homotopy groups of types}

There are many results from classical homotopy theory that have been proven in homotopy type theory. In the last week of the course, we'll survey a handful of these.

\subsection*{Pointed types}

A \textbf{pointed type} is a pair $(A,a)$ consisting of a type $A$ and a term $a : A$. The type of all points types in a universe $\UU$ is the type
\[ \UU_* \coloneq \Sigma_{X : \UU} X.\]

\begin{defn}
A \textbf{pointed map} from $(A,a)$ to $(B,b)$ is a pair $(f,p)$ where $f \colon A \to B$ and $p : f(a) = b$. We write
\[ A \to_* B \coloneq \Sigma_{f :A \to B} f(a)=b\]
for the type of all pointed maps from $(A,a)$ to $(B,b)$ leaving the basepoints implicit.
\end{defn}

We next define a function $\Omega \colon \UU_* \to \UU_*$ that takes a pointed type to its loop space.

\begin{defn} For a pointed type $(A,a)$ define
\[ \Omega(A,a) \coloneq ((a=a),\refl_a).\]
The type $\Omega(A,a)$ is called the \textbf{loop space} of the pointed type.
\end{defn}

Since $\Omega$ is an function from a type to itself it can be composed with itself. Iterating $\Omega$ defines the \textbf{iterated loop space} of a pointed type.

\begin{defn} Given a pointed type $(A,a)$ and natural number $n$ we define the $n$th loop space $\Omega^n(A,a)$ by induction on $n : \NN$ by
\[  \Omega^0(A,a) \coloneq (A,a) \qquad \Omega^{n+1}(A,a) \coloneq \Omega(\Omega^n(A,a)).\]
\end{defn}

\begin{ex} The circle $\Sone$ defines a pointed type with $\base : \Sone$ as its basepoint. Last time we proved that the identity type family $t : \Sone \vdash \base = t$ is equivalent to the type family $E : \Sone \to \UU$ that we defined by $\Sone$-induction from the type $\ZZ$ and the equivalence $\term{succ}_\ZZ : \ZZ \simeq \ZZ$. In particular, $(\base = \base) \simeq E(\base) \simeq \ZZ$ via an equivalence that carried $\refl_\base$ to $0$ and $\lloop$ to $1$. Thus we have calculated the loop space
\[ \Omega(\Sone,\base) \simeq (\ZZ,0).\]
Since $\ZZ$ is a set, the type $(0=0)$ is a proposition. Since $\refl_0 : 0=0$ we know that the type $(0=0)$ is contractible.\footnote{Recall one logically equivalent way to say that a type $A$ is a proposition is $A \to \iscontr{A}$.} Thus we calculate
\[ \Omega^2(\Sone,\base) \simeq \Omega(\ZZ,0) \simeq (\1, \star).\]
Since the identity types of contractible types are contractible we in fact have that $\Omega^n(\Sone,\base) \simeq (\1,\star)$ for all $n \geq 2$.
\end{ex}

The loop space operation $\Omega$ is \emph{functorial} in the sense that any pointed map $f : X \to_* Y$ gives rise to a pointed map $\Omega f : \Omega X \to_* \Omega Y$ defined to be the composite
\[
\begin{tikzcd} x=_Xx \arrow[r, "\ap_f"] & f(x) =_Y f(x) \arrow[r, "p^{-1} \cdot - \cdot p"] & y =_Y y
\end{tikzcd}
\]
where $p : f(x) = y$ is part of the data that comes with the pointed function $f$. Given another pointed map $g : Y \to_* Z$ there is a homotopy witnessing that the triangle of pointed maps of pointed types commutes:
\[
\begin{tikzcd}&\Omega Y \arrow[dr, "\Omega g"] \\ \Omega X \arrow[ur, "\Omega f"] \arrow[rr, "\Omega(g \circ f)"'] & & \Omega Z
\end{tikzcd}
\]

\subsection*{The suspension}

The loop space construction is closely related to the construction of the \textbf{suspension} of a type. To define this, we first need to define homotopy pushouts in type theory.

The idea of a pushout is it is a way to glue together two types $A$ and $B$ along a mediating type $S$ via maps $f \colon S \to A$ and $g \colon S \to B$. In other words we start with a diagram of the form
\[ \begin{tikzcd} A & S \arrow[l, "f"'] \arrow[r, "g"] & B
\end{tikzcd}
\]
called a \textbf{span}.

\begin{defn} A \textbf{cocone} under a span $(S,f,g)$ is given by a type $X$, a pair of functions $i : A \to X$ and $j : B \to X$ and a homotopy $H : i \circ f \sim j \circ g$ witnessing that the square
\[
\begin{tikzcd} S \arrow[d, "f"'] \arrow[r, "g"] & B \arrow[d, "j"] \\ A \arrow[r, "i"'] & X
\end{tikzcd}
\]
commutes.
\end{defn}

We write $\type{cocone}_SX$ for the type of cocones under the span $(S,f,g)$ with nadir $X$. Given a cocone $(i,j,H)$ with nadir $X$ and a map $h : X \to Y$ there is a cocone with nadir $Y$ defined by $(h \circ i, h \circ j, h \cdot H)$. 

\begin{defn} A commuting square
\[
\begin{tikzcd} S \arrow[d, "f"'] \arrow[r, "g"] & B \arrow[d, "j"] \\ A \arrow[r, "i"'] & X
\end{tikzcd}
\]
witnessed by $H : i \circ f \sim j \circ g$ is a (\textbf{homotopy}) \textbf{pushout square} if the map
\[ 
\begin{tikzcd}[row sep=tiny] (X \to Y) \arrow[r] & \type{cocone}_S(Y) \\ h \arrow[r, maps to] & (h \circ i, h \circ j, h \cdot H)
\end{tikzcd}
\]
is an equivalence for any type $Y$.
\end{defn}

Pushouts are not guaranteed to exist in plain vanilla homotopy type theory but can be constructed as higher inductive types: given a span $f \colon S \to A$ and $g \colon S \to B$ the pushout $A \cup_S B$ can be built as the higher inductive type with constructors
\begin{itemize}
\item $\inl : A \to A \cup_S B$
\item $\inr : B \to A \cup_S B$
\item $\glue : \Pi_{x :S} \inl(f(x)) = \inr(g(x))$
\end{itemize}



\begin{defn} Let $X$ be a type. A \textbf{suspension} of $X$ is a type $\Sigma X$ equipped with a \textbf{north pole} $N : \Sigma X$, a \textbf{south pole} $S : \Sigma X$, and a meridian $\term{merid} : X \to (N = S)$ so that the commuting square
\[
\begin{tikzcd} X \arrow[r, "\const_\star"] \arrow[d, "\const_\star"'] & \1 \arrow[d, "\const_S"] \\ \1 \arrow[r, "\const_N"'] & \Sigma X
\end{tikzcd}
\]
is a pushout square.
\end{defn}

\begin{defn} For any $n : \NN$ we define the $n$-\textbf{sphere} by induction on $n$ by
\[ \Sn{0} \coloneq \bool \qquad \Sn{n+1} \coloneq \Sigma \Sn{n}.\]
 \end{defn}
 
 You can even start one dimension lower by defining $\Sn{-1} \coloneq \emptyset$ and observing that $\Sigma\Sn{-1} \simeq \bool$.

\begin{rmk} It is interesting to compare the definition of the 1-sphere as $\Sigma\Sn{0}$ with the definition of $\Sone$ as a higher inductive type generated by $\base : \Sone$ and $\lloop : \base = \base$. The former defines a higher inductive type with constructors:
\begin{itemize}
 \item $N : \Sigma\Sn{0}$
 \item $S : \Sigma\Sn{0}$
 \item $\glue_\top : N = S$
 \item $\glue_\bot : N = S$
 \end{itemize}
From these definitions, its easy to define a map $\Sone \to \Sigma\Sn{0}$ by $\base\mapsto N$ and $\lloop \mapsto \glue_\top \ast \glue_\bot^{-1}$. A map $\Sigma\Sn{0} \to \Sone$ in the other direction is given by $N, S \mapsto \base$, $\glue_\top \mapsto \lloop$, $\glue_\bot \mapsto \refl$. A proof by induction \cite[6.5.1]{book-hott} shows that these functions are quasi-inverses.
 \end{rmk}

For any type $X$, we regard the suspension $\Sigma X$ as a pointed type with $N : \Sigma X$ as its basepoint. For a pointed type $(A,a)$ we define $\Sigma (A,a) = (\Sigma A, N)$ so that suspension defines a function $\Sigma \colon \UU_* \to \UU_*$ similarly to $\Omega : \UU_* \to \UU_*$. Again, suspension is \emph{functorial} in maps of pointed types, though in this case the data of the basepoints isn't really needed. Given a map $f \colon A \to B$ we can define a map $\Sigma f : \Sigma A \to_* \Sigma B$ of pointed types by appealing to the universal property of pushouts. To define the underlying map $\Sigma f : \Sigma A \to \Sigma B$ we use the equivalence
$(\Sigma A \to \Sigma B) \simeq \type{cocone}_A \Sigma B$ and instead construct a cocone
\[
\begin{tikzcd} A \arrow[r, "\const_\star"] \arrow[d, "\const_\star"'] & \1 \arrow[d, "\const_S"] \\ \1 \arrow[r, "\const_N"'] & \Sigma B
\end{tikzcd}
\]
under the span that defines the suspension of $A$. Here we take the north and south pole of $\Sigma B$ for the required maps $\1 \to \Sigma B$. It remains only to define a homotopy in the type
\[ \Pi_{x:A} N = S.\] For this we whisker the homotopy $\term{merid} : B \to (N = S)$ that comes from the suspension of $B$ and restrict along the map $f \colon A \to B$. The homotopies of the equivalence turn this function $\Sigma f : \Sigma A \to \Sigma B$ into a pointed map by providing a term of type $\Sigma f(N) = N$. Again $\Sigma \colon \UU_* \to \UU_*$ is functorial.

The constructions $\Sigma$ and $\Omega$ are \textbf{adjoint functors} on pointed types in the following sense.

\begin{thm} For any pointed types $(A,a)$ and $(B,b)$ there is an equivalence
\[ (\Sigma A \to_* B) \simeq (A \to_* \Omega B).\]
\end{thm}
\begin{proof}
We describe the maps between pointed mapping spaces and save the proof of the equivalence to the literature.

Given $f : \Sigma A \to_* B$ with $p : f(N) = b$ define a map $g : A \to_* \Omega B$ by defining $g(x)$ to be the composite loop
\[
\begin{tikzcd} b \arrow[r, equals, "p^{-1}"] & f(N) \arrow[r, equals, "\ap_f(\term{merid}(x))"] & f(S) \arrow[r, equals, "\ap_f(\term{merid}(a))^{-1}"] & f(N) \arrow[r, "p", equals] & b
\end{tikzcd}
\]
To show that $g$ is a pointed map we must identify the path $g(a)$
\[
\begin{tikzcd} b \arrow[r, equals, "p^{-1}"] & f(N) \arrow[r, equals, "\ap_f(\term{merid}(a))"] & f(S) \arrow[r, equals, "\ap_f(\term{merid}(a))^{-1}"] & f(N) \arrow[r, "p", equals] & b
\end{tikzcd}
\]
with $\refl_b$, which we can do by composing the unit and inverse laws for paths.

Conversely, given $g : A \to \Omega B$ we use the recursion that comes with the construction of the suspension as a higher inductive type to define $f : \Sigma A \to B$. We must choose terms $f(N) \coloneq b$ and $f(S) \coloneq b$ and then for each $a :A$ define a path $\ap_f(\term{merid}(a)) \coloneq g(a) : b = b$.
\end{proof}

\subsection*{Set truncation}

There are various ways one can define the \textbf{set truncation} $\set{A}$ of a type $A$, which is a type with a map $|-|_0 \colon A \to \set{A}$ which is universal among maps from $A$ to a set. One strategy is to define the quotient of the type $A$ by the equivalence relation $I_{-1} : A \to A \to \Prop$ defined by $I_{-1}(x,y) \coloneq \mere{ x= y}$. See \cite[27.3]{Rijke}.

Another approach is to define $\set{A}$ as a higher inductive type, as follows:

\begin{defn} For any type $A$ define $\set{A}$ to be the higher inductive type with constructors:
\begin{itemize}
\item $|-|_0 : A \to \set{A}$ and
\item $\term{set-quotient} : \Pi_{x,y: \set{A}} \Pi_{p,q: x=y} p =q$
\end{itemize}
\end{defn}

See \cite[6.9]{book-hott} for more.


\subsection*{Homotopy groups of types}

\begin{defn} Let $(X,x)$ be a pointed type and $n : \NN$ be a natural number with $n \geq 1$. The $n$-th \textbf{homotopy group} of a type $X$ with basepoint $x$ is defined to be the type
\[
\pi_n(X,x) \coloneq \set{ \Omega^n(X,x)}
\]
equipped with the group operations inherited from the path operations on $\Omega^n(X,x)$.
\end{defn}

It is common to write $\pi_nX$, dropping reference to the base point. For $n \doteq 0$ define $\pi_0X \coloneq \set{X}$, which is a set but not a group in general.

\begin{ex} From the equivalence $\Omega^1\Sone \simeq \ZZ$ we see that $\pi_1\Sone \simeq \ZZ$ and indeed $\pi_1\Sone$'s group structure is given by addition on $\ZZ$. Since $\Omega^n\Sone \simeq \1$ for $n > 1$ we have $\pi_n\Sone$ is the trivial group for $n \geq 2$, which is common to denote by $0$ (since the higher homotopy groups are always abelian). It follows by $\Sone$ induction that $\set{\Sone}$ is contractible, so $\pi_0\Sone \simeq \1$ as well.
\end{ex}

\subsection*{the Eckmann-Hilton argument}

An important theorem about the higher homotopy groups is the following.

\begin{thm} For any pointed type $(X,x)$ and for $n : \NN$ with $n \geq 2$, $\pi_n(X,x)$ is an abelian group.
\end{thm}

The proof involves a famous argument called the \emph{Eckmann-Hilton} argument about paths between loops on a common basepoint, which follows from the interchange law:

\begin{lem}[interchange law] Consider a diagram of paths and paths between paths of the form
\[
\begin{tikzcd}
x \arrow[r, bend left=60, equals] \arrow[r, equals, "{\Downarrow r}", "{\Downarrow r'}"'] \arrow[r, bend right=60, equals] & y \arrow[r, bend left=60, equals] \arrow[r, equals, "{\Downarrow s}", "{\Downarrow s'}"'] \arrow[r, bend right=60, equals] & z
\end{tikzcd}
\]
Then there is an identification between the horizontal composite of the vertical composites and the vertical composite of the horizontal composites.
\end{lem}


\section*{December 6: Classifying types of groups}

\bibliographystyle{alpha}
\begin{thebibliography}{UF}


\bibitem[R]{Rijke} Egbert Rijke, \emph{Introduction to Homotopy Type Theory}, available from \url{https://hott.zulipchat.com}

\bibitem[UF]{book-hott} \emph{Homotopy Type Theory: Univalent Foundations of Mathematics}, the Univalent Foundations Program, Institute for Advanced Study, available from \url{https://homotopytypetheory.org/book/}

\end{thebibliography}


\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% TeX-master: t
%%% End:
